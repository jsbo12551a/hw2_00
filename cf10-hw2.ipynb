{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3431,
     "status": "ok",
     "timestamp": 1620138284446,
     "user": {
      "displayName": "Sin Jia Zeng",
      "photoUrl": "",
      "userId": "01680498491985827186"
     },
     "user_tz": -480
    },
    "id": "mb48QetIIGJo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model, Model, Input\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils,plot_model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPool2D ,MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, UpSampling2D, concatenate\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import backend as K \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score,f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.densenet import DenseNet201,preprocess_input\n",
    "from keras.applications import VGG16 ,InceptionResNetV2\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3429,
     "status": "ok",
     "timestamp": 1620138284446,
     "user": {
      "displayName": "Sin Jia Zeng",
      "photoUrl": "",
      "userId": "01680498491985827186"
     },
     "user_tz": -480
    },
    "id": "x3liIzw3u9eg"
   },
   "outputs": [],
   "source": [
    "def plot_acc(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left') \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8024,
     "status": "ok",
     "timestamp": 1620138289043,
     "user": {
      "displayName": "Sin Jia Zeng",
      "photoUrl": "",
      "userId": "01680498491985827186"
     },
     "user_tz": -480
    },
    "id": "XC-TpvlGIV9l",
    "outputId": "cf7c864e-1bc8-4c7a-97e4-930a156e500c"
   },
   "outputs": [],
   "source": [
    "(x_img_train, y_label_train),(x_img_test,y_label_test)=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8018,
     "status": "ok",
     "timestamp": 1620138289043,
     "user": {
      "displayName": "Sin Jia Zeng",
      "photoUrl": "",
      "userId": "01680498491985827186"
     },
     "user_tz": -480
    },
    "id": "9yqej-DaIYNd",
    "outputId": "d1edf2a7-08c9-46a4-cfe7-f3485f5db501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data images (50000, 32, 32, 3) labels (50000, 1)\n",
      "test data images (10000, 32, 32, 3) labels (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"train data\", 'images', x_img_train.shape,\n",
    "      \"labels\", y_label_train.shape)\n",
    "print(\"test data\", 'images', x_img_test.shape,\n",
    "      \"labels\", y_label_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 9077,
     "status": "ok",
     "timestamp": 1620138290104,
     "user": {
      "displayName": "Sin Jia Zeng",
      "photoUrl": "",
      "userId": "01680498491985827186"
     },
     "user_tz": -480
    },
    "id": "xF5aTL_4zyO3"
   },
   "outputs": [],
   "source": [
    "# datagen = ImageDataGenerator(\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     horizontal_flip=True)\n",
    "\n",
    "datagen =  ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(x_img_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9076,
     "status": "ok",
     "timestamp": 1620138290104,
     "user": {
      "displayName": "Sin Jia Zeng",
      "photoUrl": "",
      "userId": "01680498491985827186"
     },
     "user_tz": -480
    },
    "id": "nkz8QN6FIa8V"
   },
   "outputs": [],
   "source": [
    "x_img_train_normalize = x_img_train.copy()\n",
    "x_img_test_normalize = x_img_test.copy()\n",
    "x_img_train_normalize = x_img_train.astype('float32') / 255.0\n",
    "x_img_test_normalize = x_img_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 9076,
     "status": "ok",
     "timestamp": 1620138290105,
     "user": {
      "displayName": "Sin Jia Zeng",
      "photoUrl": "",
      "userId": "01680498491985827186"
     },
     "user_tz": -480
    },
    "id": "ViB6CFfnIdUJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "y_label_train_OneHot = np_utils.to_categorical(y_label_train)\n",
    "y_label_test_OneHot = np_utils.to_categorical(y_label_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_img_train_normalize, y_label_train_OneHot, test_size=0.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 14573,
     "status": "ok",
     "timestamp": 1620138295604,
     "user": {
      "displayName": "Sin Jia Zeng",
      "photoUrl": "",
      "userId": "01680498491985827186"
     },
     "user_tz": -480
    },
    "id": "y6g6NWTmIedZ"
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(filters=64, kernel_size=3, input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
    "# model.add(Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'))\n",
    "# model.add(MaxPool2D(pool_size=2))\n",
    "\n",
    "# model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "# model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "# model.add(MaxPool2D(pool_size=2))\n",
    "\n",
    "# model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "# model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "# model.add(MaxPool2D(pool_size=2))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(rate=0.25))\n",
    "# model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Model)          (None, 1, 1, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               491776    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 18,816,330\n",
      "Trainable params: 18,587,274\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "DenseNet201_model = DenseNet201(include_top=False, weights=\"imagenet\", input_shape=(32,32,3))\n",
    "# model = add_new_last_layer(model, 3)\n",
    "\n",
    "# net.trainable = False\n",
    "model = Sequential()\n",
    "model.add(DenseNet201_model)\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Conv2D(256, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(Flatten()) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(256, activation='relu')) \n",
    "# model.add(Dense(128, activation='relu')) \n",
    "model.add(Dropout(0.1)) \n",
    "model.add(Dense(10, activation='softmax')) \n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20)\n",
    "callback_save = keras.callbacks.ModelCheckpoint(filepath='C:/Users/mb207/Desktop/py/save/desnet.ckpt', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr=1e-4), metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xtb_3tQ4If_B",
    "outputId": "e9725250-1bfa-4ca3-e6f1-cc07ded2c76c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-fa68a04abf69>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.7846 - accuracy: 0.3743\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61945, saving model to C:/Users/mb207/Desktop/py/save/desnet.ckpt\n",
      "WARNING:tensorflow:From C:\\Users\\mb207\\Anaconda3\\envs\\py_37_tf_2.2\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/desnet.ckpt\\assets\n",
      "500/500 [==============================] - 215s 431ms/step - loss: 1.7846 - accuracy: 0.3743 - val_loss: 1.1490 - val_accuracy: 0.6195\n",
      "Epoch 2/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.2286 - accuracy: 0.5896\n",
      "Epoch 00002: val_accuracy improved from 0.61945 to 0.69758, saving model to C:/Users/mb207/Desktop/py/save/desnet.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/desnet.ckpt\\assets\n",
      "500/500 [==============================] - 214s 428ms/step - loss: 1.2286 - accuracy: 0.5896 - val_loss: 0.9715 - val_accuracy: 0.6976\n",
      "Epoch 3/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0628 - accuracy: 0.6501\n",
      "Epoch 00003: val_accuracy improved from 0.69758 to 0.71824, saving model to C:/Users/mb207/Desktop/py/save/desnet.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/desnet.ckpt\\assets\n",
      "500/500 [==============================] - 222s 444ms/step - loss: 1.0628 - accuracy: 0.6501 - val_loss: 0.9270 - val_accuracy: 0.7182\n",
      "Epoch 4/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0017 - accuracy: 0.6693\n",
      "Epoch 00004: val_accuracy improved from 0.71824 to 0.73018, saving model to C:/Users/mb207/Desktop/py/save/desnet.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/desnet.ckpt\\assets\n",
      "500/500 [==============================] - 229s 458ms/step - loss: 1.0017 - accuracy: 0.6693 - val_loss: 0.8827 - val_accuracy: 0.7302\n",
      "Epoch 5/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9325 - accuracy: 0.6982\n",
      "Epoch 00005: val_accuracy improved from 0.73018 to 0.74752, saving model to C:/Users/mb207/Desktop/py/save/desnet.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/desnet.ckpt\\assets\n",
      "500/500 [==============================] - 235s 469ms/step - loss: 0.9325 - accuracy: 0.6982 - val_loss: 1.0408 - val_accuracy: 0.7475\n",
      "Epoch 6/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8974 - accuracy: 0.7069\n",
      "Epoch 00006: val_accuracy improved from 0.74752 to 0.76030, saving model to C:/Users/mb207/Desktop/py/save/desnet.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/desnet.ckpt\\assets\n",
      "500/500 [==============================] - 239s 478ms/step - loss: 0.8974 - accuracy: 0.7069 - val_loss: 0.7243 - val_accuracy: 0.7603\n",
      "Epoch 7/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8292 - accuracy: 0.7263\n",
      "Epoch 00007: val_accuracy did not improve from 0.76030\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 0.8292 - accuracy: 0.7263 - val_loss: 2.7081 - val_accuracy: 0.7235\n",
      "Epoch 8/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8181 - accuracy: 0.7388 ETA: 2s - loss:\n",
      "Epoch 00008: val_accuracy improved from 0.76030 to 0.78879, saving model to C:/Users/mb207/Desktop/py/save/desnet.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/desnet.ckpt\\assets\n",
      "500/500 [==============================] - 246s 493ms/step - loss: 0.8181 - accuracy: 0.7388 - val_loss: 0.7963 - val_accuracy: 0.7888\n",
      "Epoch 9/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7811 - accuracy: 0.7550\n",
      "Epoch 00009: val_accuracy did not improve from 0.78879\n",
      "500/500 [==============================] - 91s 183ms/step - loss: 0.7811 - accuracy: 0.7550 - val_loss: 2.2413 - val_accuracy: 0.7520\n",
      "Epoch 10/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7351 - accuracy: 0.7638\n",
      "Epoch 00010: val_accuracy improved from 0.78879 to 0.80636, saving model to C:/Users/mb207/Desktop/py/save/desnet.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/desnet.ckpt\\assets\n",
      "500/500 [==============================] - 237s 475ms/step - loss: 0.7351 - accuracy: 0.7638 - val_loss: 0.6355 - val_accuracy: 0.8064\n",
      "Epoch 11/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7378 - accuracy: 0.7701\n",
      "Epoch 00011: val_accuracy did not improve from 0.80636\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 0.7378 - accuracy: 0.7701 - val_loss: 2.4277 - val_accuracy: 0.7630\n",
      "Epoch 12/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6874 - accuracy: 0.7845\n",
      "Epoch 00012: val_accuracy improved from 0.80636 to 0.80727, saving model to C:/Users/mb207/Desktop/py/save/desnet.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/desnet.ckpt\\assets\n",
      "500/500 [==============================] - 240s 480ms/step - loss: 0.6874 - accuracy: 0.7845 - val_loss: 1.1986 - val_accuracy: 0.8073\n",
      "Epoch 13/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6854 - accuracy: 0.7816\n",
      "Epoch 00013: val_accuracy did not improve from 0.80727\n",
      "500/500 [==============================] - 93s 186ms/step - loss: 0.6854 - accuracy: 0.7816 - val_loss: 0.7822 - val_accuracy: 0.8013\n",
      "Epoch 14/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6691 - accuracy: 0.7904\n",
      "Epoch 00014: val_accuracy did not improve from 0.80727\n",
      "500/500 [==============================] - 93s 185ms/step - loss: 0.6691 - accuracy: 0.7904 - val_loss: 3.9635 - val_accuracy: 0.7838\n",
      "Epoch 15/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6252 - accuracy: 0.7956\n",
      "Epoch 00015: val_accuracy did not improve from 0.80727\n",
      "500/500 [==============================] - 93s 186ms/step - loss: 0.6252 - accuracy: 0.7956 - val_loss: 3.0092 - val_accuracy: 0.7587\n",
      "Epoch 16/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6178 - accuracy: 0.8074\n",
      "Epoch 00016: val_accuracy did not improve from 0.80727\n",
      "500/500 [==============================] - 93s 186ms/step - loss: 0.6178 - accuracy: 0.8074 - val_loss: 5.6858 - val_accuracy: 0.7567\n",
      "Epoch 17/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6263 - accuracy: 0.8091\n",
      "Epoch 00017: val_accuracy did not improve from 0.80727\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 0.6263 - accuracy: 0.8091 - val_loss: 1.0686 - val_accuracy: 0.7898\n",
      "Epoch 18/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6063 - accuracy: 0.8072\n",
      "Epoch 00018: val_accuracy did not improve from 0.80727\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 0.6063 - accuracy: 0.8072 - val_loss: 8.4767 - val_accuracy: 0.7545\n",
      "Epoch 19/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5843 - accuracy: 0.8165\n",
      "Epoch 00019: val_accuracy did not improve from 0.80727\n",
      "500/500 [==============================] - 92s 183ms/step - loss: 0.5843 - accuracy: 0.8165 - val_loss: 3.8496 - val_accuracy: 0.7959\n",
      "Epoch 20/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5727 - accuracy: 0.8186\n",
      "Epoch 00020: val_accuracy did not improve from 0.80727\n",
      "500/500 [==============================] - 93s 185ms/step - loss: 0.5727 - accuracy: 0.8186 - val_loss: 2.8886 - val_accuracy: 0.7927\n",
      "Epoch 21/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5606 - accuracy: 0.8236\n",
      "Epoch 00021: val_accuracy improved from 0.80727 to 0.82533, saving model to C:/Users/mb207/Desktop/py/save/desnet.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/desnet.ckpt\\assets\n",
      "500/500 [==============================] - 246s 492ms/step - loss: 0.5606 - accuracy: 0.8236 - val_loss: 1.3472 - val_accuracy: 0.8253\n",
      "Epoch 22/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5523 - accuracy: 0.8253\n",
      "Epoch 00022: val_accuracy did not improve from 0.82533\n",
      "500/500 [==============================] - 93s 185ms/step - loss: 0.5523 - accuracy: 0.8253 - val_loss: 0.9086 - val_accuracy: 0.8182\n",
      "Epoch 23/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5252 - accuracy: 0.8329\n",
      "Epoch 00023: val_accuracy did not improve from 0.82533\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 0.5252 - accuracy: 0.8329 - val_loss: 29.4200 - val_accuracy: 0.7765\n",
      "Epoch 24/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5424 - accuracy: 0.8329\n",
      "Epoch 00024: val_accuracy did not improve from 0.82533\n",
      "500/500 [==============================] - 93s 186ms/step - loss: 0.5424 - accuracy: 0.8329 - val_loss: 4.3256 - val_accuracy: 0.7899\n",
      "Epoch 25/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5004 - accuracy: 0.8409\n",
      "Epoch 00025: val_accuracy did not improve from 0.82533\n",
      "500/500 [==============================] - 93s 185ms/step - loss: 0.5004 - accuracy: 0.8409 - val_loss: 9.2877 - val_accuracy: 0.7916\n",
      "Epoch 26/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5086 - accuracy: 0.8402\n",
      "Epoch 00026: val_accuracy did not improve from 0.82533\n",
      "500/500 [==============================] - 93s 186ms/step - loss: 0.5086 - accuracy: 0.8402 - val_loss: 6.8641 - val_accuracy: 0.7735\n",
      "Epoch 27/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5068 - accuracy: 0.8461\n",
      "Epoch 00027: val_accuracy improved from 0.82533 to 0.83297, saving model to C:/Users/mb207/Desktop/py/save/desnet.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/desnet.ckpt\\assets\n",
      "500/500 [==============================] - 239s 478ms/step - loss: 0.5068 - accuracy: 0.8461 - val_loss: 0.5572 - val_accuracy: 0.8330\n",
      "Epoch 28/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4951 - accuracy: 0.8479 ETA: 1s - loss: 0.4\n",
      "Epoch 00028: val_accuracy improved from 0.83297 to 0.83776, saving model to C:/Users/mb207/Desktop/py/save/desnet.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/desnet.ckpt\\assets\n",
      "500/500 [==============================] - 241s 482ms/step - loss: 0.4951 - accuracy: 0.8479 - val_loss: 1.0848 - val_accuracy: 0.8378\n",
      "Epoch 29/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5016 - accuracy: 0.8474\n",
      "Epoch 00029: val_accuracy did not improve from 0.83776\n",
      "500/500 [==============================] - 93s 187ms/step - loss: 0.5016 - accuracy: 0.8474 - val_loss: 2.2133 - val_accuracy: 0.8065\n",
      "Epoch 30/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4723 - accuracy: 0.8499\n",
      "Epoch 00030: val_accuracy did not improve from 0.83776\n",
      "500/500 [==============================] - 94s 187ms/step - loss: 0.4723 - accuracy: 0.8499 - val_loss: 1.0186 - val_accuracy: 0.8357\n",
      "Epoch 31/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4826 - accuracy: 0.8511\n",
      "Epoch 00031: val_accuracy did not improve from 0.83776\n",
      "500/500 [==============================] - 94s 188ms/step - loss: 0.4826 - accuracy: 0.8511 - val_loss: 6.9450 - val_accuracy: 0.7827\n",
      "Epoch 32/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4551 - accuracy: 0.8592\n",
      "Epoch 00032: val_accuracy improved from 0.83776 to 0.83970, saving model to C:/Users/mb207/Desktop/py/save/desnet.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/desnet.ckpt\\assets\n",
      "500/500 [==============================] - 242s 485ms/step - loss: 0.4551 - accuracy: 0.8592 - val_loss: 0.8137 - val_accuracy: 0.8397\n",
      "Epoch 33/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4611 - accuracy: 0.8568\n",
      "Epoch 00033: val_accuracy did not improve from 0.83970\n",
      "500/500 [==============================] - 95s 190ms/step - loss: 0.4611 - accuracy: 0.8568 - val_loss: 4.1300 - val_accuracy: 0.7898\n",
      "Epoch 34/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4343 - accuracy: 0.8645\n",
      "Epoch 00034: val_accuracy did not improve from 0.83970\n",
      "500/500 [==============================] - 94s 189ms/step - loss: 0.4343 - accuracy: 0.8645 - val_loss: 1.9342 - val_accuracy: 0.8105\n",
      "Epoch 35/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4566 - accuracy: 0.8582\n",
      "Epoch 00035: val_accuracy did not improve from 0.83970\n",
      "500/500 [==============================] - 95s 189ms/step - loss: 0.4566 - accuracy: 0.8582 - val_loss: 18.2819 - val_accuracy: 0.7829\n",
      "Epoch 36/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4438 - accuracy: 0.8665\n",
      "Epoch 00036: val_accuracy did not improve from 0.83970\n",
      "500/500 [==============================] - 95s 191ms/step - loss: 0.4438 - accuracy: 0.8665 - val_loss: 5.6524 - val_accuracy: 0.7683\n",
      "Epoch 37/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4287 - accuracy: 0.8627\n",
      "Epoch 00037: val_accuracy did not improve from 0.83970\n",
      "500/500 [==============================] - 95s 190ms/step - loss: 0.4287 - accuracy: 0.8627 - val_loss: 2.7832 - val_accuracy: 0.8277\n",
      "Epoch 38/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4485 - accuracy: 0.8671\n",
      "Epoch 00038: val_accuracy improved from 0.83970 to 0.84509, saving model to C:/Users/mb207/Desktop/py/save/desnet.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/desnet.ckpt\\assets\n",
      "500/500 [==============================] - 243s 487ms/step - loss: 0.4485 - accuracy: 0.8671 - val_loss: 1.6206 - val_accuracy: 0.8451\n",
      "Epoch 39/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4372 - accuracy: 0.8676\n",
      "Epoch 00039: val_accuracy improved from 0.84509 to 0.85158, saving model to C:/Users/mb207/Desktop/py/save/desnet.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/desnet.ckpt\\assets\n",
      "500/500 [==============================] - 240s 479ms/step - loss: 0.4372 - accuracy: 0.8676 - val_loss: 0.5237 - val_accuracy: 0.8516\n",
      "Epoch 40/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4297 - accuracy: 0.8700\n",
      "Epoch 00040: val_accuracy did not improve from 0.85158\n",
      "500/500 [==============================] - 94s 189ms/step - loss: 0.4297 - accuracy: 0.8700 - val_loss: 32.0961 - val_accuracy: 0.7188\n",
      "Epoch 41/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.8669\n",
      "Epoch 00041: val_accuracy did not improve from 0.85158\n",
      "500/500 [==============================] - 93s 185ms/step - loss: 0.4399 - accuracy: 0.8669 - val_loss: 11.1642 - val_accuracy: 0.8014\n",
      "Epoch 42/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.8710\n",
      "Epoch 00042: val_accuracy did not improve from 0.85158\n",
      "500/500 [==============================] - 96s 192ms/step - loss: 0.4371 - accuracy: 0.8710 - val_loss: 10.8629 - val_accuracy: 0.7774\n",
      "Epoch 43/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4208 - accuracy: 0.8716\n",
      "Epoch 00043: val_accuracy did not improve from 0.85158\n",
      "500/500 [==============================] - 95s 190ms/step - loss: 0.4208 - accuracy: 0.8716 - val_loss: 32.6213 - val_accuracy: 0.7618\n",
      "Epoch 44/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4130 - accuracy: 0.8734\n",
      "Epoch 00044: val_accuracy did not improve from 0.85158\n",
      "500/500 [==============================] - 95s 191ms/step - loss: 0.4130 - accuracy: 0.8734 - val_loss: 7.8204 - val_accuracy: 0.8028\n",
      "Epoch 45/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4005 - accuracy: 0.8796\n",
      "Epoch 00045: val_accuracy did not improve from 0.85158\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 0.4005 - accuracy: 0.8796 - val_loss: 6.3955 - val_accuracy: 0.8298\n",
      "Epoch 46/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3874 - accuracy: 0.8794\n",
      "Epoch 00046: val_accuracy did not improve from 0.85158\n",
      "500/500 [==============================] - 91s 182ms/step - loss: 0.3874 - accuracy: 0.8794 - val_loss: 39.7580 - val_accuracy: 0.7677\n",
      "Epoch 47/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4163 - accuracy: 0.8763\n",
      "Epoch 00047: val_accuracy did not improve from 0.85158\n",
      "500/500 [==============================] - 92s 183ms/step - loss: 0.4163 - accuracy: 0.8763 - val_loss: 8.4814 - val_accuracy: 0.8041\n",
      "Epoch 48/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3931 - accuracy: 0.8822\n",
      "Epoch 00048: val_accuracy did not improve from 0.85158\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 0.3931 - accuracy: 0.8822 - val_loss: 9.2310 - val_accuracy: 0.8192\n",
      "Epoch 49/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4073 - accuracy: 0.8752\n",
      "Epoch 00049: val_accuracy did not improve from 0.85158\n",
      "500/500 [==============================] - 95s 190ms/step - loss: 0.4073 - accuracy: 0.8752 - val_loss: 23.8384 - val_accuracy: 0.7805\n",
      "Epoch 50/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.8803\n",
      "Epoch 00050: val_accuracy did not improve from 0.85158\n",
      "500/500 [==============================] - 93s 187ms/step - loss: 0.3852 - accuracy: 0.8803 - val_loss: 11.0804 - val_accuracy: 0.8091\n",
      "Epoch 51/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3883 - accuracy: 0.8864\n",
      "Epoch 00051: val_accuracy did not improve from 0.85158\n",
      "500/500 [==============================] - 93s 187ms/step - loss: 0.3883 - accuracy: 0.8864 - val_loss: 6.4964 - val_accuracy: 0.8313\n",
      "Epoch 52/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.8810\n",
      "Epoch 00052: val_accuracy did not improve from 0.85158\n",
      "500/500 [==============================] - 95s 189ms/step - loss: 0.4135 - accuracy: 0.8810 - val_loss: 1.6982 - val_accuracy: 0.8232\n",
      "Epoch 53/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8876\n",
      "Epoch 00053: val_accuracy did not improve from 0.85158\n",
      "500/500 [==============================] - 92s 183ms/step - loss: 0.3805 - accuracy: 0.8876 - val_loss: 26.9952 - val_accuracy: 0.7402\n",
      "Epoch 54/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3740 - accuracy: 0.8837\n",
      "Epoch 00054: val_accuracy did not improve from 0.85158\n",
      "500/500 [==============================] - 92s 185ms/step - loss: 0.3740 - accuracy: 0.8837 - val_loss: 22.1828 - val_accuracy: 0.7968\n",
      "Epoch 55/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3801 - accuracy: 0.8901\n",
      "Epoch 00055: val_accuracy improved from 0.85158 to 0.86006, saving model to C:/Users/mb207/Desktop/py/save/desnet.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/desnet.ckpt\\assets\n",
      "500/500 [==============================] - 258s 516ms/step - loss: 0.3801 - accuracy: 0.8901 - val_loss: 0.6737 - val_accuracy: 0.8601\n",
      "Epoch 56/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3528 - accuracy: 0.8902\n",
      "Epoch 00056: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 98s 195ms/step - loss: 0.3528 - accuracy: 0.8902 - val_loss: 4.4105 - val_accuracy: 0.8364\n",
      "Epoch 57/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3723 - accuracy: 0.8947 ETA: 0s - loss: 0.3732 - accuracy\n",
      "Epoch 00057: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 95s 191ms/step - loss: 0.3723 - accuracy: 0.8947 - val_loss: 18.0137 - val_accuracy: 0.7959\n",
      "Epoch 58/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3636 - accuracy: 0.8934\n",
      "Epoch 00058: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 98s 197ms/step - loss: 0.3636 - accuracy: 0.8934 - val_loss: 2.6584 - val_accuracy: 0.8245\n",
      "Epoch 59/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3720 - accuracy: 0.8923\n",
      "Epoch 00059: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 98s 196ms/step - loss: 0.3720 - accuracy: 0.8923 - val_loss: 18.5167 - val_accuracy: 0.8002\n",
      "Epoch 60/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3765 - accuracy: 0.89 - ETA: 0s - loss: 0.3768 - accuracy: 0.8934\n",
      "Epoch 00060: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 100s 201ms/step - loss: 0.3768 - accuracy: 0.8934 - val_loss: 17.6327 - val_accuracy: 0.7900\n",
      "Epoch 61/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3984 - accuracy: 0.8884\n",
      "Epoch 00061: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 96s 191ms/step - loss: 0.3984 - accuracy: 0.8884 - val_loss: 24.0140 - val_accuracy: 0.7829\n",
      "Epoch 62/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3703 - accuracy: 0.8895\n",
      "Epoch 00062: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 93s 186ms/step - loss: 0.3703 - accuracy: 0.8895 - val_loss: 39.1770 - val_accuracy: 0.7666\n",
      "Epoch 63/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3426 - accuracy: 0.8961\n",
      "Epoch 00063: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 92s 185ms/step - loss: 0.3426 - accuracy: 0.8961 - val_loss: 114.1022 - val_accuracy: 0.7336\n",
      "Epoch 64/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3600 - accuracy: 0.8946\n",
      "Epoch 00064: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 92s 185ms/step - loss: 0.3600 - accuracy: 0.8946 - val_loss: 9.5313 - val_accuracy: 0.7908\n",
      "Epoch 65/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3502 - accuracy: 0.8958\n",
      "Epoch 00065: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 93s 186ms/step - loss: 0.3502 - accuracy: 0.8958 - val_loss: 18.1221 - val_accuracy: 0.8135\n",
      "Epoch 66/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3506 - accuracy: 0.8953\n",
      "Epoch 00066: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 93s 187ms/step - loss: 0.3506 - accuracy: 0.8953 - val_loss: 42.6731 - val_accuracy: 0.7794\n",
      "Epoch 67/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3483 - accuracy: 0.8949\n",
      "Epoch 00067: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 93s 186ms/step - loss: 0.3483 - accuracy: 0.8949 - val_loss: 30.2398 - val_accuracy: 0.7902\n",
      "Epoch 68/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3534 - accuracy: 0.9023\n",
      "Epoch 00068: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 94s 189ms/step - loss: 0.3534 - accuracy: 0.9023 - val_loss: 22.2368 - val_accuracy: 0.7893\n",
      "Epoch 69/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3679 - accuracy: 0.8979\n",
      "Epoch 00069: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 95s 190ms/step - loss: 0.3679 - accuracy: 0.8979 - val_loss: 64.6346 - val_accuracy: 0.7473\n",
      "Epoch 70/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3261 - accuracy: 0.9041\n",
      "Epoch 00070: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 95s 190ms/step - loss: 0.3261 - accuracy: 0.9041 - val_loss: 59.2737 - val_accuracy: 0.7625\n",
      "Epoch 71/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3592 - accuracy: 0.8982\n",
      "Epoch 00071: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 94s 188ms/step - loss: 0.3592 - accuracy: 0.8982 - val_loss: 12.6757 - val_accuracy: 0.8081\n",
      "Epoch 72/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3571 - accuracy: 0.8960\n",
      "Epoch 00072: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 95s 189ms/step - loss: 0.3571 - accuracy: 0.8960 - val_loss: 13.1958 - val_accuracy: 0.8099\n",
      "Epoch 73/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3336 - accuracy: 0.9017\n",
      "Epoch 00073: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 96s 191ms/step - loss: 0.3336 - accuracy: 0.9017 - val_loss: 11.1869 - val_accuracy: 0.8177\n",
      "Epoch 74/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3274 - accuracy: 0.9041\n",
      "Epoch 00074: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 95s 189ms/step - loss: 0.3274 - accuracy: 0.9041 - val_loss: 4.9788 - val_accuracy: 0.8422\n",
      "Epoch 75/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3452 - accuracy: 0.8999\n",
      "Epoch 00075: val_accuracy did not improve from 0.86006\n",
      "500/500 [==============================] - 100s 200ms/step - loss: 0.3452 - accuracy: 0.8999 - val_loss: 7.3314 - val_accuracy: 0.7978\n"
     ]
    }
   ],
   "source": [
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.fit(x_img_train_normalize, y_label_train_OneHot, epochs=10, batch_size=64, verbose=1)\n",
    "history = model.fit_generator(X_train,y_train,batch_size=20, \n",
    "                               epochs=500,\n",
    "                              validation_data=(X_test,y_test),callbacks=[earlystopping,callback_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "l0s9z72EIiv5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 20s 65ms/step - loss: 8.1575 - accuracy: 0.7933\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_img_test_normalize, y_label_test_OneHot)\n",
    "pred = model.predict(x_img_test_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4lqPWlp8RQUT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 19s 61ms/step - loss: 8.1575 - accuracy: 0.7933\n",
      "WARNING:tensorflow:From <ipython-input-13-e84cf3b32266>:4: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Loss: 8.157470703125\n",
      "Accuracy: 0.7932999730110168\n",
      "predict accurscy: 0.7933, precision: 0.8170482325395259, recall: 0.7933000000000001, f1 : 0.7949109758548543\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# model.load_weights('py/mango')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(x_img_test_normalize,y_label_test_OneHot)\n",
    "pred_cy = model.predict_classes(x_img_test_normalize)\n",
    "\n",
    "precision = precision_score(y_label_test, pred_cy, average='macro')\n",
    "recall = recall_score(y_label_test, pred_cy, average='macro')\n",
    "acc = accuracy_score(y_label_test, pred_cy)\n",
    "f1 = f1_score(y_label_test, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1 : {f1}')\n",
    "plot_acc(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDz-msBPKadU"
   },
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9NwDZzvxKwAf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 14,781,642\n",
      "Trainable params: 14,781,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_base = VGG16(weights = 'imagenet', include_top = False, input_shape = (32 ,32,3))\n",
    "\n",
    "# conv_base.trainable = False\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(64, activation = 'relu'))\n",
    "# # model.add(Dropout(0.1))\n",
    "# model.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "\n",
    "# model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Flatten()) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(128, activation='relu')) \n",
    "# model.add(Dropout(0.5)) \n",
    "model.add(Dense(10, activation='softmax')) \n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20)\n",
    "callback_save = keras.callbacks.ModelCheckpoint(filepath='C:/Users/mb207/Desktop/py/save/VGG.ckpt', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr=1e-4), metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "s4gh5MSVK0Pn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.7843 - accuracy: 0.3598\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61218, saving model to C:/Users/mb207/Desktop/py/save/VGG.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/VGG.ckpt\\assets\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 1.7843 - accuracy: 0.3598 - val_loss: 1.1081 - val_accuracy: 0.6122\n",
      "Epoch 2/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.2118 - accuracy: 0.6028\n",
      "Epoch 00002: val_accuracy improved from 0.61218 to 0.67497, saving model to C:/Users/mb207/Desktop/py/save/VGG.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/VGG.ckpt\\assets\n",
      "500/500 [==============================] - 26s 52ms/step - loss: 1.2120 - accuracy: 0.6027 - val_loss: 0.9780 - val_accuracy: 0.6750\n",
      "Epoch 3/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0060 - accuracy: 0.6758\n",
      "Epoch 00003: val_accuracy did not improve from 0.67497\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.0060 - accuracy: 0.6758 - val_loss: 1.0721 - val_accuracy: 0.6682\n",
      "Epoch 4/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.9116 - accuracy: 0.7113\n",
      "Epoch 00004: val_accuracy improved from 0.67497 to 0.74091, saving model to C:/Users/mb207/Desktop/py/save/VGG.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/VGG.ckpt\\assets\n",
      "500/500 [==============================] - 25s 51ms/step - loss: 0.9112 - accuracy: 0.7114 - val_loss: 0.7633 - val_accuracy: 0.7409\n",
      "Epoch 5/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.8741 - accuracy: 0.7214\n",
      "Epoch 00005: val_accuracy improved from 0.74091 to 0.76261, saving model to C:/Users/mb207/Desktop/py/save/VGG.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/VGG.ckpt\\assets\n",
      "500/500 [==============================] - 25s 51ms/step - loss: 0.8733 - accuracy: 0.7218 - val_loss: 0.8271 - val_accuracy: 0.7626\n",
      "Epoch 6/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8807 - accuracy: 0.7222\n",
      "Epoch 00006: val_accuracy did not improve from 0.76261\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.8807 - accuracy: 0.7222 - val_loss: 0.8853 - val_accuracy: 0.7307\n",
      "Epoch 7/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8514 - accuracy: 0.7368\n",
      "Epoch 00007: val_accuracy improved from 0.76261 to 0.78085, saving model to C:/Users/mb207/Desktop/py/save/VGG.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/VGG.ckpt\\assets\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.8514 - accuracy: 0.7368 - val_loss: 0.6757 - val_accuracy: 0.7808\n",
      "Epoch 8/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8650 - accuracy: 0.7338\n",
      "Epoch 00008: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.8650 - accuracy: 0.7338 - val_loss: 0.7104 - val_accuracy: 0.7675\n",
      "Epoch 9/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8482 - accuracy: 0.7430\n",
      "Epoch 00009: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.8482 - accuracy: 0.7430 - val_loss: 0.6869 - val_accuracy: 0.7805\n",
      "Epoch 10/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.8658 - accuracy: 0.7346\n",
      "Epoch 00010: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.8655 - accuracy: 0.7347 - val_loss: 0.7083 - val_accuracy: 0.7718\n",
      "Epoch 11/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.9197 - accuracy: 0.7255\n",
      "Epoch 00011: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9196 - accuracy: 0.7252 - val_loss: 0.8528 - val_accuracy: 0.7441\n",
      "Epoch 12/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.9167 - accuracy: 0.7291\n",
      "Epoch 00012: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 0.9164 - accuracy: 0.7291 - val_loss: 0.8836 - val_accuracy: 0.7107\n",
      "Epoch 13/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.9449 - accuracy: 0.7185\n",
      "Epoch 00013: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 0.9449 - accuracy: 0.7186 - val_loss: 1.1358 - val_accuracy: 0.7662\n",
      "Epoch 14/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0045 - accuracy: 0.7055\n",
      "Epoch 00014: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 1.0078 - accuracy: 0.7051 - val_loss: 0.9930 - val_accuracy: 0.7084\n",
      "Epoch 15/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0514 - accuracy: 0.6940\n",
      "Epoch 00015: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 1.0514 - accuracy: 0.6940 - val_loss: 0.9659 - val_accuracy: 0.6693\n",
      "Epoch 16/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0494 - accuracy: 0.6833\n",
      "Epoch 00016: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 1.0487 - accuracy: 0.6836 - val_loss: 1.0297 - val_accuracy: 0.6926\n",
      "Epoch 17/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.1781 - accuracy: 0.6627\n",
      "Epoch 00017: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 1.1782 - accuracy: 0.6631 - val_loss: 1.4293 - val_accuracy: 0.7071\n",
      "Epoch 18/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.2265 - accuracy: 0.6385\n",
      "Epoch 00018: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 1.2265 - accuracy: 0.6385 - val_loss: 1.0548 - val_accuracy: 0.7155\n",
      "Epoch 19/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.3552 - accuracy: 0.6225\n",
      "Epoch 00019: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 1.3546 - accuracy: 0.6226 - val_loss: 0.8591 - val_accuracy: 0.7165\n",
      "Epoch 20/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.2696 - accuracy: 0.6343\n",
      "Epoch 00020: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 18s 37ms/step - loss: 1.2696 - accuracy: 0.6343 - val_loss: 1.1882 - val_accuracy: 0.6753\n",
      "Epoch 21/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.3356 - accuracy: 0.6177\n",
      "Epoch 00021: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 1.3348 - accuracy: 0.6178 - val_loss: 1.1926 - val_accuracy: 0.6815\n",
      "Epoch 22/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.2696 - accuracy: 0.6167\n",
      "Epoch 00022: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 1.2706 - accuracy: 0.6161 - val_loss: 1.1459 - val_accuracy: 0.6709\n",
      "Epoch 23/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.4265 - accuracy: 0.6145\n",
      "Epoch 00023: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 1.4248 - accuracy: 0.6149 - val_loss: 0.9868 - val_accuracy: 0.6764\n",
      "Epoch 24/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.2798 - accuracy: 0.6177\n",
      "Epoch 00024: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 19s 37ms/step - loss: 1.2794 - accuracy: 0.6177 - val_loss: 0.9832 - val_accuracy: 0.7268\n",
      "Epoch 25/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.3941 - accuracy: 0.5899\n",
      "Epoch 00025: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 1.3935 - accuracy: 0.5897 - val_loss: 1.1314 - val_accuracy: 0.7149\n",
      "Epoch 26/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.5240 - accuracy: 0.5668\n",
      "Epoch 00026: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 1.5240 - accuracy: 0.5668 - val_loss: 0.9819 - val_accuracy: 0.6853\n",
      "Epoch 27/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.4776 - accuracy: 0.5516\n",
      "Epoch 00027: val_accuracy did not improve from 0.78085\n",
      "500/500 [==============================] - 19s 39ms/step - loss: 1.4771 - accuracy: 0.5518 - val_loss: 1.0258 - val_accuracy: 0.6913\n"
     ]
    }
   ],
   "source": [
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.fit(x_img_train_normalize, y_label_train_OneHot, epochs=10, batch_size=64, verbose=1)\n",
    "history = model.fit_generator(X_train,y_train,batch_size=20, \n",
    "                               epochs=500,\n",
    "                              validation_data=(X_test,y_test),callbacks=[earlystopping,callback_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "P-aJDALdwUdC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 16ms/step - loss: 1.0365 - accuracy: 0.6870\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_img_test_normalize, y_label_test_OneHot)\n",
    "pred = model.predict(x_img_test_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 14ms/step - loss: 1.0365 - accuracy: 0.6870\n",
      "Loss: 1.0364726781845093\n",
      "Accuracy: 0.6869999766349792\n",
      "predict accurscy: 0.687, precision: 0.7111171057621888, recall: 0.6869999999999999, f1 : 0.6749089143243256\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model.load_weights('py/mango')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(x_img_test_normalize,y_label_test_OneHot)\n",
    "pred_cy = model.predict_classes(x_img_test_normalize)\n",
    "\n",
    "precision = precision_score(y_label_test, pred_cy, average='macro')\n",
    "recall = recall_score(y_label_test, pred_cy, average='macro')\n",
    "acc = accuracy_score(y_label_test, pred_cy)\n",
    "f1 = f1_score(y_label_test, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1 : {f1}')\n",
    "plot_acc(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,246,218\n",
      "Trainable params: 1,246,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = (32,32,3), padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation = 'relu', padding='same'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(180, (3, 3), activation = 'relu', padding='same'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "callback_save = keras.callbacks.ModelCheckpoint(filepath='C:/Users/mb207/Desktop/py/save/CNN.ckpt', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.9338 - accuracy: 0.2725\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.37430, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 19s 37ms/step - loss: 1.9338 - accuracy: 0.2725 - val_loss: 1.6565 - val_accuracy: 0.3743\n",
      "Epoch 2/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.6521 - accuracy: 0.3883\n",
      "Epoch 00002: val_accuracy improved from 0.37430 to 0.44636, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 1.6513 - accuracy: 0.3887 - val_loss: 1.4840 - val_accuracy: 0.4464\n",
      "Epoch 3/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.5108 - accuracy: 0.4448\n",
      "Epoch 00003: val_accuracy improved from 0.44636 to 0.45552, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.5109 - accuracy: 0.4448 - val_loss: 1.4983 - val_accuracy: 0.4555\n",
      "Epoch 4/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.4388 - accuracy: 0.4757\n",
      "Epoch 00004: val_accuracy improved from 0.45552 to 0.53515, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 1.4393 - accuracy: 0.4752 - val_loss: 1.2757 - val_accuracy: 0.5352\n",
      "Epoch 5/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.3794 - accuracy: 0.4985 ETA: 0s - loss: 1.3796 - accuracy: 0.\n",
      "Epoch 00005: val_accuracy did not improve from 0.53515\n",
      "500/500 [==============================] - 17s 34ms/step - loss: 1.3794 - accuracy: 0.4985 - val_loss: 1.3308 - val_accuracy: 0.5213\n",
      "Epoch 6/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.3327 - accuracy: 0.5195\n",
      "Epoch 00006: val_accuracy improved from 0.53515 to 0.55667, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 1.3327 - accuracy: 0.5195 - val_loss: 1.2233 - val_accuracy: 0.5567\n",
      "Epoch 7/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.2747 - accuracy: 0.5420\n",
      "Epoch 00007: val_accuracy improved from 0.55667 to 0.56642, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 1.2746 - accuracy: 0.5419 - val_loss: 1.2016 - val_accuracy: 0.5664\n",
      "Epoch 8/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.2365 - accuracy: 0.5570\n",
      "Epoch 00008: val_accuracy improved from 0.56642 to 0.58224, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 1.2365 - accuracy: 0.5570 - val_loss: 1.1419 - val_accuracy: 0.5822\n",
      "Epoch 9/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.2094 - accuracy: 0.5631\n",
      "Epoch 00009: val_accuracy did not improve from 0.58224\n",
      "500/500 [==============================] - 17s 34ms/step - loss: 1.2089 - accuracy: 0.5635 - val_loss: 1.1720 - val_accuracy: 0.5774\n",
      "Epoch 10/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.1920 - accuracy: 0.5656\n",
      "Epoch 00010: val_accuracy improved from 0.58224 to 0.59376, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 19s 39ms/step - loss: 1.1920 - accuracy: 0.5656 - val_loss: 1.1387 - val_accuracy: 0.5938\n",
      "Epoch 11/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.1544 - accuracy: 0.5839\n",
      "Epoch 00011: val_accuracy improved from 0.59376 to 0.61794, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 1.1544 - accuracy: 0.5839 - val_loss: 1.0723 - val_accuracy: 0.6179\n",
      "Epoch 12/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.1426 - accuracy: 0.5947 ETA: 0s -\n",
      "Epoch 00012: val_accuracy improved from 0.61794 to 0.64109, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 1.1426 - accuracy: 0.5947 - val_loss: 1.0140 - val_accuracy: 0.6411\n",
      "Epoch 13/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.1153 - accuracy: 0.6000\n",
      "Epoch 00013: val_accuracy did not improve from 0.64109\n",
      "500/500 [==============================] - 17s 34ms/step - loss: 1.1158 - accuracy: 0.6000 - val_loss: 1.0617 - val_accuracy: 0.6238\n",
      "Epoch 14/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0771 - accuracy: 0.6210 ETA: 0s - loss: 1.0770 - accuracy - ETA: 0s - loss: 1.0781 - accu\n",
      "Epoch 00014: val_accuracy did not improve from 0.64109\n",
      "500/500 [==============================] - 17s 34ms/step - loss: 1.0772 - accuracy: 0.6210 - val_loss: 1.0282 - val_accuracy: 0.6346\n",
      "Epoch 15/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0743 - accuracy: 0.6114\n",
      "Epoch 00015: val_accuracy improved from 0.64109 to 0.66036, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 1.0743 - accuracy: 0.6114 - val_loss: 0.9654 - val_accuracy: 0.6604\n",
      "Epoch 16/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0252 - accuracy: 0.6353\n",
      "Epoch 00016: val_accuracy did not improve from 0.66036\n",
      "500/500 [==============================] - 18s 36ms/step - loss: 1.0249 - accuracy: 0.6354 - val_loss: 1.0488 - val_accuracy: 0.6304\n",
      "Epoch 17/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0173 - accuracy: 0.6345\n",
      "Epoch 00017: val_accuracy improved from 0.66036 to 0.66758, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 1.0183 - accuracy: 0.6343 - val_loss: 0.9433 - val_accuracy: 0.6676\n",
      "Epoch 18/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.0202 - accuracy: 0.6412\n",
      "Epoch 00018: val_accuracy did not improve from 0.66758\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0198 - accuracy: 0.6412 - val_loss: 1.0116 - val_accuracy: 0.6412\n",
      "Epoch 19/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0146 - accuracy: 0.6416\n",
      "Epoch 00019: val_accuracy improved from 0.66758 to 0.67921, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 1.0146 - accuracy: 0.6416 - val_loss: 0.9102 - val_accuracy: 0.6792\n",
      "Epoch 20/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9859 - accuracy: 0.6556 ETA: 1s - loss: 0.9826 - accuracy - ETA: 0s - loss:\n",
      "Epoch 00020: val_accuracy did not improve from 0.67921\n",
      "500/500 [==============================] - 17s 34ms/step - loss: 0.9859 - accuracy: 0.6556 - val_loss: 1.0008 - val_accuracy: 0.6547\n",
      "Epoch 21/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9883 - accuracy: 0.6523\n",
      "Epoch 00021: val_accuracy did not improve from 0.67921\n",
      "500/500 [==============================] - 17s 33ms/step - loss: 0.9883 - accuracy: 0.6523 - val_loss: 0.9331 - val_accuracy: 0.6773\n",
      "Epoch 22/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9431 - accuracy: 0.6675\n",
      "Epoch 00022: val_accuracy improved from 0.67921 to 0.69255, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9431 - accuracy: 0.6675 - val_loss: 0.8723 - val_accuracy: 0.6925\n",
      "Epoch 23/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.9244 - accuracy: 0.6751 E\n",
      "Epoch 00023: val_accuracy did not improve from 0.69255\n",
      "500/500 [==============================] - 17s 34ms/step - loss: 0.9249 - accuracy: 0.6750 - val_loss: 0.9175 - val_accuracy: 0.6842\n",
      "Epoch 24/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9404 - accuracy: 0.6690\n",
      "Epoch 00024: val_accuracy did not improve from 0.69255\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9404 - accuracy: 0.6690 - val_loss: 0.9312 - val_accuracy: 0.6828\n",
      "Epoch 25/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9307 - accuracy: 0.6706\n",
      "Epoch 00025: val_accuracy improved from 0.69255 to 0.70333, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 0.9307 - accuracy: 0.6706 - val_loss: 0.8564 - val_accuracy: 0.7033\n",
      "Epoch 26/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.9304 - accuracy: 0.6685\n",
      "Epoch 00026: val_accuracy did not improve from 0.70333\n",
      "500/500 [==============================] - 17s 35ms/step - loss: 0.9297 - accuracy: 0.6688 - val_loss: 0.8719 - val_accuracy: 0.6996\n",
      "Epoch 27/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9199 - accuracy: 0.6745 ETA: 0s - loss: 0.9\n",
      "Epoch 00027: val_accuracy did not improve from 0.70333\n",
      "500/500 [==============================] - 18s 35ms/step - loss: 0.9199 - accuracy: 0.6745 - val_loss: 0.8480 - val_accuracy: 0.7018\n",
      "Epoch 28/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.8860 - accuracy: 0.6893\n",
      "Epoch 00028: val_accuracy did not improve from 0.70333\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.8857 - accuracy: 0.6895 - val_loss: 0.9207 - val_accuracy: 0.6826\n",
      "Epoch 29/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.9021 - accuracy: 0.6830 ETA: 0s - loss: 0.9008 - accuracy\n",
      "Epoch 00029: val_accuracy improved from 0.70333 to 0.70709, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.9021 - accuracy: 0.6830 - val_loss: 0.8342 - val_accuracy: 0.7071\n",
      "Epoch 30/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.8740 - accuracy: 0.6934\n",
      "Epoch 00030: val_accuracy did not improve from 0.70709\n",
      "500/500 [==============================] - 17s 33ms/step - loss: 0.8745 - accuracy: 0.6932 - val_loss: 0.9179 - val_accuracy: 0.6803\n",
      "Epoch 31/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.8623 - accuracy: 0.6969\n",
      "Epoch 00031: val_accuracy did not improve from 0.70709\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.8618 - accuracy: 0.6970 - val_loss: 0.8598 - val_accuracy: 0.7039\n",
      "Epoch 32/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.8707 - accuracy: 0.6908\n",
      "Epoch 00032: val_accuracy did not improve from 0.70709\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.8718 - accuracy: 0.6905 - val_loss: 0.8512 - val_accuracy: 0.7040\n",
      "Epoch 33/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8513 - accuracy: 0.7021\n",
      "Epoch 00033: val_accuracy did not improve from 0.70709\n",
      "500/500 [==============================] - 17s 34ms/step - loss: 0.8513 - accuracy: 0.7021 - val_loss: 1.0021 - val_accuracy: 0.6700\n",
      "Epoch 34/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8525 - accuracy: 0.7023\n",
      "Epoch 00034: val_accuracy did not improve from 0.70709\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.8525 - accuracy: 0.7023 - val_loss: 0.8655 - val_accuracy: 0.7038\n",
      "Epoch 35/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.8468 - accuracy: 0.7022\n",
      "Epoch 00035: val_accuracy improved from 0.70709 to 0.70818, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.8468 - accuracy: 0.7021 - val_loss: 0.8402 - val_accuracy: 0.7082\n",
      "Epoch 36/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.8336 - accuracy: 0.7072\n",
      "Epoch 00036: val_accuracy improved from 0.70818 to 0.71067, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 0.8335 - accuracy: 0.7072 - val_loss: 0.8698 - val_accuracy: 0.7107\n",
      "Epoch 37/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8299 - accuracy: 0.7119 E - E\n",
      "Epoch 00037: val_accuracy did not improve from 0.71067\n",
      "500/500 [==============================] - 17s 35ms/step - loss: 0.8299 - accuracy: 0.7119 - val_loss: 0.8406 - val_accuracy: 0.7101\n",
      "Epoch 38/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.8356 - accuracy: 0.7017\n",
      "Epoch 00038: val_accuracy improved from 0.71067 to 0.72121, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 19s 37ms/step - loss: 0.8356 - accuracy: 0.7016 - val_loss: 0.8040 - val_accuracy: 0.7212\n",
      "Epoch 39/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.8343 - accuracy: 0.7065\n",
      "Epoch 00039: val_accuracy did not improve from 0.72121\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 0.8348 - accuracy: 0.7063 - val_loss: 0.8614 - val_accuracy: 0.7050\n",
      "Epoch 40/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.8166 - accuracy: 0.7135 ETA: 0s - loss: 0.8166 \n",
      "Epoch 00040: val_accuracy improved from 0.72121 to 0.72964, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 19s 39ms/step - loss: 0.8171 - accuracy: 0.7135 - val_loss: 0.7883 - val_accuracy: 0.7296\n",
      "Epoch 41/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8028 - accuracy: 0.7118\n",
      "Epoch 00041: val_accuracy did not improve from 0.72964\n",
      "500/500 [==============================] - 17s 33ms/step - loss: 0.8028 - accuracy: 0.7118 - val_loss: 0.8404 - val_accuracy: 0.7166\n",
      "Epoch 42/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8181 - accuracy: 0.7157\n",
      "Epoch 00042: val_accuracy did not improve from 0.72964\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 0.8181 - accuracy: 0.7157 - val_loss: 0.8527 - val_accuracy: 0.7110\n",
      "Epoch 43/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.7844 - accuracy: 0.7278\n",
      "Epoch 00043: val_accuracy did not improve from 0.72964\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 0.7845 - accuracy: 0.7279 - val_loss: 0.8426 - val_accuracy: 0.7176\n",
      "Epoch 44/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.7919 - accuracy: 0.7168\n",
      "Epoch 00044: val_accuracy did not improve from 0.72964\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 0.7913 - accuracy: 0.7171 - val_loss: 0.8379 - val_accuracy: 0.7149\n",
      "Epoch 45/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.8029 - accuracy: 0.7200\n",
      "Epoch 00045: val_accuracy did not improve from 0.72964\n",
      "500/500 [==============================] - 16s 31ms/step - loss: 0.8028 - accuracy: 0.7201 - val_loss: 0.8135 - val_accuracy: 0.7229\n",
      "Epoch 46/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.7890 - accuracy: 0.7236\n",
      "Epoch 00046: val_accuracy improved from 0.72964 to 0.73291, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.7893 - accuracy: 0.7233 - val_loss: 0.7885 - val_accuracy: 0.7329\n",
      "Epoch 47/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.7821 - accuracy: 0.7246\n",
      "Epoch 00047: val_accuracy did not improve from 0.73291\n",
      "500/500 [==============================] - 17s 34ms/step - loss: 0.7814 - accuracy: 0.7248 - val_loss: 0.8640 - val_accuracy: 0.7105\n",
      "Epoch 48/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.7772 - accuracy: 0.7267\n",
      "Epoch 00048: val_accuracy did not improve from 0.73291\n",
      "500/500 [==============================] - 17s 33ms/step - loss: 0.7768 - accuracy: 0.7267 - val_loss: 0.7864 - val_accuracy: 0.7302\n",
      "Epoch 49/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7604 - accuracy: 0.7331\n",
      "Epoch 00049: val_accuracy did not improve from 0.73291\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 0.7604 - accuracy: 0.7331 - val_loss: 0.8350 - val_accuracy: 0.7131\n",
      "Epoch 50/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.7726 - accuracy: 0.7258\n",
      "Epoch 00050: val_accuracy did not improve from 0.73291\n",
      "500/500 [==============================] - 15s 31ms/step - loss: 0.7724 - accuracy: 0.7257 - val_loss: 0.8237 - val_accuracy: 0.7222\n",
      "Epoch 51/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.7604 - accuracy: 0.7341\n",
      "Epoch 00051: val_accuracy improved from 0.73291 to 0.73709, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 17s 34ms/step - loss: 0.7607 - accuracy: 0.7342 - val_loss: 0.7694 - val_accuracy: 0.7371\n",
      "Epoch 52/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7554 - accuracy: 0.7346\n",
      "Epoch 00052: val_accuracy improved from 0.73709 to 0.73830, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.7554 - accuracy: 0.7346 - val_loss: 0.7668 - val_accuracy: 0.7383\n",
      "Epoch 53/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.7710 - accuracy: 0.7346\n",
      "Epoch 00053: val_accuracy did not improve from 0.73830\n",
      "500/500 [==============================] - 15s 31ms/step - loss: 0.7713 - accuracy: 0.7344 - val_loss: 0.8035 - val_accuracy: 0.7272\n",
      "Epoch 54/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7300 - accuracy: 0.7470\n",
      "Epoch 00054: val_accuracy did not improve from 0.73830\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.7300 - accuracy: 0.7470 - val_loss: 0.8058 - val_accuracy: 0.7297\n",
      "Epoch 55/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.7515 - accuracy: 0.7352\n",
      "Epoch 00055: val_accuracy did not improve from 0.73830\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.7510 - accuracy: 0.7353 - val_loss: 0.7883 - val_accuracy: 0.7326\n",
      "Epoch 56/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.7383 - accuracy: 0.7478\n",
      "Epoch 00056: val_accuracy did not improve from 0.73830\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.7379 - accuracy: 0.7479 - val_loss: 0.7876 - val_accuracy: 0.7361\n",
      "Epoch 57/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7444 - accuracy: 0.7388\n",
      "Epoch 00057: val_accuracy did not improve from 0.73830\n",
      "500/500 [==============================] - 15s 31ms/step - loss: 0.7444 - accuracy: 0.7388 - val_loss: 0.7867 - val_accuracy: 0.7349\n",
      "Epoch 58/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7292 - accuracy: 0.7415 ETA: 0s - loss: 0.7\n",
      "Epoch 00058: val_accuracy did not improve from 0.73830\n",
      "500/500 [==============================] - 15s 31ms/step - loss: 0.7292 - accuracy: 0.7415 - val_loss: 0.7751 - val_accuracy: 0.7351\n",
      "Epoch 59/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7379 - accuracy: 0.7392\n",
      "Epoch 00059: val_accuracy did not improve from 0.73830\n",
      "500/500 [==============================] - 14s 29ms/step - loss: 0.7379 - accuracy: 0.7392 - val_loss: 0.7847 - val_accuracy: 0.7367\n",
      "Epoch 60/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.7292 - accuracy: 0.7412 ETA: 0s - loss: 0.7291 - accuracy: 0.74\n",
      "Epoch 00060: val_accuracy did not improve from 0.73830\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.7292 - accuracy: 0.7410 - val_loss: 0.8201 - val_accuracy: 0.7241\n",
      "Epoch 61/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7397 - accuracy: 0.7373\n",
      "Epoch 00061: val_accuracy did not improve from 0.73830\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.7397 - accuracy: 0.7373 - val_loss: 0.8538 - val_accuracy: 0.7104\n",
      "Epoch 62/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.7139 - accuracy: 0.7496\n",
      "Epoch 00062: val_accuracy did not improve from 0.73830\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.7135 - accuracy: 0.7497 - val_loss: 0.8124 - val_accuracy: 0.7247\n",
      "Epoch 63/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7365 - accuracy: 0.7418\n",
      "Epoch 00063: val_accuracy did not improve from 0.73830\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.7365 - accuracy: 0.7418 - val_loss: 0.7780 - val_accuracy: 0.7379\n",
      "Epoch 64/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7256 - accuracy: 0.7467\n",
      "Epoch 00064: val_accuracy improved from 0.73830 to 0.74333, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 19s 37ms/step - loss: 0.7256 - accuracy: 0.7467 - val_loss: 0.7622 - val_accuracy: 0.7433\n",
      "Epoch 65/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7074 - accuracy: 0.7527\n",
      "Epoch 00065: val_accuracy did not improve from 0.74333\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.7074 - accuracy: 0.7527 - val_loss: 0.8002 - val_accuracy: 0.7302\n",
      "Epoch 66/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7032 - accuracy: 0.7541\n",
      "Epoch 00066: val_accuracy did not improve from 0.74333\n",
      "500/500 [==============================] - 15s 31ms/step - loss: 0.7032 - accuracy: 0.7541 - val_loss: 0.7656 - val_accuracy: 0.7410\n",
      "Epoch 67/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.7590\n",
      "Epoch 00067: val_accuracy improved from 0.74333 to 0.74812, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 17s 35ms/step - loss: 0.6957 - accuracy: 0.7590 - val_loss: 0.7526 - val_accuracy: 0.7481\n",
      "Epoch 68/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7086 - accuracy: 0.7535\n",
      "Epoch 00068: val_accuracy did not improve from 0.74812\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.7086 - accuracy: 0.7535 - val_loss: 0.7808 - val_accuracy: 0.7390\n",
      "Epoch 69/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7146 - accuracy: 0.7496\n",
      "Epoch 00069: val_accuracy did not improve from 0.74812\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.7146 - accuracy: 0.7496 - val_loss: 0.8071 - val_accuracy: 0.7298\n",
      "Epoch 70/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6864 - accuracy: 0.7580\n",
      "Epoch 00070: val_accuracy did not improve from 0.74812\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6865 - accuracy: 0.7580 - val_loss: 0.8219 - val_accuracy: 0.7354\n",
      "Epoch 71/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.7556\n",
      "Epoch 00071: val_accuracy did not improve from 0.74812\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6928 - accuracy: 0.7556 - val_loss: 0.7588 - val_accuracy: 0.7477\n",
      "Epoch 72/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6759 - accuracy: 0.7671\n",
      "Epoch 00072: val_accuracy improved from 0.74812 to 0.75358, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 18s 35ms/step - loss: 0.6764 - accuracy: 0.7669 - val_loss: 0.7515 - val_accuracy: 0.7536\n",
      "Epoch 73/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6857 - accuracy: 0.7585\n",
      "Epoch 00073: val_accuracy did not improve from 0.75358\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6857 - accuracy: 0.7585 - val_loss: 0.7953 - val_accuracy: 0.7389\n",
      "Epoch 74/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7026 - accuracy: 0.7535\n",
      "Epoch 00074: val_accuracy did not improve from 0.75358\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.7026 - accuracy: 0.7535 - val_loss: 0.7824 - val_accuracy: 0.7379\n",
      "Epoch 75/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6739 - accuracy: 0.7628\n",
      "Epoch 00075: val_accuracy did not improve from 0.75358\n",
      "500/500 [==============================] - 14s 29ms/step - loss: 0.6739 - accuracy: 0.7628 - val_loss: 0.8568 - val_accuracy: 0.7247\n",
      "Epoch 76/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6875 - accuracy: 0.7551\n",
      "Epoch 00076: val_accuracy did not improve from 0.75358\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6871 - accuracy: 0.7553 - val_loss: 0.8418 - val_accuracy: 0.7326\n",
      "Epoch 77/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6893 - accuracy: 0.7591\n",
      "Epoch 00077: val_accuracy did not improve from 0.75358\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6889 - accuracy: 0.7593 - val_loss: 0.8197 - val_accuracy: 0.7359\n",
      "Epoch 78/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6825 - accuracy: 0.7668\n",
      "Epoch 00078: val_accuracy did not improve from 0.75358\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6825 - accuracy: 0.7668 - val_loss: 0.8618 - val_accuracy: 0.7336\n",
      "Epoch 79/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6742 - accuracy: 0.7659\n",
      "Epoch 00079: val_accuracy did not improve from 0.75358\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6739 - accuracy: 0.7661 - val_loss: 0.7915 - val_accuracy: 0.7412\n",
      "Epoch 80/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6835 - accuracy: 0.7637\n",
      "Epoch 00080: val_accuracy did not improve from 0.75358\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6834 - accuracy: 0.7637 - val_loss: 0.7705 - val_accuracy: 0.7444\n",
      "Epoch 81/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6594 - accuracy: 0.7716\n",
      "Epoch 00081: val_accuracy did not improve from 0.75358\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6594 - accuracy: 0.7716 - val_loss: 0.8325 - val_accuracy: 0.7344\n",
      "Epoch 82/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6572 - accuracy: 0.7740\n",
      "Epoch 00082: val_accuracy did not improve from 0.75358\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6572 - accuracy: 0.7740 - val_loss: 0.8083 - val_accuracy: 0.7353\n",
      "Epoch 83/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6557 - accuracy: 0.7738\n",
      "Epoch 00083: val_accuracy did not improve from 0.75358\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6548 - accuracy: 0.7741 - val_loss: 0.7651 - val_accuracy: 0.7465\n",
      "Epoch 84/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6516 - accuracy: 0.7714\n",
      "Epoch 00084: val_accuracy did not improve from 0.75358\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6516 - accuracy: 0.7714 - val_loss: 0.8352 - val_accuracy: 0.7355\n",
      "Epoch 85/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6610 - accuracy: 0.7662\n",
      "Epoch 00085: val_accuracy did not improve from 0.75358\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6610 - accuracy: 0.7662 - val_loss: 0.8420 - val_accuracy: 0.7248\n",
      "Epoch 86/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6540 - accuracy: 0.7708\n",
      "Epoch 00086: val_accuracy did not improve from 0.75358\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6536 - accuracy: 0.7707 - val_loss: 0.8104 - val_accuracy: 0.7390\n",
      "Epoch 87/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6463 - accuracy: 0.7724\n",
      "Epoch 00087: val_accuracy improved from 0.75358 to 0.75400, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 18s 36ms/step - loss: 0.6467 - accuracy: 0.7722 - val_loss: 0.7430 - val_accuracy: 0.7540\n",
      "Epoch 88/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6324 - accuracy: 0.7768\n",
      "Epoch 00088: val_accuracy did not improve from 0.75400\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6326 - accuracy: 0.7763 - val_loss: 0.7890 - val_accuracy: 0.7459\n",
      "Epoch 89/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6598 - accuracy: 0.7715 ETA: 0s - loss: 0.657\n",
      "Epoch 00089: val_accuracy did not improve from 0.75400\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6598 - accuracy: 0.7715 - val_loss: 0.7649 - val_accuracy: 0.7460\n",
      "Epoch 90/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6442 - accuracy: 0.7790\n",
      "Epoch 00090: val_accuracy did not improve from 0.75400\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6445 - accuracy: 0.7789 - val_loss: 0.7612 - val_accuracy: 0.7523\n",
      "Epoch 91/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6329 - accuracy: 0.7747\n",
      "Epoch 00091: val_accuracy did not improve from 0.75400\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6329 - accuracy: 0.7747 - val_loss: 0.7711 - val_accuracy: 0.7474\n",
      "Epoch 92/500\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.6551 - accuracy: 0.7746\n",
      "Epoch 00092: val_accuracy improved from 0.75400 to 0.75794, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 18s 35ms/step - loss: 0.6550 - accuracy: 0.7746 - val_loss: 0.7391 - val_accuracy: 0.7579\n",
      "Epoch 93/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6499 - accuracy: 0.7704 ETA:  - ETA: \n",
      "Epoch 00093: val_accuracy did not improve from 0.75794\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6494 - accuracy: 0.7706 - val_loss: 0.7678 - val_accuracy: 0.7510\n",
      "Epoch 94/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6633 - accuracy: 0.7676\n",
      "Epoch 00094: val_accuracy did not improve from 0.75794\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6633 - accuracy: 0.7676 - val_loss: 0.7792 - val_accuracy: 0.7432\n",
      "Epoch 95/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6536 - accuracy: 0.7731\n",
      "Epoch 00095: val_accuracy did not improve from 0.75794\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6536 - accuracy: 0.7731 - val_loss: 0.7508 - val_accuracy: 0.7507\n",
      "Epoch 96/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6327 - accuracy: 0.7812\n",
      "Epoch 00096: val_accuracy did not improve from 0.75794\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6327 - accuracy: 0.7812 - val_loss: 0.7527 - val_accuracy: 0.7540\n",
      "Epoch 97/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6345 - accuracy: 0.7844\n",
      "Epoch 00097: val_accuracy did not improve from 0.75794\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6343 - accuracy: 0.7844 - val_loss: 0.7792 - val_accuracy: 0.7529\n",
      "Epoch 98/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6306 - accuracy: 0.7812\n",
      "Epoch 00098: val_accuracy did not improve from 0.75794\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6306 - accuracy: 0.7812 - val_loss: 0.7822 - val_accuracy: 0.7502\n",
      "Epoch 99/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6319 - accuracy: 0.7759\n",
      "Epoch 00099: val_accuracy improved from 0.75794 to 0.75848, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 17s 34ms/step - loss: 0.6319 - accuracy: 0.7759 - val_loss: 0.7504 - val_accuracy: 0.7585\n",
      "Epoch 100/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6335 - accuracy: 0.7782\n",
      "Epoch 00100: val_accuracy did not improve from 0.75848\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6335 - accuracy: 0.7782 - val_loss: 0.7846 - val_accuracy: 0.7447\n",
      "Epoch 101/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6218 - accuracy: 0.7828\n",
      "Epoch 00101: val_accuracy did not improve from 0.75848\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6223 - accuracy: 0.7825 - val_loss: 0.7942 - val_accuracy: 0.7467\n",
      "Epoch 102/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6282 - accuracy: 0.7811\n",
      "Epoch 00102: val_accuracy did not improve from 0.75848\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6282 - accuracy: 0.7811 - val_loss: 0.7524 - val_accuracy: 0.7528\n",
      "Epoch 103/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6148 - accuracy: 0.7889\n",
      "Epoch 00103: val_accuracy did not improve from 0.75848\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6148 - accuracy: 0.7889 - val_loss: 0.7911 - val_accuracy: 0.7527\n",
      "Epoch 104/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6041 - accuracy: 0.7869\n",
      "Epoch 00104: val_accuracy did not improve from 0.75848\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6041 - accuracy: 0.7869 - val_loss: 0.8459 - val_accuracy: 0.7395\n",
      "Epoch 105/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6184 - accuracy: 0.7800 ETA: 0s - loss: 0.618\n",
      "Epoch 00105: val_accuracy did not improve from 0.75848\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6184 - accuracy: 0.7800 - val_loss: 0.8451 - val_accuracy: 0.7399\n",
      "Epoch 106/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6268 - accuracy: 0.7799\n",
      "Epoch 00106: val_accuracy did not improve from 0.75848\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6269 - accuracy: 0.7799 - val_loss: 0.7649 - val_accuracy: 0.7550\n",
      "Epoch 107/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6286 - accuracy: 0.7814\n",
      "Epoch 00107: val_accuracy did not improve from 0.75848\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6285 - accuracy: 0.7813 - val_loss: 0.7395 - val_accuracy: 0.7573\n",
      "Epoch 108/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6016 - accuracy: 0.7876\n",
      "Epoch 00108: val_accuracy did not improve from 0.75848\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6012 - accuracy: 0.7876 - val_loss: 0.8157 - val_accuracy: 0.7423\n",
      "Epoch 109/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6045 - accuracy: 0.7885\n",
      "Epoch 00109: val_accuracy did not improve from 0.75848\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6045 - accuracy: 0.7885 - val_loss: 0.8110 - val_accuracy: 0.7488\n",
      "Epoch 110/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6169 - accuracy: 0.7858\n",
      "Epoch 00110: val_accuracy did not improve from 0.75848\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6168 - accuracy: 0.7859 - val_loss: 0.8511 - val_accuracy: 0.7390\n",
      "Epoch 111/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6266 - accuracy: 0.7840\n",
      "Epoch 00111: val_accuracy improved from 0.75848 to 0.76352, saving model to C:/Users/mb207/Desktop/py/save/CNN.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/CNN.ckpt\\assets\n",
      "500/500 [==============================] - 18s 35ms/step - loss: 0.6260 - accuracy: 0.7841 - val_loss: 0.7158 - val_accuracy: 0.7635\n",
      "Epoch 112/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6223 - accuracy: 0.7801\n",
      "Epoch 00112: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6221 - accuracy: 0.7801 - val_loss: 0.8298 - val_accuracy: 0.7435\n",
      "Epoch 113/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6020 - accuracy: 0.7928\n",
      "Epoch 00113: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 16s 31ms/step - loss: 0.6022 - accuracy: 0.7927 - val_loss: 0.7613 - val_accuracy: 0.7580\n",
      "Epoch 114/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6061 - accuracy: 0.7898 ETA: 0s - loss: 0.6058 - accuracy: 0.79\n",
      "Epoch 00114: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6061 - accuracy: 0.7898 - val_loss: 0.7971 - val_accuracy: 0.7502\n",
      "Epoch 115/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.5844 - accuracy: 0.7975\n",
      "Epoch 00115: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.5845 - accuracy: 0.7973 - val_loss: 0.7867 - val_accuracy: 0.7568\n",
      "Epoch 116/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6013 - accuracy: 0.7910\n",
      "Epoch 00116: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6018 - accuracy: 0.7908 - val_loss: 0.7362 - val_accuracy: 0.7597\n",
      "Epoch 117/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5932 - accuracy: 0.7956\n",
      "Epoch 00117: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.5932 - accuracy: 0.7956 - val_loss: 0.7521 - val_accuracy: 0.7593\n",
      "Epoch 118/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.5949 - accuracy: 0.7917\n",
      "Epoch 00118: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 14s 28ms/step - loss: 0.5945 - accuracy: 0.7919 - val_loss: 0.7426 - val_accuracy: 0.7598\n",
      "Epoch 119/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5996 - accuracy: 0.7933\n",
      "Epoch 00119: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.5996 - accuracy: 0.7933 - val_loss: 0.7600 - val_accuracy: 0.7518\n",
      "Epoch 120/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5973 - accuracy: 0.7910\n",
      "Epoch 00120: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 0.5973 - accuracy: 0.7910 - val_loss: 0.7712 - val_accuracy: 0.7469\n",
      "Epoch 121/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.5931 - accuracy: 0.7911\n",
      "Epoch 00121: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 17s 34ms/step - loss: 0.5932 - accuracy: 0.7910 - val_loss: 0.7727 - val_accuracy: 0.7512\n",
      "Epoch 122/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.5751 - accuracy: 0.8007\n",
      "Epoch 00122: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 17s 34ms/step - loss: 0.5752 - accuracy: 0.8007 - val_loss: 0.7717 - val_accuracy: 0.7532\n",
      "Epoch 123/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.5929 - accuracy: 0.7955\n",
      "Epoch 00123: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 17s 34ms/step - loss: 0.5926 - accuracy: 0.7956 - val_loss: 0.7922 - val_accuracy: 0.7555\n",
      "Epoch 124/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6088 - accuracy: 0.7903\n",
      "Epoch 00124: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 0.6084 - accuracy: 0.7905 - val_loss: 0.7518 - val_accuracy: 0.7593\n",
      "Epoch 125/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.5853 - accuracy: 0.7981 ETA\n",
      "Epoch 00125: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 17s 34ms/step - loss: 0.5858 - accuracy: 0.7981 - val_loss: 0.7858 - val_accuracy: 0.7548\n",
      "Epoch 126/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5844 - accuracy: 0.7951\n",
      "Epoch 00126: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 0.5844 - accuracy: 0.7951 - val_loss: 0.7418 - val_accuracy: 0.7581\n",
      "Epoch 127/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5881 - accuracy: 0.7950\n",
      "Epoch 00127: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.5881 - accuracy: 0.7950 - val_loss: 0.8331 - val_accuracy: 0.7458\n",
      "Epoch 128/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5892 - accuracy: 0.7958\n",
      "Epoch 00128: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 15s 31ms/step - loss: 0.5892 - accuracy: 0.7958 - val_loss: 0.7625 - val_accuracy: 0.7573\n",
      "Epoch 129/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.5771 - accuracy: 0.7997\n",
      "Epoch 00129: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 0.5768 - accuracy: 0.7999 - val_loss: 0.7658 - val_accuracy: 0.7599\n",
      "Epoch 130/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.5881 - accuracy: 0.7993\n",
      "Epoch 00130: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.5879 - accuracy: 0.7993 - val_loss: 0.7730 - val_accuracy: 0.7570\n",
      "Epoch 131/500\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.5692 - accuracy: 0.8036\n",
      "Epoch 00131: val_accuracy did not improve from 0.76352\n",
      "500/500 [==============================] - 17s 33ms/step - loss: 0.5702 - accuracy: 0.8038 - val_loss: 0.7791 - val_accuracy: 0.7575\n"
     ]
    }
   ],
   "source": [
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.fit(x_img_train_normalize, y_label_train_OneHot, epochs=10, batch_size=64, verbose=1)\n",
    "history = model.fit_generator(X_train,y_train,batch_size=20, \n",
    "                               epochs=500,\n",
    "                              validation_data=(X_test,y_test),callbacks=[earlystopping,callback_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.7862 - accuracy: 0.7646\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_img_test_normalize, y_label_test_OneHot)\n",
    "pred = model.predict(x_img_test_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.7862 - accuracy: 0.7646\n",
      "Loss: 0.7862129211425781\n",
      "Accuracy: 0.7645999789237976\n",
      "predict accurscy: 0.7646, precision: 0.7635471086549634, recall: 0.7646, f1 : 0.7602243628285221\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model.load_weights('py/mango')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(x_img_test_normalize,y_label_test_OneHot)\n",
    "pred_cy = model.predict_classes(x_img_test_normalize)\n",
    "\n",
    "precision = precision_score(y_label_test, pred_cy, average='macro')\n",
    "recall = recall_score(y_label_test, pred_cy, average='macro')\n",
    "acc = accuracy_score(y_label_test, pred_cy)\n",
    "f1 = f1_score(y_label_test, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1 : {f1}')\n",
    "plot_acc(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = InceptionResNetV2(include_top=False, input_tensor=None,weights=\"imagenet\",\n",
    "#                 input_shape=(32,32,3))\n",
    "# x = net.output\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "# #  DropOut layer\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "# output_layer = Dense(10, activation='softmax', name='softmax')(x)\n",
    "# model = Model(inputs=net.input, outputs=output_layer)\n",
    "# model.compile(optimizer=Adam(lr=1e-5),\n",
    "#                   loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20)\n",
    "# callback_save = keras.callbacks.ModelCheckpoint(filepath='C:/Users/mb207/Desktop/py/save/InceptionResNetV2.ckpt', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(X_train,y_train,batch_size=20, \n",
    "                               epochs=500,\n",
    "                              validation_data=(X_test,y_test),callbacks=[earlystopping,callback_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_img_test_normalize, y_label_test_OneHot)\n",
    "pred = model.predict(x_img_test_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy=model.evaluate(x_img_test_normalize,y_label_test_OneHot)\n",
    "pred_cy = model.predict_classes(x_img_test_normalize)\n",
    "\n",
    "precision = precision_score(y_label_test, pred_cy, average='macro')\n",
    "recall = recall_score(y_label_test, pred_cy, average='macro')\n",
    "acc = accuracy_score(y_label_test, pred_cy)\n",
    "f1 = f1_score(y_label_test, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1 : {f1}')\n",
    "plot_acc(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 256)          524544      flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 256)          0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 512)          131584      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 10)           5130        dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,248,970\n",
      "Trainable params: 24,195,850\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "net = ResNet50(include_top=False, input_tensor=None,weights=\"imagenet\",\n",
    "                input_shape=(32,32,3))\n",
    "x = net.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "#  DropOut layer\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "output_layer = Dense(10, activation='softmax', name='softmax')(x)\n",
    "model = Model(inputs=net.input, outputs=output_layer)\n",
    "model.compile(optimizer=Adam(lr=1e-5),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20)\n",
    "callback_save = keras.callbacks.ModelCheckpoint(filepath='C:/Users/mb207/Desktop/py/save/Resnet50.ckpt', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 2.6811 - accuracy: 0.1212\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.10248, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 91s 183ms/step - loss: 2.6811 - accuracy: 0.1212 - val_loss: 81.8923 - val_accuracy: 0.1025\n",
      "Epoch 2/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 2.3676 - accuracy: 0.1692\n",
      "Epoch 00002: val_accuracy improved from 0.10248 to 0.21048, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 2.3676 - accuracy: 0.1692 - val_loss: 2.2523 - val_accuracy: 0.2105\n",
      "Epoch 3/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 2.2059 - accuracy: 0.2193\n",
      "Epoch 00003: val_accuracy improved from 0.21048 to 0.30576, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 2.2059 - accuracy: 0.2193 - val_loss: 1.9958 - val_accuracy: 0.3058\n",
      "Epoch 4/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 2.0706 - accuracy: 0.2593\n",
      "Epoch 00004: val_accuracy improved from 0.30576 to 0.35261, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 89s 178ms/step - loss: 2.0706 - accuracy: 0.2593 - val_loss: 1.8577 - val_accuracy: 0.3526\n",
      "Epoch 5/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.9386 - accuracy: 0.3053\n",
      "Epoch 00005: val_accuracy improved from 0.35261 to 0.39339, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 88s 177ms/step - loss: 1.9386 - accuracy: 0.3053 - val_loss: 1.7453 - val_accuracy: 0.3934\n",
      "Epoch 6/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.8690 - accuracy: 0.3461\n",
      "Epoch 00006: val_accuracy improved from 0.39339 to 0.42830, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 1.8690 - accuracy: 0.3461 - val_loss: 1.6523 - val_accuracy: 0.4283\n",
      "Epoch 7/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.7844 - accuracy: 0.3676\n",
      "Epoch 00007: val_accuracy improved from 0.42830 to 0.46436, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 84s 168ms/step - loss: 1.7844 - accuracy: 0.3676 - val_loss: 1.5607 - val_accuracy: 0.4644\n",
      "Epoch 8/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.7135 - accuracy: 0.3911 ETA: 0s - loss: 1.7\n",
      "Epoch 00008: val_accuracy improved from 0.46436 to 0.49358, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 1.7135 - accuracy: 0.3911 - val_loss: 1.4848 - val_accuracy: 0.4936\n",
      "Epoch 9/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.6571 - accuracy: 0.4202\n",
      "Epoch 00009: val_accuracy improved from 0.49358 to 0.51024, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 1.6571 - accuracy: 0.4202 - val_loss: 1.4349 - val_accuracy: 0.5102\n",
      "Epoch 10/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.6029 - accuracy: 0.4407\n",
      "Epoch 00010: val_accuracy improved from 0.51024 to 0.52352, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 1.6029 - accuracy: 0.4407 - val_loss: 1.3786 - val_accuracy: 0.5235\n",
      "Epoch 11/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.5406 - accuracy: 0.4610\n",
      "Epoch 00011: val_accuracy improved from 0.52352 to 0.54545, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 84s 169ms/step - loss: 1.5406 - accuracy: 0.4610 - val_loss: 1.3298 - val_accuracy: 0.5455\n",
      "Epoch 12/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.5233 - accuracy: 0.4703\n",
      "Epoch 00012: val_accuracy improved from 0.54545 to 0.55206, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 87s 175ms/step - loss: 1.5233 - accuracy: 0.4703 - val_loss: 1.2996 - val_accuracy: 0.5521\n",
      "Epoch 13/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.4854 - accuracy: 0.4823\n",
      "Epoch 00013: val_accuracy improved from 0.55206 to 0.56830, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 85s 170ms/step - loss: 1.4854 - accuracy: 0.4823 - val_loss: 1.2538 - val_accuracy: 0.5683\n",
      "Epoch 14/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.4191 - accuracy: 0.5087\n",
      "Epoch 00014: val_accuracy improved from 0.56830 to 0.58333, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 89s 178ms/step - loss: 1.4191 - accuracy: 0.5087 - val_loss: 1.2132 - val_accuracy: 0.5833\n",
      "Epoch 15/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.3960 - accuracy: 0.5171\n",
      "Epoch 00015: val_accuracy improved from 0.58333 to 0.59491, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 94s 189ms/step - loss: 1.3960 - accuracy: 0.5171 - val_loss: 1.1872 - val_accuracy: 0.5949\n",
      "Epoch 16/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.3541 - accuracy: 0.5321\n",
      "Epoch 00016: val_accuracy improved from 0.59491 to 0.60527, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 94s 187ms/step - loss: 1.3541 - accuracy: 0.5321 - val_loss: 1.1585 - val_accuracy: 0.6053\n",
      "Epoch 17/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.3547 - accuracy: 0.5364\n",
      "Epoch 00017: val_accuracy improved from 0.60527 to 0.61291, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 1.3547 - accuracy: 0.5364 - val_loss: 1.1350 - val_accuracy: 0.6129\n",
      "Epoch 18/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.3052 - accuracy: 0.5523\n",
      "Epoch 00018: val_accuracy improved from 0.61291 to 0.62412, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 91s 182ms/step - loss: 1.3052 - accuracy: 0.5523 - val_loss: 1.0916 - val_accuracy: 0.6241\n",
      "Epoch 19/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.2836 - accuracy: 0.5561\n",
      "Epoch 00019: val_accuracy improved from 0.62412 to 0.63648, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 91s 181ms/step - loss: 1.2836 - accuracy: 0.5561 - val_loss: 1.0639 - val_accuracy: 0.6365\n",
      "Epoch 20/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.2652 - accuracy: 0.5643\n",
      "Epoch 00020: val_accuracy improved from 0.63648 to 0.64552, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 1.2652 - accuracy: 0.5643 - val_loss: 1.0409 - val_accuracy: 0.6455\n",
      "Epoch 21/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.2228 - accuracy: 0.5752\n",
      "Epoch 00021: val_accuracy improved from 0.64552 to 0.65145, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 89s 178ms/step - loss: 1.2228 - accuracy: 0.5752 - val_loss: 1.0199 - val_accuracy: 0.6515\n",
      "Epoch 22/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.2319 - accuracy: 0.5779\n",
      "Epoch 00022: val_accuracy improved from 0.65145 to 0.65497, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 1.2319 - accuracy: 0.5779 - val_loss: 0.9996 - val_accuracy: 0.6550\n",
      "Epoch 23/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.2004 - accuracy: 0.5887\n",
      "Epoch 00023: val_accuracy improved from 0.65497 to 0.66309, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 90s 181ms/step - loss: 1.2004 - accuracy: 0.5887 - val_loss: 0.9824 - val_accuracy: 0.6631\n",
      "Epoch 24/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.1758 - accuracy: 0.5958\n",
      "Epoch 00024: val_accuracy improved from 0.66309 to 0.66758, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 93s 187ms/step - loss: 1.1758 - accuracy: 0.5958 - val_loss: 0.9730 - val_accuracy: 0.6676\n",
      "Epoch 25/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.1477 - accuracy: 0.6113\n",
      "Epoch 00025: val_accuracy improved from 0.66758 to 0.68103, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 1.1477 - accuracy: 0.6113 - val_loss: 0.9436 - val_accuracy: 0.6810\n",
      "Epoch 26/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.1420 - accuracy: 0.6156\n",
      "Epoch 00026: val_accuracy did not improve from 0.68103\n",
      "500/500 [==============================] - 40s 79ms/step - loss: 1.1420 - accuracy: 0.6156 - val_loss: 0.9381 - val_accuracy: 0.6792\n",
      "Epoch 27/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.1067 - accuracy: 0.6195\n",
      "Epoch 00027: val_accuracy improved from 0.68103 to 0.68764, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 99s 198ms/step - loss: 1.1067 - accuracy: 0.6195 - val_loss: 0.9050 - val_accuracy: 0.6876\n",
      "Epoch 28/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.1046 - accuracy: 0.6268\n",
      "Epoch 00028: val_accuracy improved from 0.68764 to 0.69261, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 100s 200ms/step - loss: 1.1046 - accuracy: 0.6268 - val_loss: 0.8962 - val_accuracy: 0.6926\n",
      "Epoch 29/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0935 - accuracy: 0.6307\n",
      "Epoch 00029: val_accuracy improved from 0.69261 to 0.69424, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 94s 188ms/step - loss: 1.0935 - accuracy: 0.6307 - val_loss: 0.8921 - val_accuracy: 0.6942\n",
      "Epoch 30/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0680 - accuracy: 0.6373\n",
      "Epoch 00030: val_accuracy improved from 0.69424 to 0.70133, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 88s 176ms/step - loss: 1.0680 - accuracy: 0.6373 - val_loss: 0.8838 - val_accuracy: 0.7013\n",
      "Epoch 31/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0723 - accuracy: 0.6316\n",
      "Epoch 00031: val_accuracy improved from 0.70133 to 0.70406, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 89s 178ms/step - loss: 1.0723 - accuracy: 0.6316 - val_loss: 0.8707 - val_accuracy: 0.7041\n",
      "Epoch 32/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0588 - accuracy: 0.6443\n",
      "Epoch 00032: val_accuracy improved from 0.70406 to 0.70964, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 96s 193ms/step - loss: 1.0588 - accuracy: 0.6443 - val_loss: 0.8562 - val_accuracy: 0.7096\n",
      "Epoch 33/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0399 - accuracy: 0.6469\n",
      "Epoch 00033: val_accuracy improved from 0.70964 to 0.71358, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 96s 192ms/step - loss: 1.0399 - accuracy: 0.6469 - val_loss: 0.8414 - val_accuracy: 0.7136\n",
      "Epoch 34/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0261 - accuracy: 0.6490\n",
      "Epoch 00034: val_accuracy improved from 0.71358 to 0.71733, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 94s 187ms/step - loss: 1.0261 - accuracy: 0.6490 - val_loss: 0.8293 - val_accuracy: 0.7173\n",
      "Epoch 35/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0136 - accuracy: 0.6535\n",
      "Epoch 00035: val_accuracy improved from 0.71733 to 0.72267, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 102s 204ms/step - loss: 1.0136 - accuracy: 0.6535 - val_loss: 0.8166 - val_accuracy: 0.7227\n",
      "Epoch 36/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0021 - accuracy: 0.6584\n",
      "Epoch 00036: val_accuracy improved from 0.72267 to 0.72552, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 96s 192ms/step - loss: 1.0021 - accuracy: 0.6584 - val_loss: 0.8054 - val_accuracy: 0.7255\n",
      "Epoch 37/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0024 - accuracy: 0.6627\n",
      "Epoch 00037: val_accuracy improved from 0.72552 to 0.73000, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 85s 171ms/step - loss: 1.0024 - accuracy: 0.6627 - val_loss: 0.7962 - val_accuracy: 0.7300\n",
      "Epoch 38/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9789 - accuracy: 0.6746\n",
      "Epoch 00038: val_accuracy improved from 0.73000 to 0.73091, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 83s 166ms/step - loss: 0.9789 - accuracy: 0.6746 - val_loss: 0.7977 - val_accuracy: 0.7309\n",
      "Epoch 39/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9608 - accuracy: 0.6757\n",
      "Epoch 00039: val_accuracy improved from 0.73091 to 0.73739, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 89s 178ms/step - loss: 0.9608 - accuracy: 0.6757 - val_loss: 0.7715 - val_accuracy: 0.7374\n",
      "Epoch 40/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9615 - accuracy: 0.6804\n",
      "Epoch 00040: val_accuracy improved from 0.73739 to 0.74085, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 0.9615 - accuracy: 0.6804 - val_loss: 0.7702 - val_accuracy: 0.7408\n",
      "Epoch 41/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9339 - accuracy: 0.6829\n",
      "Epoch 00041: val_accuracy improved from 0.74085 to 0.74212, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 82s 164ms/step - loss: 0.9339 - accuracy: 0.6829 - val_loss: 0.7624 - val_accuracy: 0.7421\n",
      "Epoch 42/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9275 - accuracy: 0.6872\n",
      "Epoch 00042: val_accuracy did not improve from 0.74212\n",
      "500/500 [==============================] - 38s 77ms/step - loss: 0.9275 - accuracy: 0.6872 - val_loss: 0.7604 - val_accuracy: 0.7385\n",
      "Epoch 43/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9227 - accuracy: 0.6924\n",
      "Epoch 00043: val_accuracy improved from 0.74212 to 0.74448, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 80s 160ms/step - loss: 0.9227 - accuracy: 0.6924 - val_loss: 0.7544 - val_accuracy: 0.7445\n",
      "Epoch 44/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9156 - accuracy: 0.6944\n",
      "Epoch 00044: val_accuracy improved from 0.74448 to 0.74836, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 84s 168ms/step - loss: 0.9156 - accuracy: 0.6944 - val_loss: 0.7433 - val_accuracy: 0.7484\n",
      "Epoch 45/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9113 - accuracy: 0.6910\n",
      "Epoch 00045: val_accuracy improved from 0.74836 to 0.74976, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 83s 165ms/step - loss: 0.9113 - accuracy: 0.6910 - val_loss: 0.7366 - val_accuracy: 0.7498\n",
      "Epoch 46/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8867 - accuracy: 0.6997\n",
      "Epoch 00046: val_accuracy improved from 0.74976 to 0.75188, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 0.8867 - accuracy: 0.6997 - val_loss: 0.7318 - val_accuracy: 0.7519\n",
      "Epoch 47/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9068 - accuracy: 0.6991\n",
      "Epoch 00047: val_accuracy did not improve from 0.75188\n",
      "500/500 [==============================] - 38s 75ms/step - loss: 0.9068 - accuracy: 0.6991 - val_loss: 0.7224 - val_accuracy: 0.7518\n",
      "Epoch 48/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8694 - accuracy: 0.7085\n",
      "Epoch 00048: val_accuracy improved from 0.75188 to 0.75552, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 81s 162ms/step - loss: 0.8694 - accuracy: 0.7085 - val_loss: 0.7195 - val_accuracy: 0.7555\n",
      "Epoch 49/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8562 - accuracy: 0.7092\n",
      "Epoch 00049: val_accuracy improved from 0.75552 to 0.75903, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 85s 169ms/step - loss: 0.8562 - accuracy: 0.7092 - val_loss: 0.7114 - val_accuracy: 0.7590\n",
      "Epoch 50/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8700 - accuracy: 0.7096\n",
      "Epoch 00050: val_accuracy improved from 0.75903 to 0.75964, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 84s 167ms/step - loss: 0.8700 - accuracy: 0.7096 - val_loss: 0.7115 - val_accuracy: 0.7596\n",
      "Epoch 51/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8371 - accuracy: 0.7146\n",
      "Epoch 00051: val_accuracy improved from 0.75964 to 0.76012, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 94s 187ms/step - loss: 0.8371 - accuracy: 0.7146 - val_loss: 0.7150 - val_accuracy: 0.7601\n",
      "Epoch 52/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8430 - accuracy: 0.7128\n",
      "Epoch 00052: val_accuracy improved from 0.76012 to 0.76333, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 0.8430 - accuracy: 0.7128 - val_loss: 0.7055 - val_accuracy: 0.7633\n",
      "Epoch 53/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8433 - accuracy: 0.7115\n",
      "Epoch 00053: val_accuracy improved from 0.76333 to 0.76812, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 84s 168ms/step - loss: 0.8433 - accuracy: 0.7115 - val_loss: 0.6957 - val_accuracy: 0.7681\n",
      "Epoch 54/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8251 - accuracy: 0.7240\n",
      "Epoch 00054: val_accuracy improved from 0.76812 to 0.77158, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 94s 188ms/step - loss: 0.8251 - accuracy: 0.7240 - val_loss: 0.6865 - val_accuracy: 0.7716\n",
      "Epoch 55/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8139 - accuracy: 0.7239\n",
      "Epoch 00055: val_accuracy did not improve from 0.77158\n",
      "500/500 [==============================] - 39s 78ms/step - loss: 0.8139 - accuracy: 0.7239 - val_loss: 0.6841 - val_accuracy: 0.7709\n",
      "Epoch 56/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8115 - accuracy: 0.7228\n",
      "Epoch 00056: val_accuracy did not improve from 0.77158\n",
      "500/500 [==============================] - 39s 78ms/step - loss: 0.8115 - accuracy: 0.7228 - val_loss: 0.6856 - val_accuracy: 0.7706\n",
      "Epoch 57/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8129 - accuracy: 0.7245\n",
      "Epoch 00057: val_accuracy improved from 0.77158 to 0.77467, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 88s 177ms/step - loss: 0.8129 - accuracy: 0.7245 - val_loss: 0.6776 - val_accuracy: 0.7747\n",
      "Epoch 58/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7939 - accuracy: 0.7277\n",
      "Epoch 00058: val_accuracy did not improve from 0.77467\n",
      "500/500 [==============================] - 44s 88ms/step - loss: 0.7939 - accuracy: 0.7277 - val_loss: 0.6755 - val_accuracy: 0.7734\n",
      "Epoch 59/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8042 - accuracy: 0.7313\n",
      "Epoch 00059: val_accuracy improved from 0.77467 to 0.77576, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 106s 212ms/step - loss: 0.8042 - accuracy: 0.7313 - val_loss: 0.6741 - val_accuracy: 0.7758\n",
      "Epoch 60/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7998 - accuracy: 0.7309\n",
      "Epoch 00060: val_accuracy improved from 0.77576 to 0.77594, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 101s 203ms/step - loss: 0.7998 - accuracy: 0.7309 - val_loss: 0.6688 - val_accuracy: 0.7759\n",
      "Epoch 61/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7712 - accuracy: 0.7401\n",
      "Epoch 00061: val_accuracy improved from 0.77594 to 0.78030, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 101s 202ms/step - loss: 0.7712 - accuracy: 0.7401 - val_loss: 0.6630 - val_accuracy: 0.7803\n",
      "Epoch 62/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7700 - accuracy: 0.7458\n",
      "Epoch 00062: val_accuracy improved from 0.78030 to 0.78455, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 97s 193ms/step - loss: 0.7700 - accuracy: 0.7458 - val_loss: 0.6519 - val_accuracy: 0.7845\n",
      "Epoch 63/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7752 - accuracy: 0.7388\n",
      "Epoch 00063: val_accuracy did not improve from 0.78455\n",
      "500/500 [==============================] - 42s 83ms/step - loss: 0.7752 - accuracy: 0.7388 - val_loss: 0.6464 - val_accuracy: 0.7835\n",
      "Epoch 64/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7625 - accuracy: 0.7433\n",
      "Epoch 00064: val_accuracy improved from 0.78455 to 0.78533, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 107s 214ms/step - loss: 0.7625 - accuracy: 0.7433 - val_loss: 0.6421 - val_accuracy: 0.7853\n",
      "Epoch 65/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7317 - accuracy: 0.7530\n",
      "Epoch 00065: val_accuracy improved from 0.78533 to 0.78558, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 120s 240ms/step - loss: 0.7317 - accuracy: 0.7530 - val_loss: 0.6421 - val_accuracy: 0.7856\n",
      "Epoch 66/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7504 - accuracy: 0.7431\n",
      "Epoch 00066: val_accuracy did not improve from 0.78558\n",
      "500/500 [==============================] - 52s 105ms/step - loss: 0.7504 - accuracy: 0.7431 - val_loss: 0.6415 - val_accuracy: 0.7850\n",
      "Epoch 67/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7507 - accuracy: 0.7462\n",
      "Epoch 00067: val_accuracy did not improve from 0.78558\n",
      "500/500 [==============================] - 49s 98ms/step - loss: 0.7507 - accuracy: 0.7462 - val_loss: 0.6388 - val_accuracy: 0.7850\n",
      "Epoch 68/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7284 - accuracy: 0.7550\n",
      "Epoch 00068: val_accuracy improved from 0.78558 to 0.79164, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 122s 245ms/step - loss: 0.7284 - accuracy: 0.7550 - val_loss: 0.6258 - val_accuracy: 0.7916\n",
      "Epoch 69/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7397 - accuracy: 0.7521\n",
      "Epoch 00069: val_accuracy improved from 0.79164 to 0.79255, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 126s 251ms/step - loss: 0.7397 - accuracy: 0.7521 - val_loss: 0.6297 - val_accuracy: 0.7925\n",
      "Epoch 70/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7237 - accuracy: 0.7573\n",
      "Epoch 00070: val_accuracy did not improve from 0.79255\n",
      "500/500 [==============================] - 51s 102ms/step - loss: 0.7237 - accuracy: 0.7573 - val_loss: 0.6279 - val_accuracy: 0.7920\n",
      "Epoch 71/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7346 - accuracy: 0.7541\n",
      "Epoch 00071: val_accuracy did not improve from 0.79255\n",
      "500/500 [==============================] - 50s 99ms/step - loss: 0.7346 - accuracy: 0.7541 - val_loss: 0.6220 - val_accuracy: 0.7924\n",
      "Epoch 72/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7190 - accuracy: 0.7612\n",
      "Epoch 00072: val_accuracy did not improve from 0.79255\n",
      "500/500 [==============================] - 49s 97ms/step - loss: 0.7190 - accuracy: 0.7612 - val_loss: 0.6200 - val_accuracy: 0.7916\n",
      "Epoch 73/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7020 - accuracy: 0.7657\n",
      "Epoch 00073: val_accuracy improved from 0.79255 to 0.79564, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 119s 238ms/step - loss: 0.7020 - accuracy: 0.7657 - val_loss: 0.6120 - val_accuracy: 0.7956\n",
      "Epoch 74/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7104 - accuracy: 0.7644\n",
      "Epoch 00074: val_accuracy did not improve from 0.79564\n",
      "500/500 [==============================] - 51s 103ms/step - loss: 0.7104 - accuracy: 0.7644 - val_loss: 0.6193 - val_accuracy: 0.7953\n",
      "Epoch 75/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6971 - accuracy: 0.7724\n",
      "Epoch 00075: val_accuracy improved from 0.79564 to 0.79624, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 115s 229ms/step - loss: 0.6971 - accuracy: 0.7724 - val_loss: 0.6185 - val_accuracy: 0.7962\n",
      "Epoch 76/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6728 - accuracy: 0.7718\n",
      "Epoch 00076: val_accuracy did not improve from 0.79624\n",
      "500/500 [==============================] - 51s 101ms/step - loss: 0.6728 - accuracy: 0.7718 - val_loss: 0.6251 - val_accuracy: 0.7950\n",
      "Epoch 77/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6704 - accuracy: 0.7713\n",
      "Epoch 00077: val_accuracy improved from 0.79624 to 0.79715, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 122s 244ms/step - loss: 0.6704 - accuracy: 0.7713 - val_loss: 0.6161 - val_accuracy: 0.7972\n",
      "Epoch 78/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6891 - accuracy: 0.7751\n",
      "Epoch 00078: val_accuracy did not improve from 0.79715\n",
      "500/500 [==============================] - 50s 100ms/step - loss: 0.6891 - accuracy: 0.7751 - val_loss: 0.6162 - val_accuracy: 0.7939\n",
      "Epoch 79/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6607 - accuracy: 0.7733\n",
      "Epoch 00079: val_accuracy improved from 0.79715 to 0.79903, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 122s 244ms/step - loss: 0.6607 - accuracy: 0.7733 - val_loss: 0.5996 - val_accuracy: 0.7990\n",
      "Epoch 80/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6800 - accuracy: 0.7744\n",
      "Epoch 00080: val_accuracy did not improve from 0.79903\n",
      "500/500 [==============================] - 50s 100ms/step - loss: 0.6800 - accuracy: 0.7744 - val_loss: 0.6060 - val_accuracy: 0.7978\n",
      "Epoch 81/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6679 - accuracy: 0.7737 ETA: 3s - loss: 0.6717 - accura - ETA: 2s - loss: 0.6 - ETA: 1s - ETA: 0s - loss: 0.6681 - accuracy\n",
      "Epoch 00081: val_accuracy improved from 0.79903 to 0.80103, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 113s 226ms/step - loss: 0.6679 - accuracy: 0.7737 - val_loss: 0.6005 - val_accuracy: 0.8010\n",
      "Epoch 82/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6584 - accuracy: 0.7741\n",
      "Epoch 00082: val_accuracy did not improve from 0.80103\n",
      "500/500 [==============================] - 41s 81ms/step - loss: 0.6584 - accuracy: 0.7741 - val_loss: 0.6002 - val_accuracy: 0.7996\n",
      "Epoch 83/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6474 - accuracy: 0.7811\n",
      "Epoch 00083: val_accuracy did not improve from 0.80103\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.6474 - accuracy: 0.7811 - val_loss: 0.6021 - val_accuracy: 0.7982\n",
      "Epoch 84/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6346 - accuracy: 0.7848\n",
      "Epoch 00084: val_accuracy did not improve from 0.80103\n",
      "500/500 [==============================] - 39s 78ms/step - loss: 0.6346 - accuracy: 0.7848 - val_loss: 0.5981 - val_accuracy: 0.8003\n",
      "Epoch 85/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6295 - accuracy: 0.7865\n",
      "Epoch 00085: val_accuracy improved from 0.80103 to 0.80388, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 90s 181ms/step - loss: 0.6295 - accuracy: 0.7865 - val_loss: 0.5900 - val_accuracy: 0.8039\n",
      "Epoch 86/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6201 - accuracy: 0.7896\n",
      "Epoch 00086: val_accuracy did not improve from 0.80388\n",
      "500/500 [==============================] - 39s 79ms/step - loss: 0.6201 - accuracy: 0.7896 - val_loss: 0.5992 - val_accuracy: 0.8028\n",
      "Epoch 87/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6323 - accuracy: 0.7858\n",
      "Epoch 00087: val_accuracy improved from 0.80388 to 0.80400, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.6323 - accuracy: 0.7858 - val_loss: 0.5939 - val_accuracy: 0.8040\n",
      "Epoch 88/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.7858\n",
      "Epoch 00088: val_accuracy improved from 0.80400 to 0.80685, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.6367 - accuracy: 0.7858 - val_loss: 0.5846 - val_accuracy: 0.8068\n",
      "Epoch 89/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6208 - accuracy: 0.7904\n",
      "Epoch 00089: val_accuracy did not improve from 0.80685\n",
      "500/500 [==============================] - 39s 78ms/step - loss: 0.6208 - accuracy: 0.7904 - val_loss: 0.5855 - val_accuracy: 0.8066\n",
      "Epoch 90/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6093 - accuracy: 0.7946\n",
      "Epoch 00090: val_accuracy improved from 0.80685 to 0.80733, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 83s 166ms/step - loss: 0.6093 - accuracy: 0.7946 - val_loss: 0.5856 - val_accuracy: 0.8073\n",
      "Epoch 91/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6097 - accuracy: 0.7936\n",
      "Epoch 00091: val_accuracy improved from 0.80733 to 0.81042, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.6097 - accuracy: 0.7936 - val_loss: 0.5745 - val_accuracy: 0.8104\n",
      "Epoch 92/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6193 - accuracy: 0.7898\n",
      "Epoch 00092: val_accuracy did not improve from 0.81042\n",
      "500/500 [==============================] - 39s 77ms/step - loss: 0.6193 - accuracy: 0.7898 - val_loss: 0.5869 - val_accuracy: 0.8053\n",
      "Epoch 93/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6037 - accuracy: 0.7960\n",
      "Epoch 00093: val_accuracy did not improve from 0.81042\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6037 - accuracy: 0.7960 - val_loss: 0.5795 - val_accuracy: 0.8076\n",
      "Epoch 94/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6023 - accuracy: 0.7932\n",
      "Epoch 00094: val_accuracy did not improve from 0.81042\n",
      "500/500 [==============================] - 39s 77ms/step - loss: 0.6023 - accuracy: 0.7932 - val_loss: 0.5777 - val_accuracy: 0.8096\n",
      "Epoch 95/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6021 - accuracy: 0.7940\n",
      "Epoch 00095: val_accuracy did not improve from 0.81042\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 0.6021 - accuracy: 0.7940 - val_loss: 0.5784 - val_accuracy: 0.8088\n",
      "Epoch 96/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5799 - accuracy: 0.8010\n",
      "Epoch 00096: val_accuracy improved from 0.81042 to 0.81418, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.5799 - accuracy: 0.8010 - val_loss: 0.5705 - val_accuracy: 0.8142\n",
      "Epoch 97/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5761 - accuracy: 0.8081\n",
      "Epoch 00097: val_accuracy did not improve from 0.81418\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.5761 - accuracy: 0.8081 - val_loss: 0.5901 - val_accuracy: 0.8084\n",
      "Epoch 98/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5808 - accuracy: 0.8045\n",
      "Epoch 00098: val_accuracy did not improve from 0.81418\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 0.5808 - accuracy: 0.8045 - val_loss: 0.5686 - val_accuracy: 0.8127\n",
      "Epoch 99/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5718 - accuracy: 0.8037\n",
      "Epoch 00099: val_accuracy improved from 0.81418 to 0.81503, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 81s 163ms/step - loss: 0.5718 - accuracy: 0.8037 - val_loss: 0.5643 - val_accuracy: 0.8150\n",
      "Epoch 100/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5883 - accuracy: 0.8011\n",
      "Epoch 00100: val_accuracy did not improve from 0.81503\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.5883 - accuracy: 0.8011 - val_loss: 0.5611 - val_accuracy: 0.8142\n",
      "Epoch 101/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5583 - accuracy: 0.8083\n",
      "Epoch 00101: val_accuracy did not improve from 0.81503\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.5583 - accuracy: 0.8083 - val_loss: 0.5689 - val_accuracy: 0.8125\n",
      "Epoch 102/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5661 - accuracy: 0.8110\n",
      "Epoch 00102: val_accuracy improved from 0.81503 to 0.81715, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 84s 169ms/step - loss: 0.5661 - accuracy: 0.8110 - val_loss: 0.5639 - val_accuracy: 0.8172\n",
      "Epoch 103/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5725 - accuracy: 0.8061\n",
      "Epoch 00103: val_accuracy did not improve from 0.81715\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.5725 - accuracy: 0.8061 - val_loss: 0.5590 - val_accuracy: 0.8170\n",
      "Epoch 104/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5672 - accuracy: 0.8061\n",
      "Epoch 00104: val_accuracy improved from 0.81715 to 0.81794, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 84s 167ms/step - loss: 0.5672 - accuracy: 0.8061 - val_loss: 0.5561 - val_accuracy: 0.8179\n",
      "Epoch 105/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5550 - accuracy: 0.8116\n",
      "Epoch 00105: val_accuracy did not improve from 0.81794\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.5550 - accuracy: 0.8116 - val_loss: 0.5708 - val_accuracy: 0.8158\n",
      "Epoch 106/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.8151\n",
      "Epoch 00106: val_accuracy did not improve from 0.81794\n",
      "500/500 [==============================] - 39s 78ms/step - loss: 0.5415 - accuracy: 0.8151 - val_loss: 0.5668 - val_accuracy: 0.8153\n",
      "Epoch 107/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5392 - accuracy: 0.8180\n",
      "Epoch 00107: val_accuracy did not improve from 0.81794\n",
      "500/500 [==============================] - 38s 75ms/step - loss: 0.5392 - accuracy: 0.8180 - val_loss: 0.5669 - val_accuracy: 0.8155\n",
      "Epoch 108/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5349 - accuracy: 0.8181\n",
      "Epoch 00108: val_accuracy improved from 0.81794 to 0.81848, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 0.5349 - accuracy: 0.8181 - val_loss: 0.5581 - val_accuracy: 0.8185\n",
      "Epoch 109/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5349 - accuracy: 0.8195\n",
      "Epoch 00109: val_accuracy did not improve from 0.81848\n",
      "500/500 [==============================] - 39s 79ms/step - loss: 0.5349 - accuracy: 0.8195 - val_loss: 0.5611 - val_accuracy: 0.8171\n",
      "Epoch 110/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5434 - accuracy: 0.8124\n",
      "Epoch 00110: val_accuracy did not improve from 0.81848\n",
      "500/500 [==============================] - 39s 77ms/step - loss: 0.5434 - accuracy: 0.8124 - val_loss: 0.5611 - val_accuracy: 0.8182\n",
      "Epoch 111/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5328 - accuracy: 0.8171\n",
      "Epoch 00111: val_accuracy did not improve from 0.81848\n",
      "500/500 [==============================] - 39s 78ms/step - loss: 0.5328 - accuracy: 0.8171 - val_loss: 0.5745 - val_accuracy: 0.8127\n",
      "Epoch 112/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5348 - accuracy: 0.8192\n",
      "Epoch 00112: val_accuracy did not improve from 0.81848\n",
      "500/500 [==============================] - 39s 77ms/step - loss: 0.5348 - accuracy: 0.8192 - val_loss: 0.5581 - val_accuracy: 0.8181\n",
      "Epoch 113/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5108 - accuracy: 0.8238\n",
      "Epoch 00113: val_accuracy improved from 0.81848 to 0.81964, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 99s 198ms/step - loss: 0.5108 - accuracy: 0.8238 - val_loss: 0.5603 - val_accuracy: 0.8196\n",
      "Epoch 114/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5276 - accuracy: 0.8170\n",
      "Epoch 00114: val_accuracy did not improve from 0.81964\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.5276 - accuracy: 0.8170 - val_loss: 0.5697 - val_accuracy: 0.8154\n",
      "Epoch 115/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5220 - accuracy: 0.8231 ETA: 0s - loss: 0.5220 - \n",
      "Epoch 00115: val_accuracy did not improve from 0.81964\n",
      "500/500 [==============================] - 39s 79ms/step - loss: 0.5220 - accuracy: 0.8231 - val_loss: 0.5582 - val_accuracy: 0.8178\n",
      "Epoch 116/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5058 - accuracy: 0.8273\n",
      "Epoch 00116: val_accuracy did not improve from 0.81964\n",
      "500/500 [==============================] - 39s 79ms/step - loss: 0.5058 - accuracy: 0.8273 - val_loss: 0.5564 - val_accuracy: 0.8189\n",
      "Epoch 117/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5088 - accuracy: 0.8283\n",
      "Epoch 00117: val_accuracy did not improve from 0.81964\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.5088 - accuracy: 0.8283 - val_loss: 0.5557 - val_accuracy: 0.8196\n",
      "Epoch 118/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4941 - accuracy: 0.8272\n",
      "Epoch 00118: val_accuracy did not improve from 0.81964\n",
      "500/500 [==============================] - 38s 77ms/step - loss: 0.4941 - accuracy: 0.8272 - val_loss: 0.5614 - val_accuracy: 0.8196\n",
      "Epoch 119/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5045 - accuracy: 0.8314\n",
      "Epoch 00119: val_accuracy improved from 0.81964 to 0.82188, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 84s 167ms/step - loss: 0.5045 - accuracy: 0.8314 - val_loss: 0.5617 - val_accuracy: 0.8219\n",
      "Epoch 120/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5135 - accuracy: 0.8246\n",
      "Epoch 00120: val_accuracy improved from 0.82188 to 0.82194, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 84s 168ms/step - loss: 0.5135 - accuracy: 0.8246 - val_loss: 0.5508 - val_accuracy: 0.8219\n",
      "Epoch 121/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4824 - accuracy: 0.8339\n",
      "Epoch 00121: val_accuracy did not improve from 0.82194\n",
      "500/500 [==============================] - 38s 77ms/step - loss: 0.4824 - accuracy: 0.8339 - val_loss: 0.5531 - val_accuracy: 0.8219\n",
      "Epoch 122/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4914 - accuracy: 0.8366\n",
      "Epoch 00122: val_accuracy did not improve from 0.82194\n",
      "500/500 [==============================] - 39s 78ms/step - loss: 0.4914 - accuracy: 0.8366 - val_loss: 0.5521 - val_accuracy: 0.8218\n",
      "Epoch 123/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4795 - accuracy: 0.8393\n",
      "Epoch 00123: val_accuracy did not improve from 0.82194\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.4795 - accuracy: 0.8393 - val_loss: 0.5602 - val_accuracy: 0.8185\n",
      "Epoch 124/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4974 - accuracy: 0.8274\n",
      "Epoch 00124: val_accuracy improved from 0.82194 to 0.82436, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 90s 179ms/step - loss: 0.4974 - accuracy: 0.8274 - val_loss: 0.5479 - val_accuracy: 0.8244\n",
      "Epoch 125/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4747 - accuracy: 0.8378\n",
      "Epoch 00125: val_accuracy did not improve from 0.82436\n",
      "500/500 [==============================] - 39s 77ms/step - loss: 0.4747 - accuracy: 0.8378 - val_loss: 0.5483 - val_accuracy: 0.8228\n",
      "Epoch 126/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4951 - accuracy: 0.8286\n",
      "Epoch 00126: val_accuracy did not improve from 0.82436\n",
      "500/500 [==============================] - 38s 75ms/step - loss: 0.4951 - accuracy: 0.8286 - val_loss: 0.5493 - val_accuracy: 0.8241\n",
      "Epoch 127/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4728 - accuracy: 0.8371\n",
      "Epoch 00127: val_accuracy did not improve from 0.82436\n",
      "500/500 [==============================] - 39s 78ms/step - loss: 0.4728 - accuracy: 0.8371 - val_loss: 0.5494 - val_accuracy: 0.8240\n",
      "Epoch 128/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4593 - accuracy: 0.8410\n",
      "Epoch 00128: val_accuracy did not improve from 0.82436\n",
      "500/500 [==============================] - 38s 77ms/step - loss: 0.4593 - accuracy: 0.8410 - val_loss: 0.5606 - val_accuracy: 0.8235\n",
      "Epoch 129/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4731 - accuracy: 0.8367\n",
      "Epoch 00129: val_accuracy improved from 0.82436 to 0.82479, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 92s 185ms/step - loss: 0.4731 - accuracy: 0.8367 - val_loss: 0.5477 - val_accuracy: 0.8248\n",
      "Epoch 130/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4647 - accuracy: 0.8381\n",
      "Epoch 00130: val_accuracy improved from 0.82479 to 0.82818, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 110s 220ms/step - loss: 0.4647 - accuracy: 0.8381 - val_loss: 0.5428 - val_accuracy: 0.8282\n",
      "Epoch 131/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4561 - accuracy: 0.8446 ETA: 0s - loss: 0.4559 \n",
      "Epoch 00131: val_accuracy did not improve from 0.82818\n",
      "500/500 [==============================] - 43s 86ms/step - loss: 0.4561 - accuracy: 0.8446 - val_loss: 0.5536 - val_accuracy: 0.8227\n",
      "Epoch 132/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4439 - accuracy: 0.8531\n",
      "Epoch 00132: val_accuracy did not improve from 0.82818\n",
      "500/500 [==============================] - 48s 95ms/step - loss: 0.4439 - accuracy: 0.8531 - val_loss: 0.5453 - val_accuracy: 0.8268\n",
      "Epoch 133/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4519 - accuracy: 0.8495\n",
      "Epoch 00133: val_accuracy did not improve from 0.82818\n",
      "500/500 [==============================] - 51s 102ms/step - loss: 0.4519 - accuracy: 0.8495 - val_loss: 0.5557 - val_accuracy: 0.8235\n",
      "Epoch 134/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4481 - accuracy: 0.8497\n",
      "Epoch 00134: val_accuracy improved from 0.82818 to 0.82915, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 124s 249ms/step - loss: 0.4481 - accuracy: 0.8497 - val_loss: 0.5386 - val_accuracy: 0.8292\n",
      "Epoch 135/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4564 - accuracy: 0.8437\n",
      "Epoch 00135: val_accuracy did not improve from 0.82915\n",
      "500/500 [==============================] - 49s 98ms/step - loss: 0.4564 - accuracy: 0.8437 - val_loss: 0.5501 - val_accuracy: 0.8264\n",
      "Epoch 136/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 0.8502\n",
      "Epoch 00136: val_accuracy did not improve from 0.82915\n",
      "500/500 [==============================] - 49s 98ms/step - loss: 0.4350 - accuracy: 0.8502 - val_loss: 0.5442 - val_accuracy: 0.8270\n",
      "Epoch 137/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.8513\n",
      "Epoch 00137: val_accuracy did not improve from 0.82915\n",
      "500/500 [==============================] - 49s 97ms/step - loss: 0.4416 - accuracy: 0.8513 - val_loss: 0.5400 - val_accuracy: 0.8276\n",
      "Epoch 138/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4352 - accuracy: 0.8548 ETA: 1s - loss:\n",
      "Epoch 00138: val_accuracy did not improve from 0.82915\n",
      "500/500 [==============================] - 49s 98ms/step - loss: 0.4352 - accuracy: 0.8548 - val_loss: 0.5432 - val_accuracy: 0.8277\n",
      "Epoch 139/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4447 - accuracy: 0.8477\n",
      "Epoch 00139: val_accuracy did not improve from 0.82915\n",
      "500/500 [==============================] - 49s 98ms/step - loss: 0.4447 - accuracy: 0.8477 - val_loss: 0.5438 - val_accuracy: 0.8249\n",
      "Epoch 140/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4318 - accuracy: 0.8546\n",
      "Epoch 00140: val_accuracy improved from 0.82915 to 0.83048, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 117s 233ms/step - loss: 0.4318 - accuracy: 0.8546 - val_loss: 0.5338 - val_accuracy: 0.8305\n",
      "Epoch 141/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.8554\n",
      "Epoch 00141: val_accuracy improved from 0.83048 to 0.83285, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 117s 233ms/step - loss: 0.4221 - accuracy: 0.8554 - val_loss: 0.5317 - val_accuracy: 0.8328\n",
      "Epoch 142/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4275 - accuracy: 0.8546\n",
      "Epoch 00142: val_accuracy did not improve from 0.83285\n",
      "500/500 [==============================] - 49s 99ms/step - loss: 0.4275 - accuracy: 0.8546 - val_loss: 0.5360 - val_accuracy: 0.8321\n",
      "Epoch 143/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4307 - accuracy: 0.8524\n",
      "Epoch 00143: val_accuracy did not improve from 0.83285\n",
      "500/500 [==============================] - 49s 98ms/step - loss: 0.4307 - accuracy: 0.8524 - val_loss: 0.5356 - val_accuracy: 0.8315\n",
      "Epoch 144/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4094 - accuracy: 0.8642\n",
      "Epoch 00144: val_accuracy did not improve from 0.83285\n",
      "500/500 [==============================] - 50s 99ms/step - loss: 0.4094 - accuracy: 0.8642 - val_loss: 0.5364 - val_accuracy: 0.8303\n",
      "Epoch 145/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4263 - accuracy: 0.8582\n",
      "Epoch 00145: val_accuracy did not improve from 0.83285\n",
      "500/500 [==============================] - 51s 102ms/step - loss: 0.4263 - accuracy: 0.8582 - val_loss: 0.5553 - val_accuracy: 0.8281\n",
      "Epoch 146/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4251 - accuracy: 0.8596\n",
      "Epoch 00146: val_accuracy did not improve from 0.83285\n",
      "500/500 [==============================] - 49s 97ms/step - loss: 0.4251 - accuracy: 0.8596 - val_loss: 0.5290 - val_accuracy: 0.8314\n",
      "Epoch 147/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4260 - accuracy: 0.8577\n",
      "Epoch 00147: val_accuracy did not improve from 0.83285\n",
      "500/500 [==============================] - 49s 99ms/step - loss: 0.4260 - accuracy: 0.8577 - val_loss: 0.5248 - val_accuracy: 0.8317\n",
      "Epoch 148/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.8554 ETA: 1s - loss: 0.4138 - accura - ETA: 1s - loss: 0.4\n",
      "Epoch 00148: val_accuracy did not improve from 0.83285\n",
      "500/500 [==============================] - 50s 99ms/step - loss: 0.4135 - accuracy: 0.8554 - val_loss: 0.5330 - val_accuracy: 0.8297\n",
      "Epoch 149/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4172 - accuracy: 0.8583 ETA: 0s - loss: 0.4167 - accura\n",
      "Epoch 00149: val_accuracy did not improve from 0.83285\n",
      "500/500 [==============================] - 50s 100ms/step - loss: 0.4172 - accuracy: 0.8583 - val_loss: 0.5346 - val_accuracy: 0.8301\n",
      "Epoch 150/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4006 - accuracy: 0.8633\n",
      "Epoch 00150: val_accuracy improved from 0.83285 to 0.83612, saving model to C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\n",
      "INFO:tensorflow:Assets written to: C:/Users/mb207/Desktop/py/save/Resnet50.ckpt\\assets\n",
      "500/500 [==============================] - 117s 233ms/step - loss: 0.4006 - accuracy: 0.8633 - val_loss: 0.5247 - val_accuracy: 0.8361\n",
      "Epoch 151/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3935 - accuracy: 0.8667\n",
      "Epoch 00151: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 49s 98ms/step - loss: 0.3935 - accuracy: 0.8667 - val_loss: 0.5367 - val_accuracy: 0.8336\n",
      "Epoch 152/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4035 - accuracy: 0.8639\n",
      "Epoch 00152: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 49s 98ms/step - loss: 0.4035 - accuracy: 0.8639 - val_loss: 0.5383 - val_accuracy: 0.8312\n",
      "Epoch 153/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4203 - accuracy: 0.8593\n",
      "Epoch 00153: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 48s 97ms/step - loss: 0.4203 - accuracy: 0.8593 - val_loss: 0.5374 - val_accuracy: 0.8306\n",
      "Epoch 154/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3875 - accuracy: 0.8715\n",
      "Epoch 00154: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 50s 101ms/step - loss: 0.3875 - accuracy: 0.8715 - val_loss: 0.5357 - val_accuracy: 0.8324\n",
      "Epoch 155/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4068 - accuracy: 0.8659 ETA: 3s - loss: 0\n",
      "Epoch 00155: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 52s 104ms/step - loss: 0.4068 - accuracy: 0.8659 - val_loss: 0.5417 - val_accuracy: 0.8319\n",
      "Epoch 156/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.8679 ETA: 0s - loss: 0.3895 \n",
      "Epoch 00156: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 49s 98ms/step - loss: 0.3871 - accuracy: 0.8679 - val_loss: 0.5321 - val_accuracy: 0.8318\n",
      "Epoch 157/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8697 ETA: 0s - loss: 0.3862 - ac - ETA: 0s - loss: 0.3857 - accuracy: \n",
      "Epoch 00157: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 50s 100ms/step - loss: 0.3863 - accuracy: 0.8697 - val_loss: 0.5256 - val_accuracy: 0.8340\n",
      "Epoch 158/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3665 - accuracy: 0.8787\n",
      "Epoch 00158: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 44s 88ms/step - loss: 0.3665 - accuracy: 0.8787 - val_loss: 0.5341 - val_accuracy: 0.8356\n",
      "Epoch 159/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3806 - accuracy: 0.8714\n",
      "Epoch 00159: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 40s 80ms/step - loss: 0.3806 - accuracy: 0.8714 - val_loss: 0.5240 - val_accuracy: 0.8360\n",
      "Epoch 160/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3720 - accuracy: 0.8735\n",
      "Epoch 00160: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 40s 79ms/step - loss: 0.3720 - accuracy: 0.8735 - val_loss: 0.5362 - val_accuracy: 0.8350\n",
      "Epoch 161/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3845 - accuracy: 0.8687\n",
      "Epoch 00161: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.3845 - accuracy: 0.8687 - val_loss: 0.5369 - val_accuracy: 0.8338\n",
      "Epoch 162/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3756 - accuracy: 0.8734\n",
      "Epoch 00162: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 39s 79ms/step - loss: 0.3756 - accuracy: 0.8734 - val_loss: 0.5494 - val_accuracy: 0.8301\n",
      "Epoch 163/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3682 - accuracy: 0.8762\n",
      "Epoch 00163: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.3682 - accuracy: 0.8762 - val_loss: 0.5414 - val_accuracy: 0.8331\n",
      "Epoch 164/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3702 - accuracy: 0.8731\n",
      "Epoch 00164: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 39s 78ms/step - loss: 0.3702 - accuracy: 0.8731 - val_loss: 0.5473 - val_accuracy: 0.8301\n",
      "Epoch 165/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8683\n",
      "Epoch 00165: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 40s 81ms/step - loss: 0.3838 - accuracy: 0.8683 - val_loss: 0.5357 - val_accuracy: 0.8327\n",
      "Epoch 166/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3657 - accuracy: 0.8757\n",
      "Epoch 00166: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 40s 79ms/step - loss: 0.3657 - accuracy: 0.8757 - val_loss: 0.5325 - val_accuracy: 0.8342\n",
      "Epoch 167/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3503 - accuracy: 0.8797\n",
      "Epoch 00167: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 40s 80ms/step - loss: 0.3503 - accuracy: 0.8797 - val_loss: 0.5354 - val_accuracy: 0.8356\n",
      "Epoch 168/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.8756\n",
      "Epoch 00168: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 40s 80ms/step - loss: 0.3631 - accuracy: 0.8756 - val_loss: 0.5378 - val_accuracy: 0.8340\n",
      "Epoch 169/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3545 - accuracy: 0.8770\n",
      "Epoch 00169: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 40s 79ms/step - loss: 0.3545 - accuracy: 0.8770 - val_loss: 0.5464 - val_accuracy: 0.8316\n",
      "Epoch 170/500\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3569 - accuracy: 0.8788\n",
      "Epoch 00170: val_accuracy did not improve from 0.83612\n",
      "500/500 [==============================] - 42s 85ms/step - loss: 0.3569 - accuracy: 0.8788 - val_loss: 0.5457 - val_accuracy: 0.8318\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(X_train,y_train,batch_size=20, \n",
    "                               epochs=500,\n",
    "                              validation_data=(X_test,y_test),callbacks=[earlystopping,callback_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 9s 28ms/step - loss: 0.5559 - accuracy: 0.8301\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_img_test_normalize, y_label_test_OneHot)\n",
    "pred = model.predict(x_img_test_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 8s 27ms/step - loss: 0.5559 - accuracy: 0.8301\n",
      "Loss: 0.555915892124176\n",
      "Accuracy: 0.8300999999046326\n",
      "predict accurscy: 0.8301, precision: 0.8301999803091423, recall: 0.8301000000000001, f1 : 0.8290699686116352\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss,accuracy=model.evaluate(x_img_test_normalize,y_label_test_OneHot)\n",
    "# pred_cy = model.predict_classes(x_img_test_normalize)\n",
    "pred_cy = model.predict(x_img_test_normalize)\n",
    "pred_cy=np.argmax(pred_cy,axis=1)\n",
    "precision = precision_score(y_label_test, pred_cy, average='macro')\n",
    "recall = recall_score(y_label_test, pred_cy, average='macro')\n",
    "acc = accuracy_score(y_label_test, pred_cy)\n",
    "f1 = f1_score(y_label_test, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1 : {f1}')\n",
    "plot_acc(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model= load_model('C:/Users/mb207/Desktop/py/save/desnet.ckpt')\n",
    "loss, accuracy = model.evaluate(x_img_test_normalize, y_label_test_OneHot, verbose=1)\n",
    "\n",
    "pred_cy = model.predict(x_img_test_normalize)\n",
    "precision = precision_score(y_label_test, pred_cy, average='macro')\n",
    "recall = recall_score(y_label_test, pred_cy, average='macro')\n",
    "acc = accuracy_score(y_label_test, pred_cy)\n",
    "f1 = f1_score(y_label_test, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1 : {f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model= load_model('C:/Users/mb207/Desktop/py/save/VGG.ckpt')\n",
    "loss, accuracy = model.evaluate(x_img_test_normalize, y_label_test_OneHot, verbose=1)\n",
    "pred = model.predict(x_img_test_normalize)\n",
    "loss,accuracy=model.evaluate(x_img_test_normalize,y_label_test_OneHot)\n",
    "pred_cy = model.predict_classes(x_img_test_normalize)\n",
    "precision = precision_score(y_label_test, pred_cy, average='macro')\n",
    "recall = recall_score(y_label_test, pred_cy, average='macro')\n",
    "acc = accuracy_score(y_label_test, pred_cy)\n",
    "f1 = f1_score(y_label_test, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1 : {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= load_model('C:/Users/mb207/Desktop/py/save/CNN.ckpt')\n",
    "\n",
    "loss,accuracy=model.evaluate(x_img_test_normalize,y_label_test_OneHot)\n",
    "pred_cy = model.predict_classes(x_img_test_normalize)\n",
    "precision = precision_score(y_label_test, pred_cy, average='macro')\n",
    "recall = recall_score(y_label_test, pred_cy, average='macro')\n",
    "acc = accuracy_score(y_label_test, pred_cy)\n",
    "f1 = f1_score(y_label_test, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1 : {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model= load_model('C:/Users/mb207/Desktop/py/save/InceptionResNetV2.ckpt')\n",
    "# loss, accuracy = model.evaluate(x_img_test_normalize, y_label_test_OneHot, verbose=1)\n",
    "# pred = model.predict(x_img_test_normalize)\n",
    "# loss,accuracy=model.evaluate(x_img_test_normalize,y_label_test_OneHot)\n",
    "# pred_cy = model.predict_classes(x_img_test_normalize)\n",
    "# precision = precision_score(y_label_test, pred_cy, average='macro')\n",
    "# recall = recall_score(y_label_test, pred_cy, average='macro')\n",
    "# acc = accuracy_score(y_label_test, pred_cy)\n",
    "# f1 = f1_score(y_label_test, pred_cy, average='macro')\n",
    "# print('Loss:', loss)\n",
    "# print('Accuracy:', accuracy)\n",
    "# print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1 : {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model= load_model('py/mango4.ckpt')\n",
    "\n",
    "# loss,accuracy=model.evaluate(x_img_test_normalize,y_label_test_OneHot)\n",
    "# pred_cy = model.predict_classes(x_img_test_normalize)\n",
    "# precision = precision_score(y_label_test, pred_cy, average='macro')\n",
    "# recall = recall_score(y_label_test, pred_cy, average='macro')\n",
    "# acc = accuracy_score(y_label_test, pred_cy)\n",
    "# f1 = f1_score(y_label_test, pred_cy, average='macro')\n",
    "# print('Loss:', loss)\n",
    "# print('Accuracy:', accuracy)\n",
    "# print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1 : {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNUf2neke8CxJS6Njvuopz5",
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
