{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Sequential, load_model, Model, Input\n",
    "from keras.utils import np_utils, plot_model, to_categorical\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D ,MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, UpSampling2D, concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras import backend as K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.densenet import DenseNet201,preprocess_input\n",
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4354830879496575609\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13593938621917598761\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12570735613817017331\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10654568960\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2757488003603498665\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:09:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "config=tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.visible_device_list = '0' \n",
    "config.gpu_options.allow_growth = True \n",
    "sess=tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-77cc7325c5d8>:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "cpus = tf.config.experimental.list_physical_devices(device_type='CPU')\n",
    "print(tf.test.is_gpu_available())\n",
    "print(gpus)\n",
    "print(cpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取圖片名稱、label名稱，將label轉為數值\n",
    "def Picture_len(status):\n",
    "    data = pd.read_csv(f'Dataset/Mango/DATA/{status}.csv')\n",
    "    #轉為OneHotEncoder\n",
    "    onehotencoder = OneHotEncoder(sparse=False)\n",
    "    labelencoder = LabelEncoder()\n",
    "#     print(data['label'])\n",
    "    label = onehotencoder.fit_transform(data[['label']])\n",
    "    label_labelencoder = labelencoder.fit_transform(data[['label']])\n",
    "    Picture_label = label\n",
    "    Picture_name = data['image_id'].to_numpy()\n",
    "#     print(Picture_label)\n",
    "    return Picture_name, Picture_label, label_labelencoder\n",
    "\n",
    "\n",
    "def Picture_processing(img_path, csv_name):\n",
    "    picture_pixel = 112\n",
    "    picture_data = []\n",
    "    pictures, picture_label, label_labelencoder = Picture_len(csv_name)\n",
    "    #讀取圖片並縮小\n",
    "    for picture in pictures:\n",
    "        Picture_raw = cv2.imread(f'Dataset/Mango/DATA/{img_path}/{picture}')\n",
    "        Picture_raw = cv2.resize(Picture_raw,(picture_pixel,picture_pixel),interpolation=cv2.INTER_AREA)\n",
    "        picture_data.append(Picture_raw)\n",
    "        \n",
    "    picture_data = np.array(picture_data)\n",
    "    \n",
    "    return picture_data, picture_label, label_labelencoder\n",
    "\n",
    "def plot_acc(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left') \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/user_data/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, label_labelencoder_x = Picture_processing('Train_Image', 'train')\n",
    "test_x, test_y, label_labelencoder_y = Picture_processing('Test_Image', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x/255\n",
    "test_x = test_x/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/.local/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               8388864   \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 31,977,347\n",
      "Trainable params: 31,924,227\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 5000 samples, validate on 1130 samples\n",
      "Epoch 1/500\n",
      "5000/5000 [==============================] - 28s 6ms/step - loss: 0.8836 - accuracy: 0.6694 - val_loss: 11.6810 - val_accuracy: 0.3212\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.32124, saving model to py/ResNet50/resnet50_n2\n",
      "Epoch 2/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.4745 - accuracy: 0.8100 - val_loss: 444.9731 - val_accuracy: 0.3212\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.32124\n",
      "Epoch 3/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.2598 - accuracy: 0.9012 - val_loss: 113.1873 - val_accuracy: 0.3212\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.32124\n",
      "Epoch 4/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.1646 - accuracy: 0.9474 - val_loss: 180.6906 - val_accuracy: 0.2814\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.32124\n",
      "Epoch 5/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.1188 - accuracy: 0.9620 - val_loss: 25.0545 - val_accuracy: 0.3593\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.32124 to 0.35929, saving model to py/ResNet50/resnet50_n2\n",
      "Epoch 6/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0916 - accuracy: 0.9718 - val_loss: 3.7305 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.35929 to 0.63274, saving model to py/ResNet50/resnet50_n2\n",
      "Epoch 7/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0944 - accuracy: 0.9708 - val_loss: 2.2137 - val_accuracy: 0.7230\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.63274 to 0.72301, saving model to py/ResNet50/resnet50_n2\n",
      "Epoch 8/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0956 - accuracy: 0.9732 - val_loss: 6.7318 - val_accuracy: 0.7265\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.72301 to 0.72655, saving model to py/ResNet50/resnet50_n2\n",
      "Epoch 9/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0735 - accuracy: 0.9780 - val_loss: 21.6060 - val_accuracy: 0.7292\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.72655 to 0.72920, saving model to py/ResNet50/resnet50_n2\n",
      "Epoch 10/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0776 - accuracy: 0.9804 - val_loss: 2.9101 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.72920 to 0.74425, saving model to py/ResNet50/resnet50_n2\n",
      "Epoch 11/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0630 - accuracy: 0.9810 - val_loss: 5.0996 - val_accuracy: 0.7248\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74425\n",
      "Epoch 12/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.1212 - accuracy: 0.9848 - val_loss: 7.8428 - val_accuracy: 0.7150\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74425\n",
      "Epoch 13/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0487 - accuracy: 0.9868 - val_loss: 2.1805 - val_accuracy: 0.7425\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74425\n",
      "Epoch 14/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0446 - accuracy: 0.9890 - val_loss: 8.1183 - val_accuracy: 0.7212\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74425\n",
      "Epoch 15/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0784 - accuracy: 0.9844 - val_loss: 21.3354 - val_accuracy: 0.7363\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74425\n",
      "Epoch 16/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0481 - accuracy: 0.9878 - val_loss: 25.8791 - val_accuracy: 0.7451\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.74425 to 0.74513, saving model to py/ResNet50/resnet50_n2\n",
      "Epoch 17/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0465 - accuracy: 0.9884 - val_loss: 4.0036 - val_accuracy: 0.7265\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74513\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 18/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0218 - accuracy: 0.9958 - val_loss: 2.9338 - val_accuracy: 0.7478\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.74513 to 0.74779, saving model to py/ResNet50/resnet50_n2\n",
      "Epoch 19/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 2.3917 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74779\n",
      "Epoch 20/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 2.5480 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74779\n",
      "Epoch 21/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 2.8968 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74779\n",
      "Epoch 22/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.1181 - accuracy: 0.9994 - val_loss: 3.0732 - val_accuracy: 0.7425\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74779\n",
      "Epoch 23/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 2.9520 - val_accuracy: 0.7363\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74779\n",
      "Epoch 24/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 2.9457 - val_accuracy: 0.7425\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74779\n",
      "Epoch 25/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 1.5746e-04 - accuracy: 1.0000 - val_loss: 3.1312 - val_accuracy: 0.7451\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74779\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 26/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 3.3111 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74779\n",
      "Epoch 27/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 5.0131e-05 - accuracy: 1.0000 - val_loss: 3.3566 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74779\n",
      "Epoch 28/500\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 5.6827e-04 - accuracy: 0.9998 - val_loss: 3.3162 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74779\n"
     ]
    }
   ],
   "source": [
    "\n",
    "net = ResNet50(include_top=False, input_tensor=None,weights=\"imagenet\",\n",
    "                input_shape=(112,112,3))\n",
    "\n",
    "# net.trainable = False\n",
    "model = Sequential()\n",
    "model.add(net)\n",
    "model.add(Flatten()) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(256, activation='relu')) \n",
    "model.add(Dense(3, activation='softmax')) \n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10)\n",
    "modelcheckpoint = keras.callbacks.ModelCheckpoint(filepath='py/ResNet50/resnet50_n2', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "reduceLronplateau = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=7, verbose=1, mode='auto', min_delta=0.001, cooldown=0, min_lr=0)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr=1e-4), metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(train_x[:5000],train_y[:5000], epochs=500, batch_size=32, verbose=1,validation_data=(train_x[5000:],train_y[5000:]), callbacks=[modelcheckpoint, earlystopping, reduceLronplateau])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step\n",
      "Loss: 2.7730578327178956\n",
      "Accuracy: 0.7599999904632568\n",
      "predict accurscy: 0.76, precision: 0.7603586341910424, recall: 0.7703373015873015, f1: 0.7630959664414633\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#測試資料\n",
    "# model.load_weights('py/ResNet50/resnet50_n')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "plot_acc(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 845us/step\n",
      "Loss: 2.0494774894714354\n",
      "Accuracy: 0.7360000014305115\n",
      "predict accurscy: 0.736, precision: 0.7392053327341497, recall: 0.7428571428571429, f1: 0.7408415448888576\n"
     ]
    }
   ],
   "source": [
    "#最好權重模型-測試資料\n",
    "model.load_weights('py/ResNet50/resnet50_n2')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6130/6130 [==============================] - 5s 869us/step\n",
      "Loss: 0.5412534726157022\n",
      "Accuracy: 0.9533442258834839\n",
      "predict accurscy: 0.9533442088091354, precision: 0.9544648239031318, recall: 0.9536854464693164, f1: 0.954009026466052\n"
     ]
    }
   ],
   "source": [
    "#最好權重模型-訓練資料\n",
    "model.load_weights('py/ResNet50/resnet50_n2')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(train_x,train_y)\n",
    "pred_cy = model.predict_classes(train_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_x, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/.local/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               25690368  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 49,278,851\n",
      "Trainable params: 49,225,731\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 5000 samples, validate on 1130 samples\n",
      "Epoch 1/500\n",
      "5000/5000 [==============================] - 61s 12ms/step - loss: 1.1387 - accuracy: 0.6974 - val_loss: 4.5451 - val_accuracy: 0.3327\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.33274, saving model to py/ResNet50/resnet50_n\n",
      "Epoch 2/500\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.4428 - accuracy: 0.8328 - val_loss: 11.5671 - val_accuracy: 0.3327\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.33274\n",
      "Epoch 3/500\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.2321 - accuracy: 0.9158 - val_loss: 4.3274 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.33274 to 0.34602, saving model to py/ResNet50/resnet50_n\n",
      "Epoch 4/500\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.2319 - accuracy: 0.9604 - val_loss: 2.8952 - val_accuracy: 0.3451\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.34602\n",
      "Epoch 5/500\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.1151 - accuracy: 0.9726 - val_loss: 2.5735 - val_accuracy: 0.4761\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.34602 to 0.47611, saving model to py/ResNet50/resnet50_n\n",
      "Epoch 6/500\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0822 - accuracy: 0.9828 - val_loss: 3.6400 - val_accuracy: 0.5257\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.47611 to 0.52566, saving model to py/ResNet50/resnet50_n\n",
      "Epoch 7/500\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.4623 - accuracy: 0.9770 - val_loss: 4.5978 - val_accuracy: 0.6566\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.52566 to 0.65664, saving model to py/ResNet50/resnet50_n\n",
      "Epoch 8/500\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0636 - accuracy: 0.9858 - val_loss: 2.4530 - val_accuracy: 0.7363\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.65664 to 0.73628, saving model to py/ResNet50/resnet50_n\n",
      "Epoch 9/500\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0588 - accuracy: 0.9832 - val_loss: 3.4611 - val_accuracy: 0.7310\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.73628\n",
      "Epoch 10/500\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0601 - accuracy: 0.9846 - val_loss: 2.2118 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.73628 to 0.74690, saving model to py/ResNet50/resnet50_n\n",
      "Epoch 11/500\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0625 - accuracy: 0.9864 - val_loss: 2.4112 - val_accuracy: 0.7549\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.74690 to 0.75487, saving model to py/ResNet50/resnet50_n\n",
      "Epoch 12/500\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.1305 - accuracy: 0.9864 - val_loss: 3.6416 - val_accuracy: 0.7681\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.75487 to 0.76814, saving model to py/ResNet50/resnet50_n\n",
      "Epoch 13/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0408 - accuracy: 0.9882 - val_loss: 2.6605 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76814\n",
      "Epoch 14/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0482 - accuracy: 0.9884 - val_loss: 18.1632 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76814\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 15/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 4.8018 - val_accuracy: 0.7504\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76814\n",
      "Epoch 16/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0921 - accuracy: 0.9982 - val_loss: 2.7489 - val_accuracy: 0.7540\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.76814\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 17/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 3.5617 - val_accuracy: 0.7549\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76814\n",
      "Epoch 18/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0551 - accuracy: 0.9998 - val_loss: 3.7841 - val_accuracy: 0.7566\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76814\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 19/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.3136 - accuracy: 0.9994 - val_loss: 4.0949 - val_accuracy: 0.7575\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76814\n",
      "Epoch 20/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 5.0965e-04 - accuracy: 0.9998 - val_loss: 3.7743 - val_accuracy: 0.7566\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76814\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 21/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 3.7096e-04 - accuracy: 1.0000 - val_loss: 3.9883 - val_accuracy: 0.7575\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76814\n",
      "Epoch 22/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 6.4518e-04 - accuracy: 0.9998 - val_loss: 3.8616 - val_accuracy: 0.7558\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76814\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 23/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0508 - accuracy: 0.9994 - val_loss: 3.9097 - val_accuracy: 0.7549\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76814\n",
      "Epoch 24/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.1291 - accuracy: 0.9994 - val_loss: 3.6716 - val_accuracy: 0.7575\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76814\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "Epoch 25/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 3.9062 - val_accuracy: 0.7566\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76814\n",
      "Epoch 26/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0807 - accuracy: 0.9996 - val_loss: 4.1809 - val_accuracy: 0.7566\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76814\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
      "Epoch 27/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0423 - accuracy: 0.9994 - val_loss: 4.1449 - val_accuracy: 0.7584\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76814\n",
      "Epoch 28/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 3.1503e-04 - accuracy: 1.0000 - val_loss: 3.8384 - val_accuracy: 0.7566\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76814\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
      "Epoch 29/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0854 - accuracy: 0.9998 - val_loss: 4.0455 - val_accuracy: 0.7566\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76814\n",
      "Epoch 30/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 2.0395e-04 - accuracy: 1.0000 - val_loss: 4.0913 - val_accuracy: 0.7549\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76814\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 9.9999988758398e-14.\n",
      "Epoch 31/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 9.3651e-04 - accuracy: 0.9996 - val_loss: 3.8215 - val_accuracy: 0.7566\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76814\n",
      "Epoch 32/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 3.9124 - val_accuracy: 0.7575\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76814\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.999999146890344e-15.\n",
      "Epoch 33/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0331 - accuracy: 0.9996 - val_loss: 3.8181 - val_accuracy: 0.7575\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76814\n",
      "Epoch 34/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 4.8988e-04 - accuracy: 1.0000 - val_loss: 3.7306 - val_accuracy: 0.7558\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76814\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 9.999998977483753e-16.\n",
      "Epoch 35/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 4.2437e-04 - accuracy: 1.0000 - val_loss: 3.7312 - val_accuracy: 0.7558\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76814\n",
      "Epoch 36/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 4.0304 - val_accuracy: 0.7566\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76814\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.999998977483754e-17.\n",
      "Epoch 37/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 3.2313e-04 - accuracy: 1.0000 - val_loss: 3.8274 - val_accuracy: 0.7549\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76814\n",
      "Epoch 38/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 4.0163 - val_accuracy: 0.7549\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76814\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 9.999998845134856e-18.\n",
      "Epoch 39/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 4.0169 - val_accuracy: 0.7558\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76814\n",
      "Epoch 40/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 3.8847 - val_accuracy: 0.7558\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76814\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 9.999999010570977e-19.\n",
      "Epoch 41/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 3.7395e-04 - accuracy: 1.0000 - val_loss: 3.9767 - val_accuracy: 0.7566\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76814\n",
      "Epoch 42/500\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 4.6898e-04 - accuracy: 1.0000 - val_loss: 3.7450 - val_accuracy: 0.7549\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76814\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 9.999999424161285e-20.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "net = ResNet50(include_top=False, input_tensor=None,weights=\"imagenet\",\n",
    "                input_shape=(224,224,3))\n",
    "\n",
    "# net.trainable = False\n",
    "model = Sequential()\n",
    "model.add(net)\n",
    "model.add(Flatten()) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(256, activation='relu')) \n",
    "model.add(Dense(3, activation='softmax')) \n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30)\n",
    "modelcheckpoint = keras.callbacks.ModelCheckpoint(filepath='py/ResNet50/resnet50_n', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "reduceLronplateau = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.001, cooldown=0, min_lr=0)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr=1e-4), metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(train_x[:5000],train_y[:5000], epochs=500, batch_size=32, verbose=1,validation_data=(train_x[5000:],train_y[5000:]), callbacks=[modelcheckpoint, earlystopping, reduceLronplateau])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 4ms/step\n",
      "Loss: 1.5471777222156524\n",
      "Accuracy: 0.8159999847412109\n",
      "predict accurscy: 0.816, precision: 0.8158465113053128, recall: 0.8283730158730158, f1: 0.8187866714564079\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#測試資料\n",
    "# model.load_weights('py/ResNet50/resnet50_n')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "plot_acc(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step\n",
      "Loss: 1.682476165652275\n",
      "Accuracy: 0.8040000200271606\n",
      "predict accurscy: 0.804, precision: 0.8047732362821948, recall: 0.8163690476190476, f1: 0.8050849229161222\n"
     ]
    }
   ],
   "source": [
    "#最好權重模型-測試資料\n",
    "model.load_weights('py/ResNet50/resnet50_n')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6130/6130 [==============================] - 16s 3ms/step\n",
      "Loss: 0.703574087951503\n",
      "Accuracy: 0.9526916742324829\n",
      "predict accurscy: 0.9526916802610114, precision: 0.9527934030822762, recall: 0.9542059070162571, f1: 0.9533643734585756\n"
     ]
    }
   ],
   "source": [
    "#最好權重模型-訓練資料\n",
    "model.load_weights('py/ResNet50/resnet50_n')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(train_x,train_y)\n",
    "pred_cy = model.predict_classes(train_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_x, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料增強"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/.local/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               25690368  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 49,278,851\n",
      "Trainable params: 49,225,731\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "net = ResNet50(include_top=False, input_tensor=None,weights=\"imagenet\",\n",
    "                input_shape=(224,224,3))\n",
    "\n",
    "# net.trainable = False\n",
    "model = Sequential()\n",
    "model.add(net)\n",
    "model.add(Flatten()) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(256, activation='relu')) \n",
    "model.add(Dense(3, activation='softmax')) \n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30)\n",
    "modelcheckpoint = keras.callbacks.ModelCheckpoint(filepath='py/ResNet50/resnet50', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "reduceLronplateau = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.001, cooldown=0, min_lr=0)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr=1e-4), metrics = ['accuracy'])\n",
    "# train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "# test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# train_datagen = ImageDataGenerator(rotation_range=0.2, zoom_range=0.05,\n",
    "#                                    featurewise_center = True, featurewise_std_normalization = True,\n",
    "#                                     width_shift_range=0.05, height_shift_range=0.05, shear_range=0.05,\n",
    "#                                     horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# train_datagen=ImageDataGenerator(rotation_range=5 , \n",
    "#                              width_shift_range=0.2 , \n",
    "#                              height_shift_range=0.2 ,\n",
    "#                              shear_range=0.2 ,\n",
    "#                              zoom_range=0.2 , \n",
    "#                              data_format='channels_last')\n",
    "\n",
    "# train_datagen.fit(train_x)\n",
    "\n",
    "# history = model.fit_generator(train_datagen.flow(train_x[:5000],train_y[:5000],batch_size=20), \n",
    "#                               steps_per_epoch=len(train_x[:5000]) / 20 , epochs=500,\n",
    "#                               validation_data=(train_x[5000:],train_y[5000:]),validation_steps=len(train_x[5000:]) / 20,\n",
    "#                               callbacks=[modelcheckpoint, earlystopping, reduceLronplateau])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step\n",
      "Loss: 0.6872671039104462\n",
      "Accuracy: 0.8199999928474426\n",
      "predict accurscy: 0.82, precision: 0.819412591508728, recall: 0.8305555555555556, f1: 0.822094061643304\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#測試資料\n",
    "# model.load_weights('py/ResNet50/resnet50')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "plot_acc(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step\n",
      "Loss: 0.7012974712848663\n",
      "Accuracy: 0.8199999928474426\n",
      "predict accurscy: 0.82, precision: 0.819412591508728, recall: 0.8305555555555556, f1: 0.822094061643304\n"
     ]
    }
   ],
   "source": [
    "#最好權重模型-測試資料\n",
    "model.load_weights('py/ResNet50/resnet50')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6130/6130 [==============================] - 18s 3ms/step\n",
      "Loss: 0.40334094445332036\n",
      "Accuracy: 0.8835236430168152\n",
      "predict accurscy: 0.8835236541598694, precision: 0.8847058935942508, recall: 0.8864093650354699, f1: 0.8854736177734309\n"
     ]
    }
   ],
   "source": [
    "#最好權重模型-訓練資料\n",
    "model.load_weights('py/ResNet50/resnet50')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(train_x,train_y)\n",
    "pred_cy = model.predict_classes(train_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_x, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Model)          (None, 3, 3, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 17280)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 17280)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               8847872   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 27,171,395\n",
      "Trainable params: 26,942,339\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 5000 samples, validate on 1130 samples\n",
      "Epoch 1/500\n",
      "5000/5000 [==============================] - 95s 19ms/step - loss: 0.9424 - accuracy: 0.6422 - val_loss: 0.8756 - val_accuracy: 0.6611\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66106, saving model to py/DenseNet201/densenet201_2_n\n",
      "Epoch 2/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.5692 - accuracy: 0.7674 - val_loss: 0.9786 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66106 to 0.70000, saving model to py/DenseNet201/densenet201_2_n\n",
      "Epoch 3/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.3859 - accuracy: 0.8426 - val_loss: 1.3356 - val_accuracy: 0.7221\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.70000 to 0.72212, saving model to py/DenseNet201/densenet201_2_n\n",
      "Epoch 4/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.2875 - accuracy: 0.8900 - val_loss: 1.9079 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.72212\n",
      "Epoch 5/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.2053 - accuracy: 0.9300 - val_loss: 2.8450 - val_accuracy: 0.7195\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.72212\n",
      "Epoch 6/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.1899 - accuracy: 0.9354 - val_loss: 3.3194 - val_accuracy: 0.7018\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.72212\n",
      "Epoch 7/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.1582 - accuracy: 0.9460 - val_loss: 2.3809 - val_accuracy: 0.7336\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.72212 to 0.73363, saving model to py/DenseNet201/densenet201_2_n\n",
      "Epoch 8/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.1423 - accuracy: 0.9582 - val_loss: 2.5337 - val_accuracy: 0.7265\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.73363\n",
      "Epoch 9/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.1264 - accuracy: 0.9596 - val_loss: 3.3353 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.73363 to 0.74336, saving model to py/DenseNet201/densenet201_2_n\n",
      "Epoch 10/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.1175 - accuracy: 0.9688 - val_loss: 3.1416 - val_accuracy: 0.7336\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74336\n",
      "Epoch 11/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.1281 - accuracy: 0.9678 - val_loss: 6.7964 - val_accuracy: 0.7363\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74336\n",
      "Epoch 12/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.1042 - accuracy: 0.9714 - val_loss: 6.2517 - val_accuracy: 0.6912\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74336\n",
      "Epoch 13/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0900 - accuracy: 0.9742 - val_loss: 4.4406 - val_accuracy: 0.7389\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74336\n",
      "Epoch 14/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0912 - accuracy: 0.9746 - val_loss: 4.6226 - val_accuracy: 0.7381\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74336\n",
      "Epoch 15/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0883 - accuracy: 0.9760 - val_loss: 5.9844 - val_accuracy: 0.7372\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74336\n",
      "Epoch 16/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0857 - accuracy: 0.9758 - val_loss: 7.1672 - val_accuracy: 0.7186\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74336\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 17/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0409 - accuracy: 0.9896 - val_loss: 4.1346 - val_accuracy: 0.7496\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.74336 to 0.74956, saving model to py/DenseNet201/densenet201_2_n\n",
      "Epoch 18/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0249 - accuracy: 0.9930 - val_loss: 3.5101 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.74956 to 0.75133, saving model to py/DenseNet201/densenet201_2_n\n",
      "Epoch 19/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0238 - accuracy: 0.9944 - val_loss: 4.5149 - val_accuracy: 0.7398\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75133\n",
      "Epoch 20/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0262 - accuracy: 0.9948 - val_loss: 4.5319 - val_accuracy: 0.7504\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75133\n",
      "Epoch 21/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0202 - accuracy: 0.9956 - val_loss: 5.2375 - val_accuracy: 0.7504\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75133\n",
      "Epoch 22/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0256 - accuracy: 0.9950 - val_loss: 6.3648 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75133\n",
      "Epoch 23/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0211 - accuracy: 0.9944 - val_loss: 4.6361 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75133\n",
      "Epoch 24/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0237 - accuracy: 0.9952 - val_loss: 3.8204 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75133\n",
      "Epoch 25/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0151 - accuracy: 0.9968 - val_loss: 4.0087 - val_accuracy: 0.7336\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75133\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 26/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 3.8484 - val_accuracy: 0.7566\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.75133 to 0.75664, saving model to py/DenseNet201/densenet201_2_n\n",
      "Epoch 27/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 4.0110 - val_accuracy: 0.7504\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75664\n",
      "Epoch 28/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0243 - accuracy: 0.9980 - val_loss: 3.8834 - val_accuracy: 0.7522\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75664\n",
      "Epoch 29/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 4.2967 - val_accuracy: 0.7451\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75664\n",
      "Epoch 30/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0203 - accuracy: 0.9970 - val_loss: 4.1738 - val_accuracy: 0.7522\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75664\n",
      "Epoch 31/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 4.5321 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75664\n",
      "Epoch 32/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 4.2530 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75664\n",
      "Epoch 33/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0168 - accuracy: 0.9984 - val_loss: 4.3904 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75664\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 34/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 4.1748 - val_accuracy: 0.7504\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75664\n",
      "Epoch 35/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 3.8601e-04 - accuracy: 0.9998 - val_loss: 3.9860 - val_accuracy: 0.7478\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75664\n",
      "Epoch 36/500\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 4.4221 - val_accuracy: 0.7549\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75664\n"
     ]
    }
   ],
   "source": [
    "DenseNet201_model = DenseNet201(include_top=False, weights=\"imagenet\", input_shape=(112,112,3))\n",
    "# model = add_new_last_layer(model, 3)\n",
    "\n",
    "# net.trainable = False\n",
    "model = Sequential()\n",
    "model.add(DenseNet201_model)\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Conv2D(256, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(Flatten()) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(512, activation='relu')) \n",
    "# model.add(Dense(128, activation='relu')) \n",
    "# model.add(Dropout(0.1)) \n",
    "model.add(Dense(3, activation='softmax')) \n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10)\n",
    "modelcheckpoint = keras.callbacks.ModelCheckpoint(filepath='py/DenseNet201/densenet201_2_n', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "# reduceLronplateau = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.001, cooldown=0, min_lr=0)\n",
    "reduceLronplateau=ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                             patience=7,\n",
    "                             # 3 epochs 內acc沒下降就要調整LR\n",
    "                             verbose=1,\n",
    "                             factor=0.5,\n",
    "                             # LR降為0.5\n",
    "                             min_lr=0.00001\n",
    "                             # 最小 LR 到0.00001就不再下降\n",
    "                             )\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr=1e-4), metrics = ['accuracy'])\n",
    "history = model.fit(train_x[:5000],train_y[:5000], epochs=500, batch_size=32, verbose=1,validation_data=(train_x[5000:],train_y[5000:]), callbacks=[modelcheckpoint, earlystopping, reduceLronplateau])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step\n",
      "Loss: 3.0776201152801512\n",
      "Accuracy: 0.7559999823570251\n",
      "predict accurscy: 0.756, precision: 0.7579872697519757, recall: 0.7660714285714286, f1: 0.7605567248384929\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA9tUlEQVR4nO3deXyU9bX48c/JvkJCwh5WRQREQAO47yhq3ZeixWpbi3ut1/ZW+9O69Lb19ra21VrX4lIX3AUVq7jgUlFBZBcEFMyELUBC9m3m/P74PoEhTJIBM5mZ5Lxfr3ll5llmzozynOe7i6pijDHGNJcQ7QCMMcbEJksQxhhjQrIEYYwxJiRLEMYYY0KyBGGMMSYkSxDGGGNCsgRhDCAij4nI/4R57DoROSnSMRkTbZYgjDHGhGQJwphORESSoh2D6TwsQZi44VXt/FJElohIlYj8U0R6i8gbIlIhIm+LSG7Q8WeKyHIRKRORuSIyImjfOBFZ6J33LJDW7LO+JyKLvHM/FpGDw4zxdBH5QkTKRaRIRG5vtv8o7/3KvP2XedvTReTPIrJeRHaIyEfetuNExBfidzjJe367iLwgIk+KSDlwmYhMEJF53mdsFJG/i0hK0PmjRGSOiGwXkc0i8msR6SMi1SKSF3TcISJSIiLJ4Xx30/lYgjDx5jxgEnAAcAbwBvBroCfu/+efAYjIAcAzwM+9fbOBV0UkxbtYvgL8C+gBPO+9L96544DpwBVAHvAgMEtEUsOIrwr4IZADnA5cJSJne+87yIv3Xi+mscAi77w/AYcCR3gx/TcQCPM3OQt4wfvMpwA/cAOQDxwOnAhc7cWQDbwN/BvoB+wPvKOqm4C5wIVB73sJMENVG8KMw3QyliBMvLlXVTerajHwIfCpqn6hqrXAy8A477jvA6+r6hzvAvcnIB13AT4MSAb+qqoNqvoCMD/oM6YBD6rqp6rqV9XHgTrvvFap6lxVXaqqAVVdgktSx3q7LwbeVtVnvM/dpqqLRCQB+DFwvaoWe5/5sarWhfmbzFPVV7zPrFHVz1X1E1VtVNV1uATXFMP3gE2q+mdVrVXVClX91Nv3ODAVQEQSgYtwSdR0UZYgTLzZHPS8JsTrLO95P2B90w5VDQBFQH9vX7HuPlPl+qDng4AbvSqaMhEpAwZ457VKRCaKyHte1cwO4ErcnTzee6wNcVo+roor1L5wFDWL4QAReU1ENnnVTr8PIwaAmcBIERmCK6XtUNXP9jEm0wlYgjCd1QbchR4AERHcxbEY2Aj097Y1GRj0vAj4narmBD0yVPWZMD73aWAWMEBVuwMPAE2fUwTsF+KcrUBtC/uqgIyg75GIq54K1nxK5vuBlcAwVe2Gq4ILjmFoqMC9UthzuFLEJVjpocuzBGE6q+eA00XkRK+R9UZcNdHHwDygEfiZiCSLyLnAhKBzHwau9EoDIiKZXuNzdhifmw1sV9VaEZmAq1Zq8hRwkohcKCJJIpInImO90s104G4R6SciiSJyuNfm8RWQ5n1+MnAL0FZbSDZQDlSKyIHAVUH7XgP6isjPRSRVRLJFZGLQ/ieAy4AzsQTR5VmCMJ2Sqq7C3Qnfi7tDPwM4Q1XrVbUeOBd3IdyOa694KejcBcBPgb8DpcAa79hwXA3cKSIVwG9wiarpfb8FTsMlq+24Buox3u5fAEtxbSHbgf8FElR1h/eej+BKP1XAbr2aQvgFLjFV4JLds0ExVOCqj84ANgGrgeOD9v8H1zi+UFWDq91MFyS2YJAxJpiIvAs8raqPRDsWE12WIIwxO4nIeGAOrg2lItrxmOiyKiZjDAAi8jhujMTPLTkYsBKEMcaYFlgJwhhjTEidZmKv/Px8HTx4cLTDMMaYuPL5559vVdXmY2uATpQgBg8ezIIFC6IdhjHGxBURabE7s1UxGWOMCckShDHGmJAsQRhjjAmp07RBhNLQ0IDP56O2tjbaoURcWloaBQUFJCfb2i7GmPbRqROEz+cjOzubwYMHs/vEnZ2LqrJt2zZ8Ph9DhgyJdjjGmE4iYlVMIjJdRLaIyLIW9ouI3CMia8QtIXlI0L5LRWS197h0X2Oora0lLy+vUycHABEhLy+vS5SUjDEdJ5JtEI8Bk1vZfyowzHtMw81hj4j0AG4DJuKmYL5NgtYZ3ludPTk06Srf0xjTcSJWxaSqH4jI4FYOOQt4wlvV6xMRyRGRvsBxwBxV3Q4gInNwiSacxVqMMXFIValp8JOUkEBK0t7ft6oqVfV+SqvqUYV+OWkkJe79+/gDiq+0mm+3V1PXEMCvSiCgNAaUgCr+wK5HQoKQm5FCbkYyuZkp5Gak0D09mcSE0Ddrjf4AZTUNlFXXs72qgdLqesqq66n3u8/Y+d7NPgcgLTmR9OQE9zcl0XvtnqcnJ9ItLZmBeRkhP/e7iGYbRH92XyrR521rafseRGQarvTBwIEDQx0SdWVlZTz99NNcffXVe3XeaaedxtNPP01OTk5kAjMmQhr9Aarq/VTVNVJV10hlXSNVdX7KaurZWlHH1sp6tlXVUVJRz9bKup2P2oYAgLvgpSfRLS2Z7unJdEtPpltaEt3Tk0lPSaK8toHSqnpKq+sp9S60pdX1NPh3zSuXlCAU5KYzKC+TQXkZDMrLZLD3d0CPdGrq/awtqeLrkkq+3ur9Lali/bZq6v2Bff7uItA9PZkeGSnkZCQTULyEUE95beN3/m1bMmZADjOvObLd3zeuG6lV9SHgIYDCwsKYnHWwrKyMf/zjH3skiMbGRpKSWv75Z8+eHenQTJxRVeoaA96F1091QyPJiQnuTjLZ3VWmJiWQ0MId7HdRUdvA5vI6tpTXsrmils3ldWwur2WL93drZR2VXjJoutC3JEGgR2Yq+Vkp9MxOZXBeBvlZqeRlpeIPBNhR00B5TSPltQ3sqGlgS0Uta7Y0sqOmger6RrqnJ5OTkUKPjBQG5WUwbmCOdwefTG5GCqrw7fZq1m1zF/yF60upqNt1cRaB4DlKkxKEQXkZDO2ZxQkjerFffhaD8jJIT0kkQYSkRCFRhIQE9zcxwT38AfWSU3DCcq+3e88TE4QBPTLokeHFnOkSR4+gEkdqcgKJIiQlJJCQwM73b/osgLrGADX1fmoa/NQ2BP2tD1Db4CcjJbHd/5tDdBNEMW6N4CYF3rZiXDVT8Pa5HRZVO7vppptYu3YtY8eOJTk5mbS0NHJzc1m5ciVfffUVZ599NkVFRdTW1nL99dczbdo0YNfUIZWVlZx66qkcddRRfPzxx/Tv35+ZM2eSnp4e5W9mwlHfGGBbVR1bd7tbrmdHTQP1jQEa/IGdf+v8ARoaA9T73evqnXfhfu8uvJHGQNv3QWnJCTsTxs6/KYm7bQ+uovAHNOhOf9fnVdc3Ulnnp7KuIeRFPys1iV7dUumdncboghyy05LISk0iMyWJzNRE9zw1aeffbulJ5GelkpuR0mI1TCSoKqXVDV7CcEkjMyWJoT0zGdoziwG56ftUHQUwoEf7V+uE0vTfbJ8bY/dRNBPELOBaEZmBa5DeoaobReRN4PdBDdMnAzd/1w+749XlrNhQ/l3fZjcj+3XjtjNGtXrMXXfdxbJly1i0aBFz587l9NNPZ9myZTu7o06fPp0ePXpQU1PD+PHjOe+888jLy9vtPVavXs0zzzzDww8/zIUXXsiLL77I1KlT2/W7mH2nqhSX1bCoqIxF35axfEM5mytq2VpR12K1Qkqiq2tPSUogOVG8vwk7tycnJpCVmkTv7DTvIptIZrMLbkZKIg3+gHcn6aemwT0PvsOsrvdTG7S9rLrB7av3U9sYoLq+kQSRoPdNJDMlib7d04I+L5H8rFT6dE+jV3Yavbul0qtbGlmp8VEBISL0yHR374cM7OhLbHyL2H9hEXkGVxLIFxEfrmdSMoCqPgDMxq3PuwaoBn7k7dsuIr/Frc0LcGdTg3VnMGHChN3GKtxzzz28/PLLABQVFbF69eo9EsSQIUMYO3YsAIceeijr1q3rqHBNCJV1jSzxlfHFt2UuKRSVUVJRB0BqUgIj+nbjwD7Z5O+fT35WqvdIIT87lfzMVPKzU8hIiY+Lq+naItmL6aI29itwTQv7pgPT2zOetu70O0pmZubO53PnzuXtt99m3rx5ZGRkcNxxx4Ucy5CamrrzeWJiIjU1NR0Sq9ndlvJarp+xiE++2bazDntIfiZH75/P2IE5jB2Qw4F9uu1TLxxjYpHdxkRYdnY2FRWhV2/csWMHubm5ZGRksHLlSj755JMOjs6Ea/XmCi57dD6l1fVcd/z+HDIol7EDcsjJSIl2aMZEjCWICMvLy+PII4/koIMOIj09nd69e+/cN3nyZB544AFGjBjB8OHDOeyww6IYqWnJvLXbmPavBaQlJ/LcFYdzUP/u0Q7JmA7RadakLiws1OYLBn355ZeMGDEiShF1vK72fTvCzEXF/PL5JQzMy+DRy8Z3WK8VYzqKiHyuqoWh9lkJwpgQVJUH3v+a//33SiYO6cFDlxTSPcNmyjVdiyUIY5pp9Ae4/dXlPPnJt5wxph9/uuBgUpMiMxDJmFhmCcKYINX1jVz39Be8s3ILVx67H/99yvCIjEw2Jh5YgjCdVqM/wPaqekq80ctl1fUkeNMXJIiQ5E1pkJDgngP88d8rWVq8g9+eNYpLDh8c3S9gTJRZgjAxS1Upqajjy00VlFTU7T4tRbNpKuobA2yvbmBrRZ2b2qLSzY2zt30w0pMTeeiSQk4a2bvtg43p5CxBmJhQXd/IV5srWbWpnC83VrBqUwUrN5VTWt3Q6nlJCbumqcjNSCY/K5Wh+VmMH5ziRjBnp9Izyz3P8RqZG71plAMBaAwEvGmc3fNBeZn0z7F5rowBSxARt6/TfQP89a9/Zdq0aWRkdK6ulf6AsmpTBZ+v387n60tZ7NvBum1VO+/205MTGd4nm1NG9eHAPtkM79ONfjlpbu6ioLmKUhIjM3OpMcaxBBFhLU33HY6//vWvTJ06NWYTxOKiMopKq+mWtvuc/dlpybtNN1FR28CiojIWrCtl4belfPFtGZXe9Mu9slMZNzCHs8f2Z3ifbEb0zWZAboZd+I2JAZYgIix4uu9JkybRq1cvnnvuOerq6jjnnHO44447qKqq4sILL8Tn8+H3+7n11lvZvHkzGzZs4Pjjjyc/P5/33nsv2l9lpw1lNfx+9pe8tmRji8c0LfqSlpxI0fZqAurm4R/eO5uzx/WjcFAPDh2US0Fuui2XakyM6joJ4o2bYNPS9n3PPqPh1LtaPSR4uu+33nqLF154gc8++wxV5cwzz+SDDz6gpKSEfv368frrrwNujqbu3btz9913895775Gfn9++ce+j2gY/D3/wNffNXYMqXH/iME4d3YfKWre4S3lNo7fYS8PO15X1jZw1tj+Fg3IZNzCH7DQbbGZMvOg6CSIGvPXWW7z11luMGzcOgMrKSlavXs3RRx/NjTfeyK9+9Su+973vcfTRR0c50t2pKm8u38zvZq+gaHsNpx7Uh1+fNsKmnTCmk+s6CaKNO/2OoKrcfPPNXHHFFXvsW7hwIbNnz+aWW27hxBNP5De/+U0UItzT6s0V3PHqCj5as5UDemfx9OUTOWL/2CjRGGMiq+skiCgJnu77lFNO4dZbb+UHP/gBWVlZFBcXk5ycTGNjIz169GDq1Knk5OTwyCOP7HZuR1YxVdU17lwW8/UlG3l83joyUxK5/YyRTD1s0D4vzWiMiT+WICIseLrvU089lYsvvpjDDz8cgKysLJ588knWrFnDL3/5SxISEkhOTub+++8HYNq0aUyePJl+/fq1ayN1eW0D/5q3Hl9pNSXeWslN6ybXNPh3HicCF00YyI2TDiAvK7WVdzTGdEY23XcnEs73XbmpnKueXMi6bVXkZbqlMHtmu2Ux8zK9ZTG9JTKH5mcxMM/aGYzpzGy6bwPAy1/4uPmlpWSnJfPstMOZMKRHtEMyxsSwiFYoi8hkEVklImtE5KYQ+weJyDsiskRE5opIQdA+v4gs8h6zIhlnZ1fX6OfWV5Zxw7OLObggh9d/dpQlB2NMmyJWghCRROA+YBLgA+aLyCxVXRF02J+AJ1T1cRE5AfgDcIm3r0ZVx37XOFS1SwzEaqmqcENZDVc/tZBFRWVMO2YovzxlOMnW0GyMCUMkq5gmAGtU9WsAEZkBnAUEJ4iRwH95z98DXmnPANLS0ti2bRt5eXmdOkmoKtu2bSMtLW237R+t3srPZnxBfWOA+39wCKeO7hulCI0x8SiSCaI/UBT02gdMbHbMYuBc4G/AOUC2iOSp6jYgTUQWAI3AXar6SvMPEJFpwDSAgQMH7hFAQUEBPp+PkpKS7/5tYlxaWhoFBa6GLhBQ/jF3DX+e8xXDemVx/9RD2a9nVpQjNMbEm2g3Uv8C+LuIXAZ8ABQDTf0sB6lqsYgMBd4VkaWqujb4ZFV9CHgIXC+m5m+enJzMkCFDIhl/zNlSUctNLy7l3ZVbOGtsP/5w7mgyUqL9n9kYE48ieeUoBgYEvS7wtu2kqhtwJQhEJAs4T1XLvH3F3t+vRWQuMA7YLUGYXVSVV5ds5Dczl1FT7+fOs0ZxyWGDOnXVmjEmsiKZIOYDw0RkCC4xTAEuDj5ARPKB7aoaAG4Gpnvbc4FqVa3zjjkS+GMEY41r2yrruOWVZbyxbBNjB+TwpwvGsH8vq1Iyxnw3EUsQqtooItcCbwKJwHRVXS4idwILVHUWcBzwBxFRXBXTNd7pI4AHRSSA64p7V7PeT8bzxtKN3PLKMipqG/nV5AP56dFDbDoMY0y76NQjqTuz0qp6bpu1nFmLNzC6f3f+fOEYDuidHe2wjDFxxkZSdzJzVmzm5peWsqOmnhsnHcCVx+1nYxuMMe3OEkScKKuu583lm5i5aAMfr93GiL7deOLHExjZr1u0QzPGdFKWIGJYZV0jc1Zs4tXFG/lwdQkNfmVwXgb/PXk4lx81dLd1n40xpr1ZgogxtQ1+3l25hVcXb+DdlVuoawzQr3saPzpyCGcc3I+D+nezrqvGmA5hCSKGfLmxnAsfnEdFbSP5WSlMGT+AM8b045CBuSQkWFIwxnQsSxAx5J8ffUMgoDz5k4kcNrSHdVc1xkSVJYgYUV7bwGtLNnDOuP4cNczWfDbGRJ/dosaIWYs2UNsQYMr4PScdNMaYaLAEESNmzP+WEX27cXBB92iHYowxgCWImLCseAfLisuZMn6A9VAyxsQMSxAxYMb8b0lNSuDssf2jHYoxxuxkCSLKqusbmfnFBk4f3ZfuGcnRDscYY3ayBBFlry/ZSEVdI98fP6Dtg40xpgNZgoiyZ+cXMbRnJhOG9Ih2KMYYsxtLEFG0enMFC9aXWuO0MSYmWYKIohnzi0hOFM49pCDaoRhjzB4sQURJXaOflxb6mDSyN/lZqdEOxxhj9mAJIkreWr6Z0uoGGzltjIlZEU0QIjJZRFaJyBoRuSnE/kEi8o6ILBGRuSJSELTvUhFZ7T0ujWSc0TBj/rf0z0nnqP1t3iVjTGyKWIIQkUTgPuBUYCRwkYiMbHbYn4AnVPVg4E7gD965PYDbgInABOA2EcmNVKwdbf22Kv6zZhvfHz/ApvE2xsSsSJYgJgBrVPVrVa0HZgBnNTtmJPCu9/y9oP2nAHNUdbuqlgJzgMkRjLVDPbegiASBCwqtcdoYE7simSD6A0VBr33etmCLgXO95+cA2SKSF+a5iMg0EVkgIgtKSkraLfBIavQHeH6Bj+OH96Jv9/Roh2OMMS2KdiP1L4BjReQL4FigGPCHe7KqPqSqhapa2LNnz0jF2K7eXbmFLRV1NnLaGBPzIrlgUDEQfBUs8LbtpKob8EoQIpIFnKeqZSJSDBzX7Ny5EYy1wzw7v4he2amccGCvaIdijDGtimQJYj4wTESGiEgKMAWYFXyAiOSLSFMMNwPTvedvAieLSK7XOH2yty2ubdxRw3urtnBBYYEtJ2qMiXkRu0qpaiNwLe7C/iXwnKouF5E7ReRM77DjgFUi8hXQG/idd+524Le4JDMfuNPbFteeX+AjoHBhoVUvGWNin6hqtGNoF4WFhbpgwYJoh9GiQEA55v/eY1BeBk9dfli0wzHGGABE5HNVLQy1z+o5OsgXRWX4Sms4z+ZdMsbECUsQHWT20o2kJCZw0sje0Q7FGGPCYgmiAwQCyhtLN3LMAfl0S7NV44wx8cESRAdY5Ctjw45aThvdN9qhGGNM2CxBdIDZS6x6yRgTfyxBRJiq8sayTRw9zKqXjDHxxRJEhC0qKqO4rMaql4wxcccSRITNXrqR5ESx6iVjTNyxBBFBqsrspZs4elhPuqdb9ZIxJr5Ygoigxb4dVr1kjIlbliAiqKl6aZJVLxlj4pAliAhRVV5fspGj9s+36iVjTFyyBBEhS7zqpVOteskYE6csQUTI7KUbSUoQTrbqJWNMnLIEEQGqyutLN3Lk/vnkZKREOxxjjNknliAiYGnxDnylNZxu1UvGmDhmCSICXm+qXhpl1UvGmPhlCaKducFxGznCqpeMMXEurAQhIi+JyOkiYgmlDcuKyynaXsPpo/tEOxRjjPlOwr3g/wO4GFgtIneJyPBwThKRySKySkTWiMhNIfYPFJH3ROQLEVkiIqd52weLSI2ILPIeD4T9jaLs9aUbSUwQTh5pCcIYE9+SwjlIVd8G3haR7sBF3vMi4GHgSVVtaH6OiCQC9wGTAB8wX0RmqeqKoMNuAZ5T1ftFZCQwGxjs7VurqmP37WtFx87qpf3yyM206iVjTHwLu8pIRPKAy4DLgS+AvwGHAHNaOGUCsEZVv1bVemAGcFazYxTo5j3vDmwIO/IYtHxDOd9ur7beS8aYTiHcNoiXgQ+BDOAMVT1TVZ9V1euArBZO6w8UBb32eduC3Q5MFREfrvRwXdC+IV7V0/sicnQLcU0TkQUisqCkpCScrxJRO6uXRln1kjEm/oVbgrhHVUeq6h9UdWPwDlUt/A6ffxHwmKoWAKcB//IawjcCA1V1HPBfwNMi0q35yar6kKoWqmphz549v0MY311w9VIPq14yxnQC4SaIkSKS0/RCRHJF5Oo2zikGBgS9LvC2BfsJ8ByAqs4D0oB8Va1T1W3e9s+BtcABYcYaFcs3lLN+W7VN7W2M6TTCTRA/VdWypheqWgr8tI1z5gPDRGSIiKQAU4BZzY75FjgRQERG4BJEiYj09Bq5EZGhwDDg6zBjjYo3lrnqpVOseskY00mE1YsJSBQRUVWFnT2UWq1HUdVGEbkWeBNIBKar6nIRuRNYoKqzgBuBh0XkBlyD9WWqqiJyDHCniDQAAeBKVd2+T9+wg/xnzTYOHZhr1UvGmE4j3ATxb+BZEXnQe32Ft61Vqjob1/gcvO03Qc9XAEeGOO9F4MUwY4u6+sYAKzaU86MjB0c7FGOMaTfhJohf4ZLCVd7rOcAjEYkoDq3aVEG9P8DBBTnRDsUYY9pNuAPlAsD93sM0s8hXBsCYAd2jG4gxxrSjsBKEiAwD/gCMxDUkA6CqQyMUV1xZUlRGXmYK/XPSox2KMca0m3B7MT2KKz00AscDTwBPRiqoeLPYV8aYATmISLRDMcaYdhNugkhX1XcAUdX1qno7cHrkwooflXWNrN5SycEFVr1kjOlcwm2krvNGOK/2uq4W0/IUG13KsuIdqMKYATnRDsUYY9pVuCWI63HzMP0MOBSYClwaqaDiyeKiMgDGWA8mY0wn02YJwhsU931V/QVQCfwo4lHFkSW+HQzokW4D5IwxnU6bJQhV9QNHdUAscWlRUZmVHowxnVK4bRBfiMgs4Hmgqmmjqr4UkajixNbKOorLarjsiMHRDsUYY9pduAkiDdgGnBC0TYEunSCW7BwglxPVOIwxJhLCHUlt7Q4hLC7aQYLAQf33WKrCGGPiXrgjqR/FlRh2o6o/bveI4shiXxkH9M4mIyXcgpgxxsSPcK9srwU9TwPOIc7Xj/6uVJXFRWVMGtk72qEYY0xEhFvFtNvU2yLyDPBRRCKKE77SGkqrG6z9wRjTaYU7UK65YUCv9gwk3iyyAXLGmE4u3DaICnZvg9iEWyOiy1riKyMlKYHhfbKjHYoxxkREuFVMdhVsZnHRDkb160Zy4r4WwowxJraFdXUTkXNEpHvQ6xwROTtiUcW4Rn+ApcU7rHrJGNOphXv7e5uq7mh6oaplwG1tnSQik0VklYisEZGbQuwfKCLvicgXIrJERE4L2nezd94qETklzDg7xJqSSmoa/Iy1BmpjTCcWbjfXUImk1XO9Sf7uAyYBPmC+iMxS1RVBh90CPKeq94vISGA2MNh7PgUYBfQD3haRA7x5oaJuSZHLlbYGhDGmMwu3BLFARO4Wkf28x93A522cMwFYo6pfq2o9MAM4q9kxCjQNQ+7OrrEVZwEzVLVOVb8B1njvFxMW+crolpbE4LzMaIdijDERE26CuA6oB57FXehrgWvaOKc/UBT02udtC3Y7MFVEfLjSw3V7cS4iMk1EFojIgpKSkvC+STtYXFTGwQU5JCTYEqPGmM4rrAShqlWqepOqFqrqeFX9tapWtX1mmy4CHlPVAuA04F/eynVhUdWHvJgKe/bs2Q7htK22wc+qTRWMGWDVS8aYzi3cXkxzRCQn6HWuiLzZxmnFwICg1wXetmA/AZ4DUNV5uGk88sM8NyqWbyinMaAcbD2YjDGdXLh36/lezyUAVLWUtkdSzweGicgQEUnBNTrPanbMt8CJACIyApcgSrzjpohIqogMwY3c/izMWCOqaYpv68FkjOnswu3FFBCRgar6LYCIDCbE7K7BVLVRRK4F3gQSgemqulxE7gQWqOos4EbgYRG5wXu/y1RVgeUi8hywAmgEromVHkyLi8ro3S2V3t3Soh2KMcZEVLgJ4v8BH4nI+4AARwPT2jpJVWfjGp+Dt/0m6PkK4MgWzv0d8Lsw4+swS3w2QM4Y0zWE20j9b6AQWAU8g7vzr4lgXDFpR3UDX2+tshlcjTFdQriT9V0OXI9rLF4EHAbMY/clSDu9JcVlgM3gaozpGsJtpL4eGA+sV9XjgXFAWaSCilVLfG4E9WgbQW2M6QLCTRC1qloLICKpqroSGB65sGLToqIyhuZn0j09OdqhGGNMxIXbSO3zxkG8AswRkVJgfaSCilVLfGUcsV9+tMMwxpgOEe56EOd4T28Xkfdw8yb9O2JRxaBNO2rZXF5nE/QZY7qMcEsQO6nq+5EIJNYt9gbIWQ8mY0xXYcuhhWlxURlJCcLIvt3aPtgYYzoBSxBhWuLbwYF9s0lLTox2KMYY0yEsQYQhEFAW+8psgj5jTJdiCSIM32yroqK2kbGWIIwxXYgliDAsK/aWGLU1IIwxXYgliDCs21oNwJB8W2LUGNN1WIIIg6+0mt7dUklNsgZqY0zXYQkiDL7SGgpyM6IdhjHGdChLEGHwlVVTkJse7TCMMaZDWYJoQ6M/wIayWgZYCcKYfRfwg78h2lGYvWQJog2bymvxB9RKEMbsq0AAnv4+/HEovPZfsHFxtCPqXBpqYPvXEXnriCYIEZksIqtEZI2I3BRi/19EZJH3+EpEyoL2+YP2zYpknK3xlbqF86wNwph9tOCfsGYO9B0Di56CB49xj/n/hNryaEcXvypL4L0/wF9GwQs/BtV2/4i9nqwvXCKSCNwHTAJ8wHwRmeWtQw2Aqt4QdPx1uIWImtSo6thIxReuXQnCShAmDHUVUF8F2X2iHUls2LYW3roV9j8JfvAC1JbBkudh4ePw+n/BW7fAqHPh0EuhYDyIuPMCAagqgXIf7CiG8mLY4YP6SjjoPBh89K5j90bpepekeo+CkWe161ftMCVfwby/w+IZ4K+DA06FI66NyEdFLEEAE4A1qvo1gIjMAM4CVrRw/EXAbRGMZ5/4SqsRgb45adEOxcSCqm2weenuF63y4l2v67w74nGXwKn/Cyn7MHamvho++gtsXdX6cZIIvUbCgAnQ/1BIzdr7z4qkgB9evhKSUuDMe90FPT0XJk6DCT+FDQvh88dh2Yuw6EnoeSCk93BJoXwjBJq1WSSlQUIyfP6YK40cfh2MOhsSw1jAy/c5zLsXVswEDbhtYy6G0/6v4383fwNsWgJF8111W1ZP6DkCeh0I+cMhJURthSqs+wg+vhdWv+l+i7EXwWHXQM8DIhZqJBNEf6Ao6LUPmBjqQBEZBAwB3g3anCYiC4BG4C5VfSXEedOAaQADBw5sn6ib8ZXW0Ds7zcZAGKgphfsmQPXWXdsye0K3/tBjKAw52j2v3Ayf3A9Fn8L5j0Kfg8L/jKLP3EV1+1rIPwCklVrgxjpY/pJ7LgnurnjARPcoGA+5g/ftLru9/Odv4PsMzn0EuvXbfZ+IS2r9D4VTfgfLXoIlzwEKAw5zx3cvcL9n9/7QrQAyerjvvORZdwf90uXw9m0w8UpXAklrNtNBwA+r3nDHfjsPUrvD4dfC+Mvhiyfhg/9z8Z3/KPQ9OPzv1VjvEtq6jyCrjxdfPxdj9/6Q1RsSgq4XlSXuc4q8x4YvoNHVTJDZy5Wq/PVNP4z779ZrhEuYvUa47/Hp/S6ZZOTDcTe775AZ+cXLRCNQbwUgIucDk1X1cu/1JcBEVd2jLCQivwIKVPW6oG39VbVYRIbiEseJqrq2pc8rLCzUBQsWtPv3+P6D8wio8vyVR7T7e5s48+7/uIvKBY+7C0p2P0huoWT59Vx4aRrUlLkL4PjLW79YN9TC3N+7O8RuBXDW32HosW3HVFMGxQu8i8+n7k65vsLty+zlShcDJkDBBOg3FpLDrCqtr3YXMt9nsOVLGHsxDD0uvHMBNi2Dh46DA09zv1d7J6pAwLVrfHwvrPsQUrLhkB/CYVe6i+jip2HeP1yi7T4QDrsKDrkEUrN3vcc3H8JLP4XqbTDptzDxitbj9De46qkP/gQ7itx//9oyaKje/biEJMju65JGVcmuBuSEZFfyGTARBox3/0269wd/oztmywooWel+75KVsG0NBBrduXnD4PBrYMyU8P8bhklEPlfVwpD7IpggDgduV9VTvNc3A6jqH0Ic+wVwjap+3MJ7PQa8pqovtPR5kUoQR971LhOG9OAv3x/b7u9t4kj1dvjraNj/RLjwifDOqSyBV65yF7IDv+eqWTJ67Hlc8UJ3XMlKOORSOPl/IG0f1x0J+N0FZucd66fNLlAHexeoCbsuUKquqqzoU/DNd383Ld11cUrt5tpVTvujS3RtaayHh09wJamrP4HMvH37LuHasMiVEpZ5panULKjdAf0OgSOugxFnQmILlSVV22Dm1fDVv11d/ln37RmvvxGWzID3/whl612p57hfu/8XwJUsy4uhfMOeVY5p3b0kPRH6jm35hiKUxnqX4GrLXYkwITJ9iqKVIJKAr4ATgWJgPnCxqi5vdtyBuOVLh6gXjIjkAtWqWici+cA84KzgBu7mIpEgGv0Bht/6b64+bj9uPHl4u753zPvyNfhyFhz7K8jbL9rRRN/bd7h2gas+ht4jwz8vEIBP7nPnZ/WG8x6BQYe7fY318MEf4cO73b4z74VhJ7V/7FVbXbJoShrFn0NjrdvXzUsQFRvc6+QMdwFsSiAF410bwgs/cXXfE69yJaKEVqpc37kTPvwzXDQDhp/a/t+nJTt88OmDULEJCn8EAw8Pr+Si6s6bc6srfZz3MAw+yiWGpc/D+/8Lpd+4C/zxv4ZhJ0e36q6dtZYgItYGoaqNInIt8CaQCExX1eUiciewQFWbuq5OAWbo7plqBPCgiARwXXHvai05RMrGHV10DMRXb8Hzl7o7yOWvwDG/gCOvh6TUaEcWHVVb3QXkoHP3LjmAu+s74joYdKTrivjYaa4OedjJMPNa1+A95iKYfBek50QkfDLzXVXPgae51/4GV0JoShqS4JLBgAnQ+6DQd9sXPeN6I31yn7urPe+foUs5RfNdIh07tWOTA7g2i5N/u/fnibiqqUGHw/M/gsfPcCW5bz5w37XPaJjyjPs+nSgxhCNiJYiOFokSxLy127jo4U946vKJHLl/5BuEYsK6/8CT50LP4a5xce7vYfnLrg70e3fDkGM6PqYdxa5+NjXbe3Tb9by1O9n28tatrgrj6k+/W4+R2nLXtXPp8+51Zi8442+7LtzxYMF0eP0X7v+Pi5+FnKDOIfXV8ODRriH5qo/3vZosmuoqYfYvXRtG74PguJtc9WAnTgxRKUF0Br5S1/jUZUoQGxbBM1PcP/qpL7k7zwsec3eDs290d1ZjLnINelk9Oy6u537oGmJDScnaPWGkdQtKIt2CXme77zXk2L37x165BT57GEZf8N27E6Z1g3MfdmMCihe6i0+oNolYVvhjyB0Cz13q2hmmPOMaXAHevt01rF76anwmB3DtF+fc70rNuUMiVu8fLyxBtKKotIYEgb7du0CCKPnKlRzScuCSV3bvQjfsJNfY+MGfXNfFVW/ApDtg3A93/wfkb/B6Y3i9MLasgLIiOP3P0P+QfYurdL1LDhOvgmGT3DiDugr3qG16Xr5re225K3E0va6v3P39TroDjvp5+J//0V9dF8Rjf7Vv8Tcn4nqijJnSPu8XDfsdD5e/DU9fCI+dDmf/w/3/8tmDrstpNEqZ7c3a3QBLEK3ylVbTp1saKUlxdhexYZFrbAz3jrfsW/jX2W7g1Q9fcT1bmktOhxNvhYMvhNdugFevh0VPw/6ToORL2LIStn4VNLjJ689dscndgZ9z/759ly+9pqqJ09xYg70V8O9KInNuc3e5efvBiDPaPrd8o5smYsxFdsForucB8NN34dmp8OJP3BiDvP3hxJgb62q+A0sQrYjLdSAqNsP0U1wvlWGnuCH4rU1LULkFnjjL3WlfNrvtC2HP4XDZ67D4GXjz/7kukTkD3UjQYSftOSJ05jWwfKZrv9iX/tsrZkKfg/ctOYBro0jPcY+z/+H6r7/4U/jxG9BvXOvnfvQX11B/zC/27bM7u4werrT52g2uXeWcB0OPAjZxyxJEK4pLa5g4JM7qiD++x1WJHHEdLHrGtRv0ORiO+Nme0xLUlMK/znF3+T+cGf6IXxE3cGrUua7EEDz4qLmDznejVle/tfdz3+zwuX75J/5m785rSXI6THkaHj4RnrnI3QE3H+G787OL4fNHYewPoMeQ9vn8zigpBc6+z01ZYcmh04mzupOO0+APsHFHTXw1UFeWuBkyR1/oBlvdsMz1kmmsddMS/G0M/OceN4iovgqeuhBKVsGUp1wXx72VnNZ6cgBXH53ZC5a2OMaxZSu86qUR7TipWlYv1/umrtJNQV1XGfq4D//s+sdb6SE8lhw6JUsQLdi0o5aAxtk03x/f42Z3bLqoJafDoZe57pkXP+eqaebcCnePgkdOco2/5/8T9jshcjElJMKoc+CrN11i2hsrZrquhvn7t29MvUfCBY/C5mVuOoyAf/f9Zd/Cwifc1A3B3TiN6WIsQbSgaLvXxbVHnJQgqrbC/EfcVMj5w3bfl5AAB5wCl70G0953A362f+NG7nbElMejL3CJa+Xr4Z9TvgGKPolcfMMmucFpq153E74F++BPrhrt6Bsj89nGxAlrg2hB0zoQe7XUqGr0BtTMu8+tLHXML1s/rt9YN5VAR8ZaUAg5g1w109iLwzvny1fd35FnRywsJl4BW1e7Cd/yhrkZQbd/4yZkK/xJ6N5cxnQhliBa4CutJkGgT/cwJtdShZevcLNCXvx8xw+uqd4Onz3kqnJ6hjlnVEcmMhFXsvnP31w7STiD7FbMdD2iIjjXPeBKEaXfuBHOuYPdlNMJSXDUDW2eakxnZ1VMLfCV1tC3ezrJiWH8RAumuznq17wNS5/b9w+t3eHm/Kmv2rvzPvmH66Z67H/v+2dH2ujzQf2w4pW2j63YDOs/7pjqr8QkOH+6K0E8e4nrvlv4E+jWN/KfbUyMswTRAl9pDf3D6cFUssqNB9jvBDe98Nu3t9wzpi1v3ARv/LebMMzfGN45NaUuqYw8yy0uEqt6j3Krn4XTm2nlq4B23JKQad1dz6bEZEhM2buR1sZ0YpYgWuArrW67i2tjnRtFmpIBZ9/vqisqNrqqlL219j03QdiAw9y0yq/fEN4i5J884EYJHxPDpYcmB53nGp7Lilo/bvkrbjW1jkx4uYPgJ2+5hvysXh33ucbEMEsQIdQ3BthYXtt2A/W7/+OmTT7z726R+oET3cCwj+9xXSXD/sBqeO3n0GM/N2Dt6F+4bpbv/7H182rK3NKWB35v75a1jJaDznN/l73Y8jGVJbD+P6700NEN/nn7uQZ1YwxgCSKkjTtqUG1jFtev57pEUPjj3adrnnQHIG7en3C9/79Qus4NaktOgxNucQuqz/29SxQt+ewhqNsR220PwXoMgf6FrVczrXzNLSrfUdVLxpgWWYIIoamLa4uD5Kq3w8tXuYbNk3+3+77uBXDkz9xi8uvntf1hG5e4bpbjLnGL3oO7cz7zHtjvRHj1524Bn+Zqy13X1uGnuXVu48XoC9wiOSWrQu9fMdMN6OsdByUiYzo5SxAhtLoOhKqbybSqxC0fGWqKgSOvdwua//smt+RkSwJ+ePVnbtKzSXfuvi8x2a193Ge0W92t+PPd93/2kFswva1xD7Fm1DluBbNQpYiqbW4Vr5Fnd+oFWoyJF5YgQvCV1pCYIPQNNQbiiyfdFNQn3uoGnYWSkumqmjYuct0mW/Lpg7DhC9e4HWrhmNQs+MHzkNnTzZu0ba3bXlfhVjgbdvK+r7MQLdm93eyyy17YsxF+1euuK6xVLxkTEyxBhOArraFPtzSSmo+B2LYW3viVm4Du8Otaf5PRF7gF39+5w13Qmyv71jVyDzt5V+NtKFm93OpuGoAnz/Mm5HvEdW9tr0VsOtro893CQhsW7r59xUw34jqeqsyM6cQimiBEZLKIrBKRNSJyU4j9fxGRRd7jKxEpC9p3qYis9h6XRjLO5oq2h+ji6m+AFy93VT9nP9D2aGkRVzKo3Awf3r37PlV43Zvn5/Q/t12dkr+/m2yvYpNbxevje137RLz2uBlxBiQkw9Kg3kzV213DfzR6LxljQopYghCRROA+4FRgJHCRiIwMPkZVb1DVsao6FrgXeMk7twdwGzARmADcJiK5kYq1OV9pDQN6NGtbmHuXu+M9857w5+gpKISDv+8ak0vX7dq+/CW3PsIJt4Q/W+iA8W4G0o2L3JQex+2Rb+NHeq4rOS1/addMqqvecIvzjDo7qqEZY3aJZAliArBGVb9W1XpgBtBa5fJFQFOF/SnAHFXdrqqlwBxgcgRj3amu0c/mitrdSxC+BW59gHFT975+/KTb3ZTXb93qXldvd9VU/ca5yeL2xvBT4bx/wnE379v6DbFk9HluUOH6j93rFTOh+wA3Gt0YExMiOVlffyB4yKwPVyLYg4gMAoYA77Zy7h637SIyDZgGMHBg+8zbv7Gs1hsDEVSC+Phet2Tl5Lv2/g279XMTv733O1j3ESye4ZLE1Jdc4thbB5279+fEogNOheRMt1Rl34Nh7bsuYVr1kjExI1YaqacAL6iqv80jg6jqQ6paqKqFPXuGMUNoGHaNgfBKEBWb3eCtMRe3vXpaS464zt0dv3QFfPEvt05034PbJd64lZLhBhiumOlWjgs0RHZqb2PMXotkgigGBgS9LvC2hTKFXdVLe3tuu9pjDMSiJ13deOGP9v1Nk9Ndt9dyn5tS+tg4bj9oT6MvcGM53rkDuvWH/odGOyJjTJBIVjHNB4aJyBDcxX0KsMdqMSJyIJALBA87fhP4fVDD9MnAzRGMdaei0moSE4Q+3dLcILfPH3P99puv0ra3Rp3rurbud4Kt39tk6PGuwbqqBCZe1fHraBhjWhWxf5Gq2ghci7vYfwk8p6rLReROETkz6NApwAzVXaOmVHU78FtckpkP3OltizhfaQ39crwxEGvfdRf171J6aCLi2iKsj/8uSSm7Gv1tcJwxMSeiK8qp6mxgdrNtv2n2+vYWzp0OTI9YcC3wldZQkOPd4X/+KGTkw4FndHQYXcfRN7quvgNC9l8wxkSRlemb2bkORPkG1zd/3FR3p2siI2egSxJWvWRMzLF/lUHqGv1sLq9zXVwX/svNC3Rohw7iNsaYmGEJIsiGsloABnRPhoWPuwblHkOjHJUxxkSHJYggRdtdF9dR1Z9BeTEc2g6N08YYE6csQQRpGiQ3aN2zkNXbTW1hjDFdlCWIIL7SagYmbCX1m3fgkB+6mVuNMaaLsgQRxFdaw08yPkTAJQhjjOnCLEEE2bi9nDMD77ipqMOdhtsYYzopSxBBhmz/kNzA9vYZOW2MMXHOEoSntsHP9+r/TUVqb1eCMMaYLs4ShGfz+i85JnEpRUPO37d1GowxppOxBOGRhY/TqAnUj54a7VCMMSYmWIIAaKyn15rneSdwCL0LhkQ7GmOMiQmWIABWvkpafSkz9CR6ZadFOxpjjIkJEZ3uO24seJStyX35JmMCiQm2JrIxxoCVIGDbWlj3IW+knEz/HpnRjsYYY2KGJYgeQ+HHb/J47bEMyLWlQI0xpoklCBFq+45nTVWaWyjIGGMMEOEEISKTRWSViKwRkZtaOOZCEVkhIstF5Omg7X4RWeQ9ZkUyzqZZXAusBGGMMTtFrJFaRBKB+4BJgA+YLyKzVHVF0DHDgJuBI1W1VER6Bb1FjaqOjVR8wXylbh0IK0EYY8wukSxBTADWqOrXqloPzADOanbMT4H7VLUUQFW3RDCeFlkJwhhj9hTJBNEfKAp67fO2BTsAOEBE/iMin4jI5KB9aSKywNt+dgTjpKi0mpTEBHplp0byY4wxJq5EexxEEjAMOA4oAD4QkdGqWgYMUtViERkKvCsiS1V1bfDJIjINmAYwcOC+T8/tK62hf246CTYGwhhjdopkCaIYGBD0usDbFswHzFLVBlX9BvgKlzBQ1WLv79fAXGBc8w9Q1YdUtVBVC3v27LnPgfpKa6z9wRhjmolkgpgPDBORISKSAkwBmvdGegVXekBE8nFVTl+LSK6IpAZtPxJYQYQUl1ZbgjDGmGYiVsWkqo0ici3wJpAITFfV5SJyJ7BAVWd5+04WkRWAH/ilqm4TkSOAB0UkgEtidwX3fmpPNfV+tlbWWwO1McY0E9E2CFWdDcxutu03Qc8V+C/vEXzMx8DoSMbWpKbBz5lj+jG6f/eO+DhjjIkb0W6kjroemSncc9EezRvGGNPl2VQbxhhjQrIEYYwxJiRLEMYYY0KyBGGMMSYkSxDGGGNCsgRhjDEmJEsQxhhjQrIEYYwxJiRxg5njn4iUAOu/w1vkA1vbKZxIi6dYIb7ijadYIb7ijadYIb7i/S6xDlLVkLOddpoE8V2JyAJVLYx2HOGIp1ghvuKNp1ghvuKNp1ghvuKNVKxWxWSMMSYkSxDGGGNCsgSxy0PRDmAvxFOsEF/xxlOsEF/xxlOsEF/xRiRWa4MwxhgTkpUgjDHGhGQJwhhjTEhdPkGIyGQRWSUia0TkpmjH0xYRWSciS0VkkYgsiHY8wURkuohsEZFlQdt6iMgcEVnt/c2NZozBWoj3dhEp9n7fRSJyWjRjbCIiA0TkPRFZISLLReR6b3vM/b6txBqrv22aiHwmIou9eO/wtg8RkU+9a8OzIpISw7E+JiLfBP22Y9vl87pyG4SIJAJfAZMAHzAfuChS61+3BxFZBxSqaswN4BGRY4BK4AlVPcjb9kdgu6re5SXgXFX9VTTjbNJCvLcDlar6p2jG1pyI9AX6qupCEckGPgfOBi4jxn7fVmK9kNj8bQXIVNVKEUkGPgKuxy2F/JKqzhCRB4DFqnp/jMZ6JfCaqr7Qnp/X1UsQE4A1qvq1qtYDM4CzohxT3FLVD4DtzTafBTzuPX8cd6GICS3EG5NUdaOqLvSeVwBfAv2Jwd+3lVhjkjqV3stk76HACUDTBTdWftuWYo2Irp4g+gNFQa99xPD/yB4F3hKRz0VkWrSDCUNvVd3oPd8E9I5mMGG6VkSWeFVQUa+yaU5EBgPjgE+J8d+3WawQo7+tiCSKyCJgCzAHWAuUqWqjd0jMXBuax6qqTb/t77zf9i8iktoen9XVE0Q8OkpVDwFOBa7xqknigrr6zFiv07wf2A8YC2wE/hzVaJoRkSzgReDnqloevC/Wft8Qscbsb6uqflUdCxTgahYOjG5ELWseq4gcBNyMi3k80ANol2rGrp4gioEBQa8LvG0xS1WLvb9bgJdx/zPHss1enXRT3fSWKMfTKlXd7P0DDAAPE0O/r1fn/CLwlKq+5G2Oyd83VKyx/Ns2UdUy4D3gcCBHRJK8XTF3bQiKdbJXraeqWgc8Sjv9tl09QcwHhnm9FVKAKcCsKMfUIhHJ9Br9EJFM4GRgWetnRd0s4FLv+aXAzCjG0qami63nHGLk9/UaJ/8JfKmqdwftirnft6VYY/i37SkiOd7zdFynlS9xF9/zvcNi5bcNFevKoJsEwbWVtMtv26V7MQF4Xe3+CiQC01X1d9GNqGUiMhRXagBIAp6OpXhF5BngONzUw5uB24BXgOeAgbjp2C9U1ZhoGG4h3uNwVSAKrAOuCKrjjxoROQr4EFgKBLzNv8bV7cfU79tKrBcRm7/twbhG6ETcTfNzqnqn9+9tBq7K5gtgqneHHjWtxPou0BMQYBFwZVBj9r5/XldPEMYYY0Lr6lVMxhhjWmAJwhhjTEiWIIwxxoRkCcIYY0xIliCMMcaEZAnCmBggIseJyGvRjsOYYJYgjDHGhGQJwpi9ICJTvfn4F4nIg97EaZXeBGnLReQdEenpHTtWRD7xJlB7uWlyOhHZX0Te9ub0Xygi+3lvnyUiL4jIShF5yhsVa0zUWIIwJkwiMgL4PnCkN1maH/gBkAksUNVRwPu4EdkATwC/UtWDcaOKm7Y/BdynqmOAI3AT14Gb9fTnwEhgKHBkhL+SMa1KavsQY4znROBQYL53c5+OmxwvADzrHfMk8JKIdAdyVPV9b/vjwPPeXFr9VfVlAFWtBfDe7zNV9XmvFwGDcQvCGBMVliCMCZ8Aj6vqzbttFLm12XH7On9N8Dw/fuzfp4kyq2IyJnzvAOeLSC/YuR70INy/o6ZZPy8GPlLVHUCpiBztbb8EeN9bYc0nImd775EqIhkd+SWMCZfdoRgTJlVdISK34Fb0SwAagGuAKtzCLbfgqpy+751yKfCAlwC+Bn7kbb8EeFBE7vTe44IO/BrGhM1mczXmOxKRSlXNinYcxrQ3q2IyxhgTkpUgjDHGhGQlCGOMMSFZgjDGGBOSJQhjjDEhWYIwxhgTkiUIY4wxIf1/E2tUwUu74xcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model.load_weights('py/DenseNet201/densenet201_2_n')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "plot_acc(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 2ms/step\n",
      "Loss: 3.0776201152801512\n",
      "Accuracy: 0.7559999823570251\n",
      "predict accurscy: 0.756, precision: 0.7579872697519757, recall: 0.7660714285714286, f1: 0.7605567248384929\n"
     ]
    }
   ],
   "source": [
    "#測試集預測\n",
    "model.load_weights('py/DenseNet201/densenet201_2_n')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6130/6130 [==============================] - 11s 2ms/step\n",
      "Loss: 0.7094301913730653\n",
      "Accuracy: 0.9551386833190918\n",
      "predict accurscy: 0.9551386623164764, precision: 0.9562045383582559, recall: 0.955614148603526, f1: 0.9558733966297362\n"
     ]
    }
   ],
   "source": [
    "#訓練集預測\n",
    "model.load_weights('py/DenseNet201/densenet201_2_n')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(train_x,train_y)\n",
    "pred_cy = model.predict_classes(train_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_x, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料增強"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Model)          (None, 7, 7, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 94080)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 94080)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               48169472  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 66,492,995\n",
      "Trainable params: 66,263,939\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "DenseNet201_model = DenseNet201(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "# model = add_new_last_layer(model, 3)\n",
    "\n",
    "# net.trainable = False\n",
    "model = Sequential()\n",
    "model.add(DenseNet201_model)\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Conv2D(256, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(Flatten()) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(512, activation='relu')) \n",
    "# model.add(Dense(128, activation='relu')) \n",
    "# model.add(Dropout(0.1)) \n",
    "model.add(Dense(3, activation='softmax')) \n",
    "\n",
    "# x = base_model.output\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# # # 增加 DropOut layer\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# output_layer = Dense(3, activation='softmax')(x)\n",
    "# model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10)\n",
    "modelcheckpoint = keras.callbacks.ModelCheckpoint(filepath='py/DenseNet201/densenet201_2', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "# reduceLronplateau = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.001, cooldown=0, min_lr=0)\n",
    "reduceLronplateau=ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                             patience=7,\n",
    "                             # 3 epochs 內acc沒下降就要調整LR\n",
    "                             verbose=1,\n",
    "                             factor=0.5,\n",
    "                             # LR降為0.5\n",
    "                             min_lr=0.00001\n",
    "                             # 最小 LR 到0.00001就不再下降\n",
    "                             )\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr=1e-4), metrics = ['accuracy'])\n",
    "# train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "# test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "# train_datagen = ImageDataGenerator(rotation_range=0.2, zoom_range=0.05,\n",
    "#                                    featurewise_center = True, featurewise_std_normalization = True,\n",
    "#                                     width_shift_range=0.05, height_shift_range=0.05, shear_range=0.05,\n",
    "#                                     horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# train_datagen=ImageDataGenerator(rotation_range=15 , \n",
    "#                              width_shift_range=0.2 , \n",
    "#                              height_shift_range=0.2 ,\n",
    "#                              shear_range=0.2 ,\n",
    "#                              zoom_range=0.2 , \n",
    "#                              data_format='channels_last')\n",
    "\n",
    "# train_datagen.fit(train_x)\n",
    "\n",
    "# history = model.fit_generator(train_datagen.flow(train_x[:5000],train_y[:5000],batch_size=20), \n",
    "#                               steps_per_epoch=100 , epochs=500,\n",
    "#                               validation_data=(train_x[5000:],train_y[5000:]),validation_steps=100,\n",
    "#                               callbacks=[modelcheckpoint, earlystopping, reduceLronplateau])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step\n",
      "Loss: 1.3140835013389587\n",
      "Accuracy: 0.8119999766349792\n",
      "predict accurscy: 0.812, precision: 0.8135405053883314, recall: 0.8206349206349207, f1: 0.8159651608016943\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# model.load_weights('py/mango')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "plot_acc(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step\n",
      "Loss: 0.7850775408744812\n",
      "Accuracy: 0.828000009059906\n",
      "predict accurscy: 0.828, precision: 0.8286215816703623, recall: 0.8373015873015873, f1: 0.8305101300440922\n"
     ]
    }
   ],
   "source": [
    "#測試集預測\n",
    "model.load_weights('py/DenseNet201/densenet201_2')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6130/6130 [==============================] - 35s 6ms/step\n",
      "Loss: 0.30890823635736064\n",
      "Accuracy: 0.8928222060203552\n",
      "predict accurscy: 0.8928221859706362, precision: 0.8935311121783399, recall: 0.8959252299122826, f1: 0.8945200541916689\n"
     ]
    }
   ],
   "source": [
    "#訓練集預測\n",
    "model.load_weights('py/DenseNet201/densenet201_2')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(train_x,train_y)\n",
    "pred_cy = model.predict_classes(train_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_x, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 12,977,283\n",
      "Trainable params: 12,977,283\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 5000 samples, validate on 1130 samples\n",
      "Epoch 1/500\n",
      "5000/5000 [==============================] - 4s 700us/step - loss: 0.9878 - accuracy: 0.4942 - val_loss: 0.9031 - val_accuracy: 0.5416\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.54159, saving model to py/CNN/cnn_n2\n",
      "Epoch 2/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 0.8596 - accuracy: 0.5870 - val_loss: 0.8519 - val_accuracy: 0.5876\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.54159 to 0.58761, saving model to py/CNN/cnn_n2\n",
      "Epoch 3/500\n",
      "5000/5000 [==============================] - 2s 454us/step - loss: 0.8277 - accuracy: 0.6080 - val_loss: 0.9237 - val_accuracy: 0.5602\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.58761\n",
      "Epoch 4/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 0.8007 - accuracy: 0.6248 - val_loss: 0.8949 - val_accuracy: 0.5850\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.58761\n",
      "Epoch 5/500\n",
      "5000/5000 [==============================] - 2s 455us/step - loss: 0.7729 - accuracy: 0.6492 - val_loss: 0.8019 - val_accuracy: 0.6345\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.58761 to 0.63451, saving model to py/CNN/cnn_n2\n",
      "Epoch 6/500\n",
      "5000/5000 [==============================] - 2s 449us/step - loss: 0.7218 - accuracy: 0.6666 - val_loss: 0.8355 - val_accuracy: 0.6097\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.63451\n",
      "Epoch 7/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 0.6830 - accuracy: 0.6982 - val_loss: 0.8050 - val_accuracy: 0.6354\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.63451 to 0.63540, saving model to py/CNN/cnn_n2\n",
      "Epoch 8/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 0.6211 - accuracy: 0.7218 - val_loss: 0.8134 - val_accuracy: 0.6407\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.63540 to 0.64071, saving model to py/CNN/cnn_n2\n",
      "Epoch 9/500\n",
      "5000/5000 [==============================] - 2s 455us/step - loss: 0.5453 - accuracy: 0.7642 - val_loss: 0.8400 - val_accuracy: 0.6451\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.64071 to 0.64513, saving model to py/CNN/cnn_n2\n",
      "Epoch 10/500\n",
      "5000/5000 [==============================] - 2s 450us/step - loss: 0.4633 - accuracy: 0.8052 - val_loss: 0.8712 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.64513 to 0.65929, saving model to py/CNN/cnn_n2\n",
      "Epoch 11/500\n",
      "5000/5000 [==============================] - 2s 449us/step - loss: 0.3671 - accuracy: 0.8488 - val_loss: 0.9845 - val_accuracy: 0.6646\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.65929 to 0.66460, saving model to py/CNN/cnn_n2\n",
      "Epoch 12/500\n",
      "5000/5000 [==============================] - 2s 450us/step - loss: 0.2806 - accuracy: 0.8838 - val_loss: 1.1783 - val_accuracy: 0.6442\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66460\n",
      "Epoch 13/500\n",
      "5000/5000 [==============================] - 2s 448us/step - loss: 0.1997 - accuracy: 0.9242 - val_loss: 1.2846 - val_accuracy: 0.6637\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66460\n",
      "Epoch 14/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 0.1754 - accuracy: 0.9334 - val_loss: 1.3259 - val_accuracy: 0.6611\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66460\n",
      "Epoch 15/500\n",
      "5000/5000 [==============================] - 2s 445us/step - loss: 0.1389 - accuracy: 0.9488 - val_loss: 1.6918 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.66460 to 0.67080, saving model to py/CNN/cnn_n2\n",
      "Epoch 16/500\n",
      "5000/5000 [==============================] - 2s 451us/step - loss: 0.1117 - accuracy: 0.9586 - val_loss: 1.6496 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.67080 to 0.67168, saving model to py/CNN/cnn_n2\n",
      "Epoch 17/500\n",
      "5000/5000 [==============================] - 2s 454us/step - loss: 0.0711 - accuracy: 0.9760 - val_loss: 1.8597 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67168\n",
      "Epoch 18/500\n",
      "5000/5000 [==============================] - 2s 453us/step - loss: 0.0633 - accuracy: 0.9796 - val_loss: 2.0447 - val_accuracy: 0.6425\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67168\n",
      "Epoch 19/500\n",
      "5000/5000 [==============================] - 2s 450us/step - loss: 0.0522 - accuracy: 0.9828 - val_loss: 2.2647 - val_accuracy: 0.6628\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67168\n",
      "Epoch 20/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 0.0821 - accuracy: 0.9726 - val_loss: 2.1050 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67168\n",
      "Epoch 21/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 0.0499 - accuracy: 0.9830 - val_loss: 2.2720 - val_accuracy: 0.6434\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67168\n",
      "Epoch 22/500\n",
      "5000/5000 [==============================] - 2s 454us/step - loss: 0.0427 - accuracy: 0.9878 - val_loss: 2.3108 - val_accuracy: 0.6619\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67168\n",
      "Epoch 23/500\n",
      "5000/5000 [==============================] - 2s 451us/step - loss: 0.0460 - accuracy: 0.9834 - val_loss: 2.5112 - val_accuracy: 0.6451\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67168\n",
      "Epoch 24/500\n",
      "5000/5000 [==============================] - 2s 446us/step - loss: 0.0511 - accuracy: 0.9840 - val_loss: 2.2249 - val_accuracy: 0.6513\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67168\n",
      "Epoch 25/500\n",
      "5000/5000 [==============================] - 2s 453us/step - loss: 0.0438 - accuracy: 0.9852 - val_loss: 2.5541 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.67168\n",
      "Epoch 26/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 0.0362 - accuracy: 0.9894 - val_loss: 2.4871 - val_accuracy: 0.6814\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.67168 to 0.68142, saving model to py/CNN/cnn_n2\n",
      "Epoch 27/500\n",
      "5000/5000 [==============================] - 2s 455us/step - loss: 0.0453 - accuracy: 0.9876 - val_loss: 2.2248 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.68142\n",
      "Epoch 28/500\n",
      "5000/5000 [==============================] - 2s 457us/step - loss: 0.0191 - accuracy: 0.9946 - val_loss: 2.6004 - val_accuracy: 0.6611\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.68142\n",
      "Epoch 29/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 0.0497 - accuracy: 0.9850 - val_loss: 2.2749 - val_accuracy: 0.6628\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.68142\n",
      "Epoch 30/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 2.4993 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.68142\n",
      "Epoch 31/500\n",
      "5000/5000 [==============================] - 2s 449us/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 2.4704 - val_accuracy: 0.6478\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.68142\n",
      "Epoch 32/500\n",
      "5000/5000 [==============================] - 2s 454us/step - loss: 0.0290 - accuracy: 0.9890 - val_loss: 2.5256 - val_accuracy: 0.6558\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.68142\n",
      "Epoch 33/500\n",
      "5000/5000 [==============================] - 2s 457us/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 2.7463 - val_accuracy: 0.6549\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.68142\n",
      "Epoch 34/500\n",
      "5000/5000 [==============================] - 2s 456us/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 2.6209 - val_accuracy: 0.6504\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.68142\n",
      "Epoch 35/500\n",
      "5000/5000 [==============================] - 2s 446us/step - loss: 0.0486 - accuracy: 0.9854 - val_loss: 2.5990 - val_accuracy: 0.6389\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.68142\n",
      "Epoch 36/500\n",
      "5000/5000 [==============================] - 2s 456us/step - loss: 0.0331 - accuracy: 0.9886 - val_loss: 2.4709 - val_accuracy: 0.6655\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.68142\n",
      "Epoch 37/500\n",
      "5000/5000 [==============================] - 2s 451us/step - loss: 0.0368 - accuracy: 0.9874 - val_loss: 2.3428 - val_accuracy: 0.6602\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.68142\n",
      "Epoch 38/500\n",
      "5000/5000 [==============================] - 2s 453us/step - loss: 0.0315 - accuracy: 0.9914 - val_loss: 2.6504 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.68142\n",
      "Epoch 39/500\n",
      "5000/5000 [==============================] - 2s 455us/step - loss: 0.0324 - accuracy: 0.9894 - val_loss: 2.3811 - val_accuracy: 0.6770\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.68142\n",
      "Epoch 40/500\n",
      "5000/5000 [==============================] - 2s 455us/step - loss: 0.0409 - accuracy: 0.9868 - val_loss: 2.3917 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.68142\n",
      "Epoch 41/500\n",
      "5000/5000 [==============================] - 2s 458us/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 2.7935 - val_accuracy: 0.6619\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.68142\n",
      "Epoch 42/500\n",
      "5000/5000 [==============================] - 2s 446us/step - loss: 0.0304 - accuracy: 0.9918 - val_loss: 2.4615 - val_accuracy: 0.6584\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.68142\n",
      "Epoch 43/500\n",
      "5000/5000 [==============================] - 2s 450us/step - loss: 0.0306 - accuracy: 0.9904 - val_loss: 2.3979 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.68142\n",
      "Epoch 44/500\n",
      "5000/5000 [==============================] - 2s 449us/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 2.4811 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.68142\n",
      "Epoch 45/500\n",
      "5000/5000 [==============================] - 2s 449us/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 2.8538 - val_accuracy: 0.6584\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.68142\n",
      "Epoch 46/500\n",
      "5000/5000 [==============================] - 2s 450us/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 2.8767 - val_accuracy: 0.6584\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.68142\n",
      "Epoch 47/500\n",
      "5000/5000 [==============================] - 2s 454us/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 2.8887 - val_accuracy: 0.6487\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.68142\n",
      "Epoch 48/500\n",
      "5000/5000 [==============================] - 2s 455us/step - loss: 0.0148 - accuracy: 0.9946 - val_loss: 2.8924 - val_accuracy: 0.6460\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.68142\n",
      "Epoch 49/500\n",
      "5000/5000 [==============================] - 2s 446us/step - loss: 0.0227 - accuracy: 0.9940 - val_loss: 2.7834 - val_accuracy: 0.6602\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.68142\n",
      "Epoch 50/500\n",
      "5000/5000 [==============================] - 2s 450us/step - loss: 0.0496 - accuracy: 0.9858 - val_loss: 2.5934 - val_accuracy: 0.6425\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.68142\n",
      "Epoch 51/500\n",
      "5000/5000 [==============================] - 2s 445us/step - loss: 0.0284 - accuracy: 0.9900 - val_loss: 2.5006 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.68142\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 52/500\n",
      "5000/5000 [==============================] - 2s 453us/step - loss: 0.0056 - accuracy: 0.9972 - val_loss: 2.7142 - val_accuracy: 0.6779\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.68142\n",
      "Epoch 53/500\n",
      "5000/5000 [==============================] - 2s 460us/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 3.0245 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.68142\n",
      "Epoch 54/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 2.9635 - val_accuracy: 0.6796\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.68142\n",
      "Epoch 55/500\n",
      "5000/5000 [==============================] - 2s 455us/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 3.0156 - val_accuracy: 0.6867\n",
      "\n",
      "Epoch 00055: val_accuracy improved from 0.68142 to 0.68673, saving model to py/CNN/cnn_n2\n",
      "Epoch 56/500\n",
      "5000/5000 [==============================] - 2s 456us/step - loss: 6.8210e-04 - accuracy: 0.9998 - val_loss: 3.1808 - val_accuracy: 0.6788\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.68673\n",
      "Epoch 57/500\n",
      "5000/5000 [==============================] - 2s 451us/step - loss: 4.2584e-04 - accuracy: 1.0000 - val_loss: 3.1529 - val_accuracy: 0.6858\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.68673\n",
      "Epoch 58/500\n",
      "5000/5000 [==============================] - 2s 446us/step - loss: 3.9285e-04 - accuracy: 1.0000 - val_loss: 3.2438 - val_accuracy: 0.6823\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.68673\n",
      "Epoch 59/500\n",
      "5000/5000 [==============================] - 2s 446us/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 3.0802 - val_accuracy: 0.6761\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.68673\n",
      "Epoch 60/500\n",
      "5000/5000 [==============================] - 2s 446us/step - loss: 2.2882e-04 - accuracy: 1.0000 - val_loss: 3.1165 - val_accuracy: 0.6858\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.68673\n",
      "Epoch 61/500\n",
      "5000/5000 [==============================] - 2s 450us/step - loss: 3.3097e-04 - accuracy: 1.0000 - val_loss: 3.2424 - val_accuracy: 0.6823\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.68673\n",
      "Epoch 62/500\n",
      "5000/5000 [==============================] - 2s 457us/step - loss: 7.0138e-04 - accuracy: 0.9996 - val_loss: 3.2552 - val_accuracy: 0.6664\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.68673\n",
      "Epoch 63/500\n",
      "5000/5000 [==============================] - 2s 447us/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 3.2449 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.68673\n",
      "Epoch 64/500\n",
      "5000/5000 [==============================] - 2s 450us/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 3.2878 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.68673\n",
      "Epoch 65/500\n",
      "5000/5000 [==============================] - 2s 446us/step - loss: 1.8784e-04 - accuracy: 1.0000 - val_loss: 3.3638 - val_accuracy: 0.6726\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.68673\n",
      "Epoch 66/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 3.4308 - val_accuracy: 0.6602\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.68673\n",
      "Epoch 67/500\n",
      "5000/5000 [==============================] - 2s 451us/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 3.3700 - val_accuracy: 0.6832\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.68673\n",
      "Epoch 68/500\n",
      "5000/5000 [==============================] - 2s 451us/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 3.5547 - val_accuracy: 0.6841\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.68673\n",
      "Epoch 69/500\n",
      "5000/5000 [==============================] - 2s 447us/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 3.2365 - val_accuracy: 0.6752\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.68673\n",
      "Epoch 70/500\n",
      "5000/5000 [==============================] - 2s 450us/step - loss: 0.0096 - accuracy: 0.9964 - val_loss: 3.5300 - val_accuracy: 0.6805\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.68673\n",
      "Epoch 71/500\n",
      "5000/5000 [==============================] - 2s 447us/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 3.5110 - val_accuracy: 0.6726\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.68673\n",
      "Epoch 72/500\n",
      "5000/5000 [==============================] - 2s 449us/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 3.4070 - val_accuracy: 0.6770\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.68673\n",
      "Epoch 73/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 9.5602e-04 - accuracy: 0.9998 - val_loss: 3.4120 - val_accuracy: 0.6796\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.68673\n",
      "Epoch 74/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 2.2451e-04 - accuracy: 1.0000 - val_loss: 3.4692 - val_accuracy: 0.6850\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.68673\n",
      "Epoch 75/500\n",
      "5000/5000 [==============================] - 2s 455us/step - loss: 1.8809e-04 - accuracy: 1.0000 - val_loss: 3.5101 - val_accuracy: 0.6752\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.68673\n",
      "Epoch 76/500\n",
      "5000/5000 [==============================] - 2s 460us/step - loss: 5.3852e-04 - accuracy: 0.9998 - val_loss: 3.6486 - val_accuracy: 0.6876\n",
      "\n",
      "Epoch 00076: val_accuracy improved from 0.68673 to 0.68761, saving model to py/CNN/cnn_n2\n",
      "Epoch 77/500\n",
      "5000/5000 [==============================] - 2s 455us/step - loss: 7.6603e-05 - accuracy: 1.0000 - val_loss: 3.6619 - val_accuracy: 0.6858\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.68761\n",
      "Epoch 78/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 3.3850e-04 - accuracy: 1.0000 - val_loss: 3.7365 - val_accuracy: 0.6823\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.68761\n",
      "Epoch 79/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 4.3434e-04 - accuracy: 0.9998 - val_loss: 3.8365 - val_accuracy: 0.6912\n",
      "\n",
      "Epoch 00079: val_accuracy improved from 0.68761 to 0.69115, saving model to py/CNN/cnn_n2\n",
      "Epoch 80/500\n",
      "5000/5000 [==============================] - 2s 447us/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 3.5216 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.69115\n",
      "Epoch 81/500\n",
      "5000/5000 [==============================] - 2s 444us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 3.5385 - val_accuracy: 0.6752\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.69115\n",
      "Epoch 82/500\n",
      "5000/5000 [==============================] - 2s 448us/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 3.8237 - val_accuracy: 0.6752\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.69115\n",
      "Epoch 83/500\n",
      "5000/5000 [==============================] - 2s 451us/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 3.6533 - val_accuracy: 0.6752\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.69115\n",
      "Epoch 84/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 0.0142 - accuracy: 0.9966 - val_loss: 3.6482 - val_accuracy: 0.6788\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.69115\n",
      "Epoch 85/500\n",
      "5000/5000 [==============================] - 2s 454us/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 3.6928 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.69115\n",
      "Epoch 86/500\n",
      "5000/5000 [==============================] - 2s 451us/step - loss: 7.7029e-04 - accuracy: 0.9998 - val_loss: 3.7244 - val_accuracy: 0.6832\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.69115\n",
      "Epoch 87/500\n",
      "5000/5000 [==============================] - 2s 450us/step - loss: 2.5364e-04 - accuracy: 1.0000 - val_loss: 3.7736 - val_accuracy: 0.6850\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.69115\n",
      "Epoch 88/500\n",
      "5000/5000 [==============================] - 2s 454us/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 3.9804 - val_accuracy: 0.6726\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.69115\n",
      "Epoch 89/500\n",
      "5000/5000 [==============================] - 2s 451us/step - loss: 0.0110 - accuracy: 0.9978 - val_loss: 4.0056 - val_accuracy: 0.6814\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.69115\n",
      "Epoch 90/500\n",
      "5000/5000 [==============================] - 2s 456us/step - loss: 8.2897e-04 - accuracy: 0.9998 - val_loss: 3.9936 - val_accuracy: 0.6752\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.69115\n",
      "Epoch 91/500\n",
      "5000/5000 [==============================] - 2s 451us/step - loss: 3.8782e-04 - accuracy: 1.0000 - val_loss: 3.6002 - val_accuracy: 0.6832\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.69115\n",
      "Epoch 92/500\n",
      "5000/5000 [==============================] - 2s 451us/step - loss: 3.8516e-04 - accuracy: 1.0000 - val_loss: 3.6826 - val_accuracy: 0.6903\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.69115\n",
      "Epoch 93/500\n",
      "5000/5000 [==============================] - 2s 449us/step - loss: 1.2421e-04 - accuracy: 1.0000 - val_loss: 3.7547 - val_accuracy: 0.6920\n",
      "\n",
      "Epoch 00093: val_accuracy improved from 0.69115 to 0.69204, saving model to py/CNN/cnn_n2\n",
      "Epoch 94/500\n",
      "5000/5000 [==============================] - 2s 450us/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 3.7204 - val_accuracy: 0.6929\n",
      "\n",
      "Epoch 00094: val_accuracy improved from 0.69204 to 0.69292, saving model to py/CNN/cnn_n2\n",
      "Epoch 95/500\n",
      "5000/5000 [==============================] - 2s 443us/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 3.5575 - val_accuracy: 0.6628\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.69292\n",
      "Epoch 96/500\n",
      "5000/5000 [==============================] - 2s 446us/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 3.6466 - val_accuracy: 0.6566\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.69292\n",
      "Epoch 97/500\n",
      "5000/5000 [==============================] - 2s 449us/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 3.7737 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.69292\n",
      "Epoch 98/500\n",
      "5000/5000 [==============================] - 2s 448us/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 5.0279 - val_accuracy: 0.6442\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.69292\n",
      "Epoch 99/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 0.0212 - accuracy: 0.9952 - val_loss: 3.5561 - val_accuracy: 0.6637\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.69292\n",
      "Epoch 100/500\n",
      "5000/5000 [==============================] - 2s 453us/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 4.3262 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.69292\n",
      "Epoch 101/500\n",
      "5000/5000 [==============================] - 2s 451us/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 4.0597 - val_accuracy: 0.6726\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.69292\n",
      "Epoch 102/500\n",
      "5000/5000 [==============================] - 2s 448us/step - loss: 4.9812e-04 - accuracy: 1.0000 - val_loss: 4.2719 - val_accuracy: 0.6646\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.69292\n",
      "Epoch 103/500\n",
      "5000/5000 [==============================] - 2s 442us/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 4.1106 - val_accuracy: 0.6929\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.69292\n",
      "Epoch 104/500\n",
      "5000/5000 [==============================] - 2s 447us/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 4.2203 - val_accuracy: 0.6726\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.69292\n",
      "Epoch 105/500\n",
      "5000/5000 [==============================] - 2s 446us/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 3.9605 - val_accuracy: 0.6761\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.69292\n",
      "Epoch 106/500\n",
      "5000/5000 [==============================] - 2s 443us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 4.4640 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.69292\n",
      "Epoch 107/500\n",
      "5000/5000 [==============================] - 2s 445us/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 3.9386 - val_accuracy: 0.6566\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.69292\n",
      "Epoch 108/500\n",
      "5000/5000 [==============================] - 2s 446us/step - loss: 0.0106 - accuracy: 0.9984 - val_loss: 4.1173 - val_accuracy: 0.6646\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.69292\n",
      "Epoch 109/500\n",
      "5000/5000 [==============================] - 2s 449us/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 4.2706 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.69292\n",
      "Epoch 110/500\n",
      "5000/5000 [==============================] - 2s 453us/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 4.4236 - val_accuracy: 0.6540\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.69292\n",
      "Epoch 111/500\n",
      "5000/5000 [==============================] - 2s 449us/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 4.5104 - val_accuracy: 0.6619\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.69292\n",
      "Epoch 112/500\n",
      "5000/5000 [==============================] - 2s 450us/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 4.3081 - val_accuracy: 0.6619\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.69292\n",
      "Epoch 113/500\n",
      "5000/5000 [==============================] - 2s 446us/step - loss: 1.8375e-04 - accuracy: 1.0000 - val_loss: 4.3895 - val_accuracy: 0.6752\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.69292\n",
      "Epoch 114/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 9.8497e-05 - accuracy: 1.0000 - val_loss: 4.4276 - val_accuracy: 0.6664\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.69292\n",
      "Epoch 115/500\n",
      "5000/5000 [==============================] - 2s 454us/step - loss: 2.9334e-05 - accuracy: 1.0000 - val_loss: 4.4357 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.69292\n",
      "Epoch 116/500\n",
      "5000/5000 [==============================] - 2s 447us/step - loss: 1.9123e-05 - accuracy: 1.0000 - val_loss: 4.4460 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.69292\n",
      "Epoch 117/500\n",
      "5000/5000 [==============================] - 2s 446us/step - loss: 2.2174e-04 - accuracy: 1.0000 - val_loss: 4.4050 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.69292\n",
      "Epoch 118/500\n",
      "5000/5000 [==============================] - 2s 445us/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 4.6511 - val_accuracy: 0.6558\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.69292\n",
      "Epoch 119/500\n",
      "5000/5000 [==============================] - 2s 450us/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 3.9990 - val_accuracy: 0.6761\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.69292\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 120/500\n",
      "5000/5000 [==============================] - 2s 446us/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 4.2081 - val_accuracy: 0.6761\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.69292\n",
      "Epoch 121/500\n",
      "5000/5000 [==============================] - 2s 450us/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 4.4161 - val_accuracy: 0.6681\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.69292\n",
      "Epoch 122/500\n",
      "5000/5000 [==============================] - 2s 449us/step - loss: 1.3428e-04 - accuracy: 1.0000 - val_loss: 4.3630 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.69292\n",
      "Epoch 123/500\n",
      "5000/5000 [==============================] - 2s 453us/step - loss: 5.2723e-05 - accuracy: 1.0000 - val_loss: 4.3906 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.69292\n",
      "Epoch 124/500\n",
      "5000/5000 [==============================] - 2s 452us/step - loss: 2.9947e-04 - accuracy: 0.9998 - val_loss: 4.2164 - val_accuracy: 0.6779\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.69292\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = (112,112,3), padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(128, (3, 3), activation = 'relu', padding='same'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation = 'relu', padding='same'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30)\n",
    "modelcheckpoint = keras.callbacks.ModelCheckpoint(filepath='py/CNN/cnn_n2', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "# reduceLronplateau = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=3, verbose=1, mode='auto', min_delta=0.001, cooldown=0, min_lr=0)\n",
    "reduceLronplateau=ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                             patience=25,\n",
    "                             # 3 epochs 內acc沒下降就要調整LR\n",
    "                             verbose=1,\n",
    "                             factor=0.5,\n",
    "                             # LR降為0.5\n",
    "                             min_lr=0.00001\n",
    "                             # 最小 LR 到0.00001就不再下降\n",
    "                             )\n",
    "\n",
    "# model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr=1e-4), metrics = ['accuracy'])\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# history = model.fit(train_x, train_y, epochs=500, batch_size=32, verbose=1, callbacks=[modelcheckpoint, earlystopping, reduceLronplateau])\n",
    "\n",
    "history = model.fit(train_x[:5000],train_y[:5000], epochs=500, batch_size=32, verbose=1,validation_data=(train_x[5000:],train_y[5000:]), callbacks=[modelcheckpoint, earlystopping, reduceLronplateau])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 328us/step\n",
      "Loss: 3.5702946491241456\n",
      "Accuracy: 0.7080000042915344\n",
      "predict accurscy: 0.708, precision: 0.711422265639133, recall: 0.7160714285714285, f1: 0.7134830867365798\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# model.load_weights('py/CNN/cnn_n2')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "plot_acc(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 177us/step\n",
      "Loss: 3.3031304483413697\n",
      "Accuracy: 0.6919999718666077\n",
      "predict accurscy: 0.692, precision: 0.7008085708510209, recall: 0.6981150793650793, f1: 0.699393443358647\n"
     ]
    }
   ],
   "source": [
    "#測試集\n",
    "model.load_weights('py/CNN/cnn_n2')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6130/6130 [==============================] - 1s 181us/step\n",
      "Loss: 0.6858325669600878\n",
      "Accuracy: 0.9433931708335876\n",
      "predict accurscy: 0.9433931484502447, precision: 0.9440853525156151, recall: 0.9439263796071975, f1: 0.9440048914361681\n"
     ]
    }
   ],
   "source": [
    "#訓練集\n",
    "model.load_weights('py/CNN/cnn_n2')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(train_x,train_y)\n",
    "pred_cy = model.predict_classes(train_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_x, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 112, 112, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 56, 56, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 3,491,075\n",
      "Trainable params: 3,491,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 5000 samples, validate on 1130 samples\n",
      "Epoch 1/500\n",
      "5000/5000 [==============================] - 2s 423us/step - loss: 1.0268 - accuracy: 0.4480 - val_loss: 0.9370 - val_accuracy: 0.5310\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53097, saving model to py/CNN/cnn_n\n",
      "Epoch 2/500\n",
      "5000/5000 [==============================] - 2s 374us/step - loss: 0.9079 - accuracy: 0.5526 - val_loss: 0.9538 - val_accuracy: 0.5301\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53097\n",
      "Epoch 3/500\n",
      "5000/5000 [==============================] - 2s 370us/step - loss: 0.8642 - accuracy: 0.5852 - val_loss: 0.8272 - val_accuracy: 0.6177\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.53097 to 0.61770, saving model to py/CNN/cnn_n\n",
      "Epoch 4/500\n",
      "5000/5000 [==============================] - 2s 371us/step - loss: 0.8096 - accuracy: 0.6210 - val_loss: 0.7814 - val_accuracy: 0.6513\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.61770 to 0.65133, saving model to py/CNN/cnn_n\n",
      "Epoch 5/500\n",
      "5000/5000 [==============================] - 2s 364us/step - loss: 0.7250 - accuracy: 0.6704 - val_loss: 0.7183 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.65133 to 0.66991, saving model to py/CNN/cnn_n\n",
      "Epoch 6/500\n",
      "5000/5000 [==============================] - 2s 365us/step - loss: 0.6787 - accuracy: 0.6932 - val_loss: 0.6538 - val_accuracy: 0.6973\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.66991 to 0.69735, saving model to py/CNN/cnn_n\n",
      "Epoch 7/500\n",
      "5000/5000 [==============================] - 2s 368us/step - loss: 0.6033 - accuracy: 0.7326 - val_loss: 0.6314 - val_accuracy: 0.7292\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.69735 to 0.72920, saving model to py/CNN/cnn_n\n",
      "Epoch 8/500\n",
      "5000/5000 [==============================] - 2s 368us/step - loss: 0.5746 - accuracy: 0.7454 - val_loss: 0.6387 - val_accuracy: 0.7248\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.72920\n",
      "Epoch 9/500\n",
      "5000/5000 [==============================] - 2s 370us/step - loss: 0.5460 - accuracy: 0.7570 - val_loss: 0.6515 - val_accuracy: 0.7230\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.72920\n",
      "Epoch 10/500\n",
      "5000/5000 [==============================] - 2s 370us/step - loss: 0.5194 - accuracy: 0.7700 - val_loss: 0.5917 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.72920 to 0.74867, saving model to py/CNN/cnn_n\n",
      "Epoch 11/500\n",
      "5000/5000 [==============================] - 2s 365us/step - loss: 0.4994 - accuracy: 0.7804 - val_loss: 0.6111 - val_accuracy: 0.7389\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74867\n",
      "Epoch 12/500\n",
      "5000/5000 [==============================] - 2s 372us/step - loss: 0.4924 - accuracy: 0.7806 - val_loss: 0.6445 - val_accuracy: 0.7345\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74867\n",
      "Epoch 13/500\n",
      "5000/5000 [==============================] - 2s 371us/step - loss: 0.4754 - accuracy: 0.7906 - val_loss: 0.6385 - val_accuracy: 0.7301\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74867\n",
      "Epoch 14/500\n",
      "5000/5000 [==============================] - 2s 365us/step - loss: 0.4304 - accuracy: 0.8134 - val_loss: 0.6572 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74867\n",
      "Epoch 15/500\n",
      "5000/5000 [==============================] - 2s 370us/step - loss: 0.4149 - accuracy: 0.8208 - val_loss: 0.6422 - val_accuracy: 0.7301\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74867\n",
      "Epoch 16/500\n",
      "5000/5000 [==============================] - 2s 372us/step - loss: 0.3829 - accuracy: 0.8296 - val_loss: 0.6763 - val_accuracy: 0.7389\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74867\n",
      "Epoch 17/500\n",
      "5000/5000 [==============================] - 2s 365us/step - loss: 0.3702 - accuracy: 0.8450 - val_loss: 0.6736 - val_accuracy: 0.7336\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74867\n",
      "Epoch 18/500\n",
      "5000/5000 [==============================] - 2s 371us/step - loss: 0.3353 - accuracy: 0.8592 - val_loss: 0.7158 - val_accuracy: 0.7354\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74867\n",
      "Epoch 19/500\n",
      "5000/5000 [==============================] - 2s 371us/step - loss: 0.3084 - accuracy: 0.8658 - val_loss: 0.7539 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74867\n",
      "Epoch 20/500\n",
      "5000/5000 [==============================] - 2s 370us/step - loss: 0.2983 - accuracy: 0.8742 - val_loss: 0.8091 - val_accuracy: 0.7416\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74867\n",
      "Epoch 21/500\n",
      "5000/5000 [==============================] - 2s 369us/step - loss: 0.2861 - accuracy: 0.8800 - val_loss: 0.8072 - val_accuracy: 0.7372\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74867\n",
      "Epoch 22/500\n",
      "5000/5000 [==============================] - 2s 372us/step - loss: 0.2547 - accuracy: 0.8984 - val_loss: 0.8715 - val_accuracy: 0.7230\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74867\n",
      "Epoch 23/500\n",
      "5000/5000 [==============================] - 2s 370us/step - loss: 0.2395 - accuracy: 0.9010 - val_loss: 0.7910 - val_accuracy: 0.7451\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74867\n",
      "Epoch 24/500\n",
      "5000/5000 [==============================] - 2s 371us/step - loss: 0.2100 - accuracy: 0.9164 - val_loss: 0.9362 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74867\n",
      "Epoch 25/500\n",
      "5000/5000 [==============================] - 2s 372us/step - loss: 0.2202 - accuracy: 0.9172 - val_loss: 0.9675 - val_accuracy: 0.7381\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74867\n",
      "Epoch 26/500\n",
      "5000/5000 [==============================] - 2s 372us/step - loss: 0.1903 - accuracy: 0.9236 - val_loss: 0.9557 - val_accuracy: 0.7212\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74867\n",
      "Epoch 27/500\n",
      "5000/5000 [==============================] - 2s 369us/step - loss: 0.1880 - accuracy: 0.9292 - val_loss: 1.1482 - val_accuracy: 0.7381\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74867\n",
      "Epoch 28/500\n",
      "5000/5000 [==============================] - 2s 374us/step - loss: 0.1469 - accuracy: 0.9392 - val_loss: 1.0929 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74867\n",
      "Epoch 29/500\n",
      "5000/5000 [==============================] - 2s 369us/step - loss: 0.1528 - accuracy: 0.9430 - val_loss: 1.1214 - val_accuracy: 0.7336\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74867\n",
      "Epoch 30/500\n",
      "5000/5000 [==============================] - 2s 370us/step - loss: 0.1616 - accuracy: 0.9388 - val_loss: 1.1357 - val_accuracy: 0.7062\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74867\n",
      "Epoch 31/500\n",
      "5000/5000 [==============================] - 2s 373us/step - loss: 0.1348 - accuracy: 0.9472 - val_loss: 1.1367 - val_accuracy: 0.7301\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74867\n",
      "Epoch 32/500\n",
      "5000/5000 [==============================] - 2s 373us/step - loss: 0.1149 - accuracy: 0.9574 - val_loss: 1.2563 - val_accuracy: 0.7398\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74867\n",
      "Epoch 33/500\n",
      "5000/5000 [==============================] - 2s 374us/step - loss: 0.1425 - accuracy: 0.9454 - val_loss: 1.1991 - val_accuracy: 0.7204\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74867\n",
      "Epoch 34/500\n",
      "5000/5000 [==============================] - 2s 373us/step - loss: 0.1241 - accuracy: 0.9560 - val_loss: 1.2052 - val_accuracy: 0.7416\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74867\n",
      "Epoch 35/500\n",
      "5000/5000 [==============================] - 2s 374us/step - loss: 0.1174 - accuracy: 0.9602 - val_loss: 1.1333 - val_accuracy: 0.7257\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74867\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 36/500\n",
      "5000/5000 [==============================] - 2s 366us/step - loss: 0.0667 - accuracy: 0.9798 - val_loss: 1.2875 - val_accuracy: 0.7310\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74867\n",
      "Epoch 37/500\n",
      "5000/5000 [==============================] - 2s 366us/step - loss: 0.0482 - accuracy: 0.9832 - val_loss: 1.3945 - val_accuracy: 0.7398\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74867\n",
      "Epoch 38/500\n",
      "5000/5000 [==============================] - 2s 366us/step - loss: 0.0482 - accuracy: 0.9838 - val_loss: 1.4742 - val_accuracy: 0.7221\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74867\n",
      "Epoch 39/500\n",
      "5000/5000 [==============================] - 2s 366us/step - loss: 0.0482 - accuracy: 0.9848 - val_loss: 1.4019 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74867\n",
      "Epoch 40/500\n",
      "5000/5000 [==============================] - 2s 369us/step - loss: 0.0419 - accuracy: 0.9850 - val_loss: 1.5132 - val_accuracy: 0.7416\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74867\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = (112,112,3), padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(128, (3, 3), activation = 'relu', padding='same'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "# model.add(Dense(128, activation = 'relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30)\n",
    "modelcheckpoint = keras.callbacks.ModelCheckpoint(filepath='py/CNN/cnn_n', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "# reduceLronplateau = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=3, verbose=1, mode='auto', min_delta=0.001, cooldown=0, min_lr=0)\n",
    "reduceLronplateau=ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                             patience=25,\n",
    "                             # 3 epochs 內acc沒下降就要調整LR\n",
    "                             verbose=1,\n",
    "                             factor=0.5,\n",
    "                             # LR降為0.5\n",
    "                             min_lr=0.00001\n",
    "                             # 最小 LR 到0.00001就不再下降\n",
    "                             )\n",
    "\n",
    "# model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr=1e-4), metrics = ['accuracy'])\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# history = model.fit(train_x, train_y, epochs=500, batch_size=32, verbose=1, callbacks=[modelcheckpoint, earlystopping, reduceLronplateau])\n",
    "\n",
    "history = model.fit(train_x[:5000],train_y[:5000], epochs=500, batch_size=32, verbose=1,validation_data=(train_x[5000:],train_y[5000:]), callbacks=[modelcheckpoint, earlystopping, reduceLronplateau])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 158us/step\n",
      "Loss: 1.4089090626239777\n",
      "Accuracy: 0.7400000095367432\n",
      "predict accurscy: 0.74, precision: 0.7454350161117077, recall: 0.747718253968254, f1: 0.745480275855576\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# model.load_weights('py/CNN/cnn_n')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "plot_acc(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 171us/step\n",
      "Loss: 0.5853228583335877\n",
      "Accuracy: 0.7680000066757202\n",
      "predict accurscy: 0.768, precision: 0.7757390845006285, recall: 0.7851190476190476, f1: 0.767297953090119\n"
     ]
    }
   ],
   "source": [
    "#測試集\n",
    "model.load_weights('py/CNN/cnn_n')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6130/6130 [==============================] - 1s 160us/step\n",
      "Loss: 0.4932718079348762\n",
      "Accuracy: 0.7796084880828857\n",
      "predict accurscy: 0.7796084828711256, precision: 0.7875266774027808, recall: 0.791002093749614, f1: 0.7781541584377009\n"
     ]
    }
   ],
   "source": [
    "#訓練集\n",
    "model.load_weights('py/CNN/cnn_n')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(train_x,train_y)\n",
    "pred_cy = model.predict_classes(train_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_x, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料增強"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 13,124,867\n",
      "Trainable params: 13,124,867\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 1.1185 - accuracy: 0.3560 - val_loss: 1.0981 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.34602, saving model to py/CNN/cnn\n",
      "Epoch 2/500\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 1.0958 - accuracy: 0.3765 - val_loss: 1.0876 - val_accuracy: 0.3496\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.34602 to 0.34956, saving model to py/CNN/cnn\n",
      "Epoch 3/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 1.0945 - accuracy: 0.3875 - val_loss: 1.0995 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.34956\n",
      "Epoch 4/500\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 1.0966 - accuracy: 0.3705 - val_loss: 1.0999 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.34956\n",
      "Epoch 5/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 1.0952 - accuracy: 0.3760 - val_loss: 1.1000 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.34956\n",
      "Epoch 6/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 1.0954 - accuracy: 0.3715 - val_loss: 1.0992 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.34956\n",
      "Epoch 7/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 1.0963 - accuracy: 0.3805 - val_loss: 1.0868 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.34956\n",
      "Epoch 8/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 1.0791 - accuracy: 0.3960 - val_loss: 1.0634 - val_accuracy: 0.4088\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.34956 to 0.40885, saving model to py/CNN/cnn\n",
      "Epoch 9/500\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 1.0312 - accuracy: 0.4530 - val_loss: 1.0014 - val_accuracy: 0.4752\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.40885 to 0.47522, saving model to py/CNN/cnn\n",
      "Epoch 10/500\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.9982 - accuracy: 0.4810 - val_loss: 1.0531 - val_accuracy: 0.4504\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.47522\n",
      "Epoch 11/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 1.0037 - accuracy: 0.4775 - val_loss: 1.0128 - val_accuracy: 0.4522\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.47522\n",
      "Epoch 12/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.9907 - accuracy: 0.5030 - val_loss: 0.9894 - val_accuracy: 0.4965\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.47522 to 0.49646, saving model to py/CNN/cnn\n",
      "Epoch 13/500\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.9738 - accuracy: 0.5185 - val_loss: 0.9593 - val_accuracy: 0.5106\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.49646 to 0.51062, saving model to py/CNN/cnn\n",
      "Epoch 14/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.9576 - accuracy: 0.5160 - val_loss: 0.9486 - val_accuracy: 0.5327\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.51062 to 0.53274, saving model to py/CNN/cnn\n",
      "Epoch 15/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.9350 - accuracy: 0.5505 - val_loss: 0.9190 - val_accuracy: 0.5354\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.53274 to 0.53540, saving model to py/CNN/cnn\n",
      "Epoch 16/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.9207 - accuracy: 0.5550 - val_loss: 0.9113 - val_accuracy: 0.5673\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.53540 to 0.56726, saving model to py/CNN/cnn\n",
      "Epoch 17/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.9334 - accuracy: 0.5405 - val_loss: 0.9908 - val_accuracy: 0.4593\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.56726\n",
      "Epoch 18/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.9245 - accuracy: 0.5585 - val_loss: 0.9149 - val_accuracy: 0.5478\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.56726\n",
      "Epoch 19/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.9146 - accuracy: 0.5565 - val_loss: 0.9164 - val_accuracy: 0.5584\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.56726\n",
      "Epoch 20/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.9085 - accuracy: 0.5605 - val_loss: 0.9174 - val_accuracy: 0.5442\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.56726\n",
      "Epoch 21/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.9000 - accuracy: 0.5545 - val_loss: 0.9797 - val_accuracy: 0.4850\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.56726\n",
      "Epoch 22/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.8946 - accuracy: 0.5655 - val_loss: 0.9305 - val_accuracy: 0.5575\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.56726\n",
      "Epoch 23/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.8946 - accuracy: 0.5605 - val_loss: 0.8892 - val_accuracy: 0.5735\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.56726 to 0.57345, saving model to py/CNN/cnn\n",
      "Epoch 24/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.8897 - accuracy: 0.5695 - val_loss: 0.9190 - val_accuracy: 0.5735\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.57345\n",
      "Epoch 25/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.9007 - accuracy: 0.5655 - val_loss: 0.8716 - val_accuracy: 0.5761\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.57345 to 0.57611, saving model to py/CNN/cnn\n",
      "Epoch 26/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.8781 - accuracy: 0.5830 - val_loss: 0.8726 - val_accuracy: 0.5832\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.57611 to 0.58319, saving model to py/CNN/cnn\n",
      "Epoch 27/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.8980 - accuracy: 0.5760 - val_loss: 0.8634 - val_accuracy: 0.5867\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.58319 to 0.58673, saving model to py/CNN/cnn\n",
      "Epoch 28/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.8787 - accuracy: 0.5595 - val_loss: 0.8811 - val_accuracy: 0.5575\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.58673\n",
      "Epoch 29/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.8759 - accuracy: 0.5895 - val_loss: 0.8838 - val_accuracy: 0.5841\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.58673\n",
      "Epoch 30/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.8808 - accuracy: 0.5755 - val_loss: 0.8882 - val_accuracy: 0.5752\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.58673\n",
      "Epoch 31/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.8826 - accuracy: 0.5785 - val_loss: 0.8669 - val_accuracy: 0.5947\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.58673 to 0.59469, saving model to py/CNN/cnn\n",
      "Epoch 32/500\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.8634 - accuracy: 0.5895 - val_loss: 0.8660 - val_accuracy: 0.5885\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.59469\n",
      "Epoch 33/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.8635 - accuracy: 0.5860 - val_loss: 0.8928 - val_accuracy: 0.5664\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.59469\n",
      "Epoch 34/500\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.8735 - accuracy: 0.5905 - val_loss: 0.8571 - val_accuracy: 0.6018\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.59469 to 0.60177, saving model to py/CNN/cnn\n",
      "Epoch 35/500\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.8843 - accuracy: 0.5905 - val_loss: 0.8990 - val_accuracy: 0.5637\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.60177\n",
      "Epoch 36/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.8583 - accuracy: 0.5930 - val_loss: 0.8715 - val_accuracy: 0.5832\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.60177\n",
      "Epoch 37/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.8446 - accuracy: 0.6135 - val_loss: 0.9215 - val_accuracy: 0.5593\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.60177\n",
      "Epoch 38/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.8643 - accuracy: 0.5855 - val_loss: 0.8416 - val_accuracy: 0.5938\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.60177\n",
      "Epoch 39/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.8579 - accuracy: 0.5940 - val_loss: 0.8628 - val_accuracy: 0.6133\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.60177 to 0.61327, saving model to py/CNN/cnn\n",
      "Epoch 40/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.8653 - accuracy: 0.5795 - val_loss: 0.8416 - val_accuracy: 0.5991\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.61327\n",
      "Epoch 41/500\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.8657 - accuracy: 0.5960 - val_loss: 0.8419 - val_accuracy: 0.6080\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.61327\n",
      "Epoch 42/500\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.8656 - accuracy: 0.5955 - val_loss: 0.8668 - val_accuracy: 0.5929\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.61327\n",
      "Epoch 43/500\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.8260 - accuracy: 0.6105 - val_loss: 0.8298 - val_accuracy: 0.6062\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.61327\n",
      "Epoch 44/500\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.8374 - accuracy: 0.6115 - val_loss: 0.8321 - val_accuracy: 0.6027\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.61327\n",
      "Epoch 45/500\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.8516 - accuracy: 0.6005 - val_loss: 0.8345 - val_accuracy: 0.5973\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.61327\n",
      "Epoch 46/500\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.8387 - accuracy: 0.6150 - val_loss: 0.8568 - val_accuracy: 0.6088\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.61327\n",
      "Epoch 47/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.8226 - accuracy: 0.6255 - val_loss: 0.8184 - val_accuracy: 0.6239\n",
      "\n",
      "Epoch 00047: val_accuracy improved from 0.61327 to 0.62389, saving model to py/CNN/cnn\n",
      "Epoch 48/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.8563 - accuracy: 0.5935 - val_loss: 0.8256 - val_accuracy: 0.6150\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.62389\n",
      "Epoch 49/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.8169 - accuracy: 0.6100 - val_loss: 0.8240 - val_accuracy: 0.6027\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.62389\n",
      "Epoch 50/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.8394 - accuracy: 0.6115 - val_loss: 0.8594 - val_accuracy: 0.6133\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.62389\n",
      "Epoch 51/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.8281 - accuracy: 0.6210 - val_loss: 0.8437 - val_accuracy: 0.6133\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.62389\n",
      "Epoch 52/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.8385 - accuracy: 0.6155 - val_loss: 0.8191 - val_accuracy: 0.6142\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.62389\n",
      "Epoch 53/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.8359 - accuracy: 0.6045 - val_loss: 0.8396 - val_accuracy: 0.5991\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.62389\n",
      "Epoch 54/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.8045 - accuracy: 0.6230 - val_loss: 0.8345 - val_accuracy: 0.6195\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.62389\n",
      "Epoch 55/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.8086 - accuracy: 0.6170 - val_loss: 0.7998 - val_accuracy: 0.6150\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.62389\n",
      "Epoch 56/500\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.7956 - accuracy: 0.6445 - val_loss: 0.8153 - val_accuracy: 0.6204\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.62389\n",
      "Epoch 57/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.8121 - accuracy: 0.6275 - val_loss: 0.8268 - val_accuracy: 0.6124\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.62389\n",
      "Epoch 58/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.8141 - accuracy: 0.6200 - val_loss: 0.7963 - val_accuracy: 0.6398\n",
      "\n",
      "Epoch 00058: val_accuracy improved from 0.62389 to 0.63982, saving model to py/CNN/cnn\n",
      "Epoch 59/500\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.7972 - accuracy: 0.6370 - val_loss: 0.7865 - val_accuracy: 0.6398\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.63982\n",
      "Epoch 60/500\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.8179 - accuracy: 0.6215 - val_loss: 0.7846 - val_accuracy: 0.6381\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.63982\n",
      "Epoch 61/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.7823 - accuracy: 0.6485 - val_loss: 0.7660 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00061: val_accuracy improved from 0.63982 to 0.65752, saving model to py/CNN/cnn\n",
      "Epoch 62/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.8041 - accuracy: 0.6310 - val_loss: 0.7447 - val_accuracy: 0.6513\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.65752\n",
      "Epoch 63/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.7692 - accuracy: 0.6465 - val_loss: 0.7345 - val_accuracy: 0.6628\n",
      "\n",
      "Epoch 00063: val_accuracy improved from 0.65752 to 0.66283, saving model to py/CNN/cnn\n",
      "Epoch 64/500\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.7726 - accuracy: 0.6535 - val_loss: 0.7796 - val_accuracy: 0.6274\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.66283\n",
      "Epoch 65/500\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.7799 - accuracy: 0.6425 - val_loss: 0.7280 - val_accuracy: 0.6726\n",
      "\n",
      "Epoch 00065: val_accuracy improved from 0.66283 to 0.67257, saving model to py/CNN/cnn\n",
      "Epoch 66/500\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.7573 - accuracy: 0.6745 - val_loss: 0.7013 - val_accuracy: 0.6867\n",
      "\n",
      "Epoch 00066: val_accuracy improved from 0.67257 to 0.68673, saving model to py/CNN/cnn\n",
      "Epoch 67/500\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.6918 - accuracy: 0.6930 - val_loss: 0.6990 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00067: val_accuracy improved from 0.68673 to 0.70265, saving model to py/CNN/cnn\n",
      "Epoch 68/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.7283 - accuracy: 0.6635 - val_loss: 0.6673 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.70265\n",
      "Epoch 69/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.6977 - accuracy: 0.6955 - val_loss: 0.6491 - val_accuracy: 0.7159\n",
      "\n",
      "Epoch 00069: val_accuracy improved from 0.70265 to 0.71593, saving model to py/CNN/cnn\n",
      "Epoch 70/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.6740 - accuracy: 0.6955 - val_loss: 0.6637 - val_accuracy: 0.7071\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.71593\n",
      "Epoch 71/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.6609 - accuracy: 0.7045 - val_loss: 0.6955 - val_accuracy: 0.7097\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.71593\n",
      "Epoch 72/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.6672 - accuracy: 0.7055 - val_loss: 0.6518 - val_accuracy: 0.7159\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.71593\n",
      "Epoch 73/500\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.6665 - accuracy: 0.6885 - val_loss: 0.6218 - val_accuracy: 0.7159\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.71593\n",
      "Epoch 74/500\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.6214 - accuracy: 0.7165 - val_loss: 0.6320 - val_accuracy: 0.7327\n",
      "\n",
      "Epoch 00074: val_accuracy improved from 0.71593 to 0.73274, saving model to py/CNN/cnn\n",
      "Epoch 75/500\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.6229 - accuracy: 0.7235 - val_loss: 0.6136 - val_accuracy: 0.7363\n",
      "\n",
      "Epoch 00075: val_accuracy improved from 0.73274 to 0.73628, saving model to py/CNN/cnn\n",
      "Epoch 76/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.6317 - accuracy: 0.7150 - val_loss: 0.6728 - val_accuracy: 0.7044\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.73628\n",
      "Epoch 77/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.6127 - accuracy: 0.7305 - val_loss: 0.6329 - val_accuracy: 0.7177\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.73628\n",
      "Epoch 78/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5960 - accuracy: 0.7265 - val_loss: 0.6379 - val_accuracy: 0.7230\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.73628\n",
      "Epoch 79/500\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.6145 - accuracy: 0.7265 - val_loss: 0.6044 - val_accuracy: 0.7451\n",
      "\n",
      "Epoch 00079: val_accuracy improved from 0.73628 to 0.74513, saving model to py/CNN/cnn\n",
      "Epoch 80/500\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.5974 - accuracy: 0.7400 - val_loss: 0.7157 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.74513\n",
      "Epoch 81/500\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.5871 - accuracy: 0.7410 - val_loss: 0.6188 - val_accuracy: 0.7150\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.74513\n",
      "Epoch 82/500\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.5802 - accuracy: 0.7465 - val_loss: 0.6348 - val_accuracy: 0.7283\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.74513\n",
      "Epoch 83/500\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.6052 - accuracy: 0.7335 - val_loss: 0.6252 - val_accuracy: 0.7319\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.74513\n",
      "Epoch 84/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.5934 - accuracy: 0.7475 - val_loss: 0.6360 - val_accuracy: 0.7204\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.74513\n",
      "Epoch 85/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.5880 - accuracy: 0.7325 - val_loss: 0.6539 - val_accuracy: 0.7142\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.74513\n",
      "Epoch 86/500\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.5940 - accuracy: 0.7435 - val_loss: 0.6037 - val_accuracy: 0.7363\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.74513\n",
      "Epoch 87/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.5559 - accuracy: 0.7500 - val_loss: 0.6182 - val_accuracy: 0.7292\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.74513\n",
      "Epoch 88/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5797 - accuracy: 0.7475 - val_loss: 0.6249 - val_accuracy: 0.7248\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.74513\n",
      "Epoch 89/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.5484 - accuracy: 0.7640 - val_loss: 0.6187 - val_accuracy: 0.7363\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.74513\n",
      "Epoch 90/500\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.5841 - accuracy: 0.7450 - val_loss: 0.5962 - val_accuracy: 0.7451\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.74513\n",
      "Epoch 91/500\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.5662 - accuracy: 0.7400 - val_loss: 0.6041 - val_accuracy: 0.7425\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.74513\n",
      "Epoch 92/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.5572 - accuracy: 0.7585 - val_loss: 0.5870 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.74513\n",
      "Epoch 93/500\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.5697 - accuracy: 0.7540 - val_loss: 0.5984 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00093: val_accuracy improved from 0.74513 to 0.74690, saving model to py/CNN/cnn\n",
      "Epoch 94/500\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.5436 - accuracy: 0.7630 - val_loss: 0.5947 - val_accuracy: 0.7425\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.74690\n",
      "Epoch 95/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5628 - accuracy: 0.7500 - val_loss: 0.6281 - val_accuracy: 0.7195\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.74690\n",
      "Epoch 96/500\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.5651 - accuracy: 0.7485 - val_loss: 0.6546 - val_accuracy: 0.7177\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.74690\n",
      "Epoch 97/500\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.5615 - accuracy: 0.7645 - val_loss: 0.6316 - val_accuracy: 0.7212\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.74690\n",
      "Epoch 98/500\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.5366 - accuracy: 0.7670 - val_loss: 0.6071 - val_accuracy: 0.7372\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.74690\n",
      "Epoch 99/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5606 - accuracy: 0.7555 - val_loss: 0.5720 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.74690\n",
      "Epoch 100/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.5450 - accuracy: 0.7610 - val_loss: 0.5718 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00100: val_accuracy improved from 0.74690 to 0.74867, saving model to py/CNN/cnn\n",
      "Epoch 101/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.5747 - accuracy: 0.7375 - val_loss: 0.6022 - val_accuracy: 0.7257\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.74867\n",
      "Epoch 102/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.5512 - accuracy: 0.7620 - val_loss: 0.5934 - val_accuracy: 0.7416\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.74867\n",
      "Epoch 103/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5150 - accuracy: 0.7775 - val_loss: 0.5994 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.74867\n",
      "Epoch 104/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.5280 - accuracy: 0.7610 - val_loss: 0.5991 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.74867\n",
      "Epoch 105/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.5288 - accuracy: 0.7625 - val_loss: 0.5914 - val_accuracy: 0.7301\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.74867\n",
      "Epoch 106/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5415 - accuracy: 0.7615 - val_loss: 0.5869 - val_accuracy: 0.7504\n",
      "\n",
      "Epoch 00106: val_accuracy improved from 0.74867 to 0.75044, saving model to py/CNN/cnn\n",
      "Epoch 107/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.5202 - accuracy: 0.7790 - val_loss: 0.5905 - val_accuracy: 0.7460\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.75044\n",
      "Epoch 108/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.5644 - accuracy: 0.7495 - val_loss: 0.6239 - val_accuracy: 0.7204\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.75044\n",
      "Epoch 109/500\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.4984 - accuracy: 0.7840 - val_loss: 0.5936 - val_accuracy: 0.7460\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.75044\n",
      "Epoch 110/500\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.5511 - accuracy: 0.7545 - val_loss: 0.5825 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.75044\n",
      "Epoch 111/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5247 - accuracy: 0.7715 - val_loss: 0.5697 - val_accuracy: 0.7531\n",
      "\n",
      "Epoch 00111: val_accuracy improved from 0.75044 to 0.75310, saving model to py/CNN/cnn\n",
      "Epoch 112/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.5459 - accuracy: 0.7580 - val_loss: 0.5749 - val_accuracy: 0.7416\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.75310\n",
      "Epoch 113/500\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.5228 - accuracy: 0.7790 - val_loss: 0.6134 - val_accuracy: 0.7310\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.75310\n",
      "Epoch 114/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5137 - accuracy: 0.7800 - val_loss: 0.6103 - val_accuracy: 0.7363\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.75310\n",
      "Epoch 115/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5307 - accuracy: 0.7600 - val_loss: 0.5863 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.75310\n",
      "Epoch 116/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5232 - accuracy: 0.7685 - val_loss: 0.6209 - val_accuracy: 0.7283\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.75310\n",
      "Epoch 117/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.4953 - accuracy: 0.7800 - val_loss: 0.6015 - val_accuracy: 0.7327\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.75310\n",
      "Epoch 118/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.5348 - accuracy: 0.7675 - val_loss: 0.5799 - val_accuracy: 0.7416\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.75310\n",
      "Epoch 119/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.4992 - accuracy: 0.7695 - val_loss: 0.5756 - val_accuracy: 0.7558\n",
      "\n",
      "Epoch 00119: val_accuracy improved from 0.75310 to 0.75575, saving model to py/CNN/cnn\n",
      "Epoch 120/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.5245 - accuracy: 0.7685 - val_loss: 0.5970 - val_accuracy: 0.7478\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.75575\n",
      "Epoch 121/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.4921 - accuracy: 0.7785 - val_loss: 0.5625 - val_accuracy: 0.7558\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.75575\n",
      "Epoch 122/500\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.5204 - accuracy: 0.7660 - val_loss: 0.5764 - val_accuracy: 0.7593\n",
      "\n",
      "Epoch 00122: val_accuracy improved from 0.75575 to 0.75929, saving model to py/CNN/cnn\n",
      "Epoch 123/500\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.5064 - accuracy: 0.7780 - val_loss: 0.6003 - val_accuracy: 0.7257\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.75929\n",
      "Epoch 124/500\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.5165 - accuracy: 0.7760 - val_loss: 0.5754 - val_accuracy: 0.7504\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.75929\n",
      "Epoch 125/500\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.5364 - accuracy: 0.7660 - val_loss: 0.5802 - val_accuracy: 0.7540\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.75929\n",
      "Epoch 126/500\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.4959 - accuracy: 0.7790 - val_loss: 0.6066 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.75929\n",
      "Epoch 127/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.5099 - accuracy: 0.7795 - val_loss: 0.5802 - val_accuracy: 0.7522\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.75929\n",
      "Epoch 128/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.5116 - accuracy: 0.7715 - val_loss: 0.6441 - val_accuracy: 0.7115\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.75929\n",
      "Epoch 129/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.5280 - accuracy: 0.7710 - val_loss: 0.6146 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.75929\n",
      "Epoch 130/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.5365 - accuracy: 0.7550 - val_loss: 0.5735 - val_accuracy: 0.7460\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.75929\n",
      "Epoch 131/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.4883 - accuracy: 0.7945 - val_loss: 0.5814 - val_accuracy: 0.7566\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.75929\n",
      "Epoch 132/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.4906 - accuracy: 0.7820 - val_loss: 0.5939 - val_accuracy: 0.7381\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.75929\n",
      "Epoch 133/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5258 - accuracy: 0.7645 - val_loss: 0.5846 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.75929\n",
      "Epoch 134/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.5058 - accuracy: 0.7710 - val_loss: 0.5812 - val_accuracy: 0.7398\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.75929\n",
      "Epoch 135/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5063 - accuracy: 0.7775 - val_loss: 0.6074 - val_accuracy: 0.7327\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.75929\n",
      "Epoch 136/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.4917 - accuracy: 0.7990 - val_loss: 0.5864 - val_accuracy: 0.7363\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.75929\n",
      "Epoch 137/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.4975 - accuracy: 0.7790 - val_loss: 0.6359 - val_accuracy: 0.7336\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.75929\n",
      "Epoch 138/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4965 - accuracy: 0.7760 - val_loss: 0.6015 - val_accuracy: 0.7558\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.75929\n",
      "Epoch 139/500\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.5334 - accuracy: 0.7570 - val_loss: 0.5759 - val_accuracy: 0.7522\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.75929\n",
      "Epoch 140/500\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.4679 - accuracy: 0.8025 - val_loss: 0.5901 - val_accuracy: 0.7522\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.75929\n",
      "Epoch 141/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5061 - accuracy: 0.7870 - val_loss: 0.5848 - val_accuracy: 0.7478\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.75929\n",
      "Epoch 142/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5126 - accuracy: 0.7845 - val_loss: 0.5812 - val_accuracy: 0.7549\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.75929\n",
      "Epoch 143/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4485 - accuracy: 0.8020 - val_loss: 0.5937 - val_accuracy: 0.7496\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.75929\n",
      "Epoch 144/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.5081 - accuracy: 0.7825 - val_loss: 0.5784 - val_accuracy: 0.7398\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.75929\n",
      "Epoch 145/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.5031 - accuracy: 0.7725 - val_loss: 0.6231 - val_accuracy: 0.7257\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.75929\n",
      "Epoch 146/500\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4743 - accuracy: 0.7870 - val_loss: 0.5725 - val_accuracy: 0.7460\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.75929\n",
      "Epoch 147/500\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.4683 - accuracy: 0.7965 - val_loss: 0.5694 - val_accuracy: 0.7558\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.75929\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 148/500\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.4734 - accuracy: 0.7950 - val_loss: 0.5730 - val_accuracy: 0.7575\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.75929\n",
      "Epoch 149/500\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.4445 - accuracy: 0.8025 - val_loss: 0.5797 - val_accuracy: 0.7504\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.75929\n",
      "Epoch 150/500\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.4506 - accuracy: 0.8000 - val_loss: 0.5625 - val_accuracy: 0.7522\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.75929\n",
      "Epoch 151/500\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.4570 - accuracy: 0.7955 - val_loss: 0.5602 - val_accuracy: 0.7566\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.75929\n",
      "Epoch 152/500\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.4530 - accuracy: 0.7995 - val_loss: 0.5796 - val_accuracy: 0.7558\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.75929\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = (224,224,3), padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(128, (3, 3), activation = 'relu', padding='same'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "# model.add(Dense(128, activation = 'relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30)\n",
    "modelcheckpoint = keras.callbacks.ModelCheckpoint(filepath='py/CNN/cnn', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "# reduceLronplateau = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=3, verbose=1, mode='auto', min_delta=0.001, cooldown=0, min_lr=0)\n",
    "reduceLronplateau=ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                             patience=25,\n",
    "                             # 3 epochs 內acc沒下降就要調整LR\n",
    "                             verbose=1,\n",
    "                             factor=0.5,\n",
    "                             # LR降為0.5\n",
    "                             min_lr=0.00001\n",
    "                             # 最小 LR 到0.00001就不再下降\n",
    "                             )\n",
    "\n",
    "# model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr=1e-4), metrics = ['accuracy'])\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "# train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "# test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "# train_datagen = ImageDataGenerator(rotation_range=0.2, zoom_range=0.05,\n",
    "#                                    featurewise_center = True, featurewise_std_normalization = True,\n",
    "#                                     width_shift_range=0.05, height_shift_range=0.05, shear_range=0.05,\n",
    "#                                     horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "train_datagen=ImageDataGenerator(rotation_range=15 , \n",
    "                             width_shift_range=0.2 , \n",
    "                             height_shift_range=0.2 ,\n",
    "                             shear_range=0.2 ,\n",
    "                             zoom_range=0.2 , \n",
    "                             data_format='channels_last')\n",
    "\n",
    "\n",
    "train_datagen.fit(train_x)\n",
    "\n",
    "history = model.fit_generator(train_datagen.flow(train_x[:5000],train_y[:5000],batch_size=20), \n",
    "                              steps_per_epoch=100 , epochs=500,\n",
    "                              validation_data=(train_x[5000:],train_y[5000:]),validation_steps=50,\n",
    "                              callbacks=[modelcheckpoint, earlystopping, reduceLronplateau])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 670us/step\n",
      "Loss: 0.5530701458454133\n",
      "Accuracy: 0.7639999985694885\n",
      "predict accurscy: 0.764, precision: 0.7647265940729383, recall: 0.7776785714285714, f1: 0.768532438769341\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABUDklEQVR4nO3dd3xV9f348df73uy9A0nIYO+9FFDcoHVbt1Vrtdpq7dBW+7O2tbvf1tpa2zrqqnuLW0EQVIYs2RACZEL23uPz++NzMglwUW4Skvfz8cjj5p5z7rnveyHnfT5bjDEopZQauFy9HYBSSqnepYlAKaUGOE0ESik1wGkiUEqpAU4TgVJKDXCaCJRSaoDTRKAGFBF5UkR+6+Gx+0TkdG/HpFRv00SglFIDnCYCpY5DIuLT2zGo/kMTgepznCqZO0Vkk4hUi8h/RSReRN4TkUoRWSwikR2OP09EtopImYgsE5ExHfZNEZH1zuteBAK6vNc3RGSj89rPRWSihzGeIyIbRKRCRLJF5Fdd9s91zlfm7L/O2R4oIn8VkUwRKReRT51t80Ukp5vv4XTn91+JyCsi8oyIVADXichMEVnpvMd+EfmniPh1eP04EflIREpEJF9Efi4ig0SkRkSiOxw3VUQKRcTXk8+u+h9NBKqvuhg4AxgJnAu8B/wciMX+v/0BgIiMBJ4Hfujsexd4S0T8nIviG8D/gCjgZee8OK+dAjwOfBeIBh4GFomIvwfxVQPfAiKAc4BbROQC57wpTrwPOjFNBjY6r/sLMA040Ynpp0CLh9/J+cArzns+CzQDPwJigBOA04DvOTGEAouB94EEYDiwxBhzAFgGXNrhvNcALxhjGj2MQ/UzmghUX/WgMSbfGJMLrABWG2M2GGPqgNeBKc5xlwHvGGM+ci5kfwECsRfa2YAv8IAxptEY8wrwRYf3uAl42Biz2hjTbIx5Cqh3XndYxphlxpjNxpgWY8wmbDI62dl9JbDYGPO8877FxpiNIuICvg3cbozJdd7zc2NMvYffyUpjzBvOe9YaY9YZY1YZY5qMMfuwiaw1hm8AB4wxfzXG1BljKo0xq519TwFXA4iIG7gCmyzVAKWJQPVV+R1+r+3meYjzewKQ2brDGNMCZAOJzr5c03lmxcwOv6cAP3GqVspEpAwY4rzusERklogsdapUyoGbsXfmOOfI6OZlMdiqqe72eSK7SwwjReRtETngVBf93oMYAN4ExopIGrbUVW6MWfMVY1L9gCYCdbzLw17QARARwV4Ec4H9QKKzrVVyh9+zgd8ZYyI6/AQZY5734H2fAxYBQ4wx4cB/gNb3yQaGdfOaIqDuEPuqgaAOn8ONrVbqqOtUwf8GdgAjjDFh2KqzjjEM7S5wp1T1ErZUcA1aGhjwNBGo491LwDkicprT2PkTbPXO58BKoAn4gYj4ishFwMwOr30UuNm5uxcRCXYagUM9eN9QoMQYUyciM7HVQa2eBU4XkUtFxEdEokVkslNaeRy4X0QSRMQtIic4bRK7gADn/X2Be4AjtVWEAhVAlYiMBm7psO9tYLCI/FBE/EUkVERmddj/NHAdcB6aCAY8TQTquGaM2Ym9s30Qe8d9LnCuMabBGNMAXIS94JVg2xNe6/DatcCNwD+BUmC3c6wnvgfcJyKVwL3YhNR63izgbGxSKsE2FE9ydt8BbMa2VZQAfwJcxphy55yPYUsz1UCnXkTduAObgCqxSe3FDjFUYqt9zgUOAOnAKR32f4ZtpF5vjOlYXaYGINGFaZQamETkY+A5Y8xjvR2L6l2aCJQagERkBvARto2jsrfjUb1Lq4aUGmBE5CnsGIMfahJQoCUCpZQa8LREoJRSA9xxN3FVTEyMSU1N7e0wlFLquLJu3boiY0zXsSnAcZgIUlNTWbt2bW+HoZRSxxUROWQ3Ya0aUkqpAU4TgVJKDXCaCJRSaoA77toIutPY2EhOTg51dXW9HYpXBQQEkJSUhK+vrh+ilDp2+kUiyMnJITQ0lNTUVDpPNNl/GGMoLi4mJyeHtLS03g5HKdWP9Iuqobq6OqKjo/ttEgAQEaKjo/t9qUcp1fO8mghEZIGI7BSR3SJyVzf7k53FPTaIXZ/27K/xXl8v2OPAQPiMSqme57VE4Cys8RCwEBgLXCEiY7scdg/wkjFmCnA58C9vxaOUUt5S39TMC2uyaGo+ePnp7fsr8HQqn6bmFp5bnUVGYdWxDvGwvFkimAnsNsbsceaFfwG7+HZHBghzfg/HrjZ13CkrK+Nf/zr6HHb22WdTVlZ27ANSSvWo5buKuOu1zXy4Lb/T9s8zilj49xWsSC/y6DxPrczk569v5sy/Lefu1zZTXtPY6VyN3SSaY8GbiSCRzmus5jjbOvoVcLWI5ADvArd1dyIRuUlE1orI2sLCQm/E+rUcKhE0NTUd9nXvvvsuERERXopKKXWsrM8qZd6fP6awsr7b/QfKawFYvL1zIvhkp71efZZx5ESwv7yW+z/cydzhMVw9K5mX12ZzxaOrKKlu4OFPMrjqsdU8umLP1/wk3evtXkNXAE8aY/4qIicA/xOR8c6Sfm2MMY8AjwBMnz69z02Xetddd5GRkcHkyZPx9fUlICCAyMhIduzYwa5du7jgggvIzs6mrq6O22+/nZtuuglony6jqqqKhQsXMnfuXD7//HMSExN58803CQwM7OVPplT/Z4w5YvvbR9vyyS6p5fOMIs6f3PV+Fg5U2E4cy3YW0txicLvs+T7dbRPAF3tLuj3v/vJarn/iC0bEh1JYWUezMfzhogkMiQri1DHx3PT0Wk796zLKaho5Z+Jgvj3HOz0GvZkIcrGLiLdKcrZ1dAOwAMAYs1JEAoAYoOCrvumv39rKtryKr/rybo1NCOOX54475P4//vGPbNmyhY0bN7Js2TLOOecctmzZ0tbN8/HHHycqKora2lpmzJjBxRdfTHR0dKdzpKen8/zzz/Poo49y6aWX8uqrr3L11Vcf08+hlOrso2353PPGZt6//SQig/0OedzGrDIA1mWWdpsI8itsSaGkuoENWaVMT42ipLqBrXkVhPj7sDm3nLrGZgJ83Z1e96+lGewuqKKwsp7i6gZ+umAUQ6KCADh5ZCxPXD+D257bwPfmD+OOM0fhcnmnw4g3q4a+AEaISJqI+GEbgxd1OSYLOA1ARMYAAUDfq/s5SjNnzuzU1/8f//gHkyZNYvbs2WRnZ5Oenn7Qa9LS0pg8eTIA06ZNY9++fT0UrVID14asUvIr6ln05aGbJ5tbDJtyygD4Yl9pt8fkV9QxNDYYH5eweLu9j/3cqQ66fk4qjc2GDU4yaXWgvI4Xv8jmm9OTWP3z0/jghydxy8nDOh1z4rAY1t5zOj9dMNprSQC8WCIwxjSJyK3AB4AbeNwYs1VE7gPWGmMWYRf3flREfoRtOL7OfM2Vcg53595TgoOD235ftmwZixcvZuXKlQQFBTF//vxuxwL4+/u3/e52u6mtre2RWJUayPLK7N/ZK+tyuPbE1G6PSS+opLqhmbSYYHYcqKCirpGwgM6j+wsq6hkeG8KgsACWbM/nroWj+Wx3EaEBPlw/J41/Lt3NF/tKOGFYe03Aw8szaDaG780fjo/bxahBod2+f090G/fqOAJjzLvGmJHGmGHGmN852+51kgDGmG3GmDnGmEnGmMnGmA+9GY+3hIaGUlnZ/Yp/5eXlREZGEhQUxI4dO1i1alUPR6eUOpS8MntTtjm3nF353f8Nt1YLfXtuGsZw0J09QH5lHfFhAZw6Oo70gipeWZfDivQiThgaTVSwH6PiQ/liX3s7QXFVPc+tzuLCKYltVUG9qV+MLO5t0dHRzJkzh/Hjx3PnnXd22rdgwQKampoYM2YMd911F7Nnz+6lKJXyvo3ZZWzJLe/tMDyWW1bLSSNj8XEJr67L6faYjdllhAf6cuGURNwuYe2+zg2/dY3NlNU0Eh/mz4VTEhmXEMYdL39JTmktc0fEADAzLYr1maVt4wze33qA+qYWrzX+Hq3e7jXUbzz33HPdbvf39+e9997rdl9rO0BMTAxbtmxp237HHXcc8/iU6gn3vLEZP7eL1743p7dDOaKm5hYOVNRxwZQEG/OGXO48axQ+7s73xxuyypg8JIIQfx/GDg5jbZd2ggKnoTg+LIDoEH/eunUub23K4+1N+1k4fjAAM1KjeHplJptyy5maHMn7Ww6QGh3EmMHdVwf1NE0ESqmvLKe0Bj+3i7iwAIwxZBbVgBy6S2ZOaQ3vbT7AxpwyJiSGc3OXxtE3N+ayp7CaH50xstv3a24xNLW04O/j7nZ/q4q6RpZszyevrI7QAB+umZ1yUDwFlfU0txgSIgIZPSiMxdvz2y7Urarqm9hVUMnCCYMAmJYSyQtfZNHQ1IKfj00Y+ZW2eik+LAAAl0s4f3Jip95FJ42IJcjPzf9WZjIsJoSVGcXcMC+tz0wbo1VDSqlDenrlPpbtPHRv7uuf+IK7X9sMQGlNI5X1TVTWNVFY1f3Aq5+9uonfvbudxdvyeejj3TS3tPcNaWxu4XfvbOcfH6e3NeJ29dt3tnH6/Z+0VbG8ui6H8x/6jGdWZVLT0D6A868f7ORHL37J/32wk3vf3NrWk6ej1vdIjAhkzvAYROCzLiOAN2SVYgxMHhIBwEkjY6hrbOHyR1aS7rQp5Fd0TgTdCQ/y5fIZySz6Mo+nVu6jqcW0lRb6Ak0ESqluVdY18pu3t/G3j3Z1uz+3rJb0gip2HLAXxKySmrZ9uwsOniunqbmFDVllXDM7hT9dPJHK+iZ2HmhvoF2yvYCCynqMgdc3dB1yBAWVdTy7OovsklqWpxdijOGfS3ezfX8F97yxhbMeWE5dYzONzS28tWk/Z42LZ9OvzmREXAi/fWcb9U3NB8UPNhFEBfsxLiGsbQAY2Lr/372znehgP6al2FLCKaPiuP/SSewpquYbD35KdklN2xiC+DB/Duc789IQ4IHFuxgcHsDExPDDHt+TNBEopbr1aXoRjc2GTbnlFHdzh/+Zc9HMLaulur6JzOLqtn0ZhfZ3Ywwtzl3/zvxKahqamZYS2XZhXZvZ3vD63JosBocHMDU5glfX5xw0UdsTn+2jqbmF0AAfXlmXw5q9JewtquYPF07gX1dNJbuklpfX5bAivZCS6ga+OW0IYQG+3HvuWDKLa3hsxd5O52ztMTQ4wo7gnzM8hvVZpVTX25LFn9/fyY4DlfzfNycS6nQXFREumprES989gfqmFpanF5JfUYefj4vwwMMvGJUQEcj5kxNpMXDWuEFeHRdwtDQRKKW6tXh7AW6XYAzdTpr2WYe7571F1WQV2xJBgK+LDKdEcNvzG7jx6bVAe7fLqcmRJEUGMigsoK3hNau4huW7CrlsxhAumzGEPYXVbMwuo7Kukb1F1ZTXNvLMqkwWjh/MxVOTWLytgEdX7CHU34ezJwxm4fhBTBoSwaPL9/Dqulwig3w5aWQsAPNGxHLG2Hj+74OdjLn3fb75n89paGohr6yW8EBfQvxtU+nc4TE0NhvW7Cth2c4CHv9sL9eekMKpo+MP+uwj4kKIDfVnzd4S8ivqGBQW4FF9//dOGUZiRCAXT03y9J+hR2hjsVIDUG1DM34+rrY5cbpqbjEs3VnA2RMG89nuIj7ZVcgFU9obP1taDJ/tLmLs4DC27a8go7CKrJIa4kL9GRQeQEZhFXWNzXy0LZ+G5hYOlNexPquUmBA/hkQFIiJMS41s64r57OpM3C7h8hnJBPu7+eWirdz5yibyymqpaWjGz+2iobmFm08ehgg8+fk+Fm8v4MpZyQT62YbjW04exs3PrCOrpIarZye3NeYC/OWbk3hlXQ6bcsp4c2MeazNLyC2rJSGifT6vGalR+Pm4WLQxjxXpRYyKD+Xus8d0+/2ICLPSoli9p4SU6KAjVgu1GhYbwmd3nerRsT1JSwTHwFedhhrggQceoKam5sgHKnUMlNc08of3tjP5vg/58/s7DnncxuxSSqobOGNsPCeNiGH5rsK2Kh6w1TxFVQ1cNTsZt0vYXVBFZkkNKdFBDI8NIaOgirX7SqlvasEYeGfzfjZklTElObLtznlGSiR55XVsyCrl6ZWZnD1hMIPCAwgN8OX8SYlkFdewcPxg/nDRBC6ZnsQPTh3OhKRwxiWEMdoZhXv5jPbpzM4cG8/QWDuq/8IpnecDCg/05Ya5afz+wgn4uV0s3VFAXlktiRHtDbwBvm6mp0Ty+oZcKuoa+ccVUw6aG6ijWUOjOVBRx5bccuIO01B8PNBEcAxoIlA9oa6xme88tZYNWd3Pd9PRyoxiSqsbOm1rbjGc99CnPLJ8D5FBfjy3JqtTT5uOFm8vwMclnDwylpNHxVJc3cCWvHKKquoprqpvqxY6ZVQcyVFBZBRWkV1Sw5CoIIbFhZBXXsd7W/bj6xaGx4Xw7OpM9hZVd+qaOT01CoBbn9tAU0sLd545qm3fby8cz/p7z+Cvl07iipnJ/P7CCfzY2S8i/OiMkVw5K5kJHRpcXS7hF98YyyXTkjq9T0fB/j7MGhrF0p2F5JbVkhjReYbfOcPtALCfLxx9yCkfWs1Os/FXNzQTH3p8JwKtGjoGOk5DfcYZZxAXF8dLL71EfX09F154Ib/+9a+prq7m0ksvJScnh+bmZn7xi1+Qn59PXl4ep5xyCjExMSxdurS3P4rqw1bvLWHx9nwGhfsz5RAXOoBteRVc8egqrpiZzB8umtC2fWN2GZnFNfz54omkxgRz6cMrefvL/Vw6Ywhvbsxl9KCwtovf0h0FTE+NJDzQl3kjbF37jU+vbevV4+d2MTQ2mISIQIbFhrA1r4IDFXWkRAUzzLkrf219LtNTojh5VCx/fM+WPqYkR7TFM3pQKMF+bnLLavn2nDSSo9unWvB1u/B1H/o+9axxgzhr3KCDtp8yKo5TRsUd9ns8ZVQc9729DaBT1RDANSekkBodzNkTDj53V8PjQogK9qOkusHjqqG+qv8lgvfuggObj+05B02AhX885O6O01B/+OGHvPLKK6xZswZjDOeddx7Lly+nsLCQhIQE3nnnHcDOQRQeHs7999/P0qVLiYmJObYxq36ndZGTNd3Mbb8ivZBR8aHEhQVwv9Pd851NefzqvLFtg6+W7SzAJXDmuHjCA30Z4dypGww/e3Uz50wYzENXTaWmoYmd+ZXcduoIAGJC/Dl7wiD2FdVw1awU/H1cbMop57Qx9oI7LC64bUGW5OhAhseFAFDb2My8kTF8Y+Jg/vjeDtwuYWJS+x28j9vFtNQoNmSVctupwz3/IlpaYNVDUJUPZ/72KL9FOGX0oRNBWIAv50z0rH+/iDAzNYr3tx5gULiWCFQHH374IR9++CFTpkwBoKqqivT0dObNm8dPfvITfvazn/GNb3yDefPm9XKk6njzyS47KGpXfhUl1Q1EOfPn7y+v5Zr/riExIpCfLRzN4u35zBkezWe7i1m2s7DtzvnjHQVMS4kkIsi+7spZyfz6rW1sybPTm2zJs3ME7ThQiTEwLiGs7b3/ddW0Q8Y1PDak7ffkqGCSo4Jxu4TmFsNJI2JJigxiZloUTc0tBPl1vuT87oLxVNY1HXotgLoKqK+AcKeXTW0pvPZdSP8AEDj1F+BzdHfjaTHBpMUEs7eomjRXPnz8OMz/ObiOoqbcGCjZw6y0SN7feoC4r1M1lLEU1j0B6R/BBf+CcRe276srhxV/BZ9AGDwRkmZCSOxXf69D6H+J4DB37j3BGMPdd9/Nd7/73YP2rV+/nnfffZd77rmH0047jXvvvbcXIlTHo+ySGjIKqzlnwmDe2byfNXuLWeCMTF21pxiwi6L84PkNRAX78a+rpnHaX5fxxoZczho3iPyKOrbmVXDnWe318BdNTeLP7+8kKTKQ08bE859PMiivbWSrs7BTx0RwOMPi2hNBSnQQfj4uUqKCKK9tZOygEGhu5OGrp9HczQzzR5x58907YNf7cNt6CI6B126yF86RC+z20kyI7TAdReFOKEqHMd847Gnnj4plb1E1wzbdD+mLYPQ5kDDFo88LwK4P4PnLuHL0ReTOvLlt5HGb/G3wzk9siSXp0EmUPZ/A/y6AoGgIjoW3fwwpc+3FvqYE/nchHNhkEw8Gzv4LzLzR8zg9pI3Fx0DHaajPOussHn/8caqqbD/q3NxcCgoKyMvLIygoiKuvvpo777yT9evXH/RapQ5lebqtFrr11OEE+LpYtae9emhVRgnhgb68esuJpMUEc9eC0YQH+nLupASWbC+gvLaxrVrp1NHt9efhgb68ddtcXrn5RE505snfmlvOtrwKwgN9D2pIPZRhTokgyM9NtHNnf/2cVH42JxzXw/PgucuIDPYjJuQo69Eba2HHO/aueMl99uKb/iGc/iuY50zMWNJhDd8Nz8LDJ8OLV0HBdrstew28f7dzIW1388nD+NtZUQTufttu2Pfp0cWW+SmIG/+db3BP5ncIfOEiePFqKM6A5iZ442bI+hyeu7RzjF2t+AuEDIIfboErX4SGKnjnx/Dli/D4WfZzXPEC/DwXblgMow+f4L4qTQTHQMdpqD/66COuvPJKTjjhBCZMmMAll1xCZWUlmzdvZubMmUyePJlf//rX3HPPPQDcdNNNLFiwgFNOOaWXP4Xqa8prG/n+s+v538p9LNleQGJEIKMHhTItJbJTO8HKPcXMSotibEIYS++Yz6VOl8oLJifS0NzCz1/fzMvrshkcHtDW7bLV8LgQwoN8GR/rxpcmNueWsy2vnLGDww4/QOrNW+HVG6GxjvBAX2JD/UmOCmp7zTWj4dLNN0LBVshYAvlbj/4L2L3EXhgTp8P6p+Gt2yF6BMy8CaKc6ZtL99rHdU/Bm9+DxGngEwCr/wMtzbDoB7DqX7ZKqYP4sAAubHwHEAiJP/pEkLseEqfCt96EqFSbtPYuhyfOtqWY/V/ahGWa4ZlLoLbs4HNkf2Ffc+Jt4BcEcWPg5J/C9kXw+k3QVA9XvwIjzwK/YBgyA8K8Mz9R/6sa6iVdp6G+/fbbOz0fNmwYZ5111kGvu+2227jtttu8Gpvqe3JKa0iKtNUidY3N/OHd7dw8fxiDw+1duDGGn7++mXc27+edzfsBuGpWstNAGc0DS3ZRXtNIVUMTWSU1XHdiqr0T3fE2JM+G0EFMTArn6tnJvLIuh7rGFq50Xn+QvSuIev5yfh18Gp/mJLHjQCXXzE45dPBN9bDpRWhusA22VzzPORMGExbgY/et+jcs/4utc7/yZXunvPYJOOcvB5+raLdtA0icevC+bW9CYBRc9TI8NBMq98NVr4KPH7ijwT+s/W47/UOITINrF8HbP4IvX4CYUVDolAzKsyEoqv3c9VWw7mkYez4EhMGW12zicB1+VlPAfs95G2DqtyDtJPsD9u796Qtsff/Y82Huj2DIbHhigU1Gp/y883lW/BUCI2Hade3b5vwQfINg0ERImXN07RZfg5YIlPKW+ir44P9Bfeeqvyc+28vcPy3l7U12ndwPth7gqZWZPLc6q+2YV9bl8M6m/dx51iieuG4Gp4yK5YqZyQDMSg3jTvcLZKx4nlW7ixBaON13E/xnLrx8LTx2BhRnICL89oIJrP/FGTx5/YxO/fTbpH8Ez14CDVXM8dnOxzsKqG9qYVyi0z5QnGF74TU3tr8mb6NNAhO+CftWwHs/5VfnjbP9/F+/GRb/ElLnwI1LYeSZMO4Cmzgaqju/tzHw0rfghasOqrqhqR52vmfr7oOi4JLH4YzfwIjT7X4RiEyFEqdEcGCzreN3uWH2LdBUBx/cDQERdn95h0nsitLt+9aXw+zvQeo8m4wObDr8v2fb63dCY40tfXQUNwaufxdmfhfOud9uSznBVues/k/n/wfFGbDrPZh1C/i3t7Hg9oUTvg9p83osCYAmAqW8J/0DWPlPW/x3fLwjn984XRdfXmtXxHrXueP/cKvtgllQWcevFm1l9tAobj55GKeMjuOJ62cy3hk8Na3sA77ns4ipK29jwoeXsiLgxyS/9y178Vv4Z1ud8sTZ9mIDBPn5MH9U3ME9c0r22AtizEiYcg1JDXtoabSTy00Ib4BFt8GD02yC+X2CvdMHyF5tH8/6vb3I7fvMPjcG9iyFSVfY+u5oZ62BadfbC+2WVzu//95PbNVRZd7B9egZS6Gh0iYRsHfdc37Q+ZioNPu62jIoy7TdvMFekIee0h4jQEVu+3n/Ndu2HSz4o61uSZ1r9+371JZCHj65/TN1J3edfUzophQTPQzO/rNt2G4178e2nWPt4+3bWquixl906PfpQf0mEXzNNe+PCwPhM/YrubZDQEtlAf9blcktz6zj+89uYMzgMK6fk8qK9EIyi6tZtrOQiCBfduZXklVcw/Ors6luaOb3F044eC6gpnp8V/yZurhJ/F6+Q1B9AZWBSXDRo/D91TDru3D9e/bCs+aRQ8fW0gJv3gYuH9sYOfx03KaJUZKNv48w7N3LYeNz9u70osdsVcXyv9hqkezVEDUUQuLsxbd0ry39VO63dfFd75STZ0PsGPjisc53/qv+Db528Bn7VnR+zcZnISAcUk869GeIGgplWbY+HmyMrRb8Ac78nU1KLl8od5ahTP8Q3H7wg/W25AAQOsi2Pax/Gl79ji1dPHUufPb3g0sqYBNBQLh9f08kTrOJ6fN/2rYEsN9hUDREH8X4CS/qF4kgICCA4uLifn2hNMZQXFxMQMDxPXBlQHHuHNP37OEXb2xhc245C8YP4vHrZnDlzGRaDPzkpS+pb2rhF+eMBeycPM+uzmT+qFiGduif32bt41CeTcCC+/jGDb/gQr+HyVj4LEy8tL0/fdxoSJhs67EPZd3jtufLWb+D8MS2rpMTXXs4I6YUKdoJC/9k90/8pq3vrimCvcsgaxUMmWXPEz/ePhZsgwPOcqvx4zq/lwjMuslesLNW2W3FGbb754m3HtxYm7fRNpjO/K5tDziUyDRoabTngfYSAdhSwYm32uqVsIT2RFC8G6KG2STWUepcKNplq5tu3whjzoWP7j24FAP23zVh6tFV3cz7MVQXwPa37PPs1fY77CMrlPWLxuKkpCRycnIoLCzs7VC8KiAggKSkvjV97YC24x17F3nhf2yjX0fNTfaCBuzPzSQ29GQ+ufOUtjv8+LAAxiWEsTazlLhQu+j5oyv28M+P02lpqOavDX+HrHsgeVb7ORtq7F152kkwdD4TgTU/P637BuCEKbaBtrkJ3F3+zJsabHfMtJNhyjV2W0QyBEYy1zcb/9BAKANGLmx/zYgzwD8cPvk/mxDaEoFz0c/f0t4zJm7swfFMvBwW/9qOCE6eDcv/z96ZT7/BXpz3fWrvvkXg49/Y7/PEWw///bfekW9bBMFxEHrwdNGAHYzWWjVUnAGDxh98zIRLbBvBJY/b7+KSx+G/OfDunfZ72rccvvivrebK32YT49FImQthibbqadip9jNPufrozuFF/SIR+Pr6kpaW1tthqIGipdk2iH7+oH2etRpGLeh8TOF2aLLVAHVl+zln+uCDqnkunJLI1rwKFo63i5ScOTaef3y8m4sisonev9x2Ibzlc9t1EGDr6/YifNJP285xyC6eCVOg6V/2Lje+y4U5a6WtOpr13fY7UhFImMJZVQcQVw3ET7AlhVY+/jD2XNjwjH3emggikm3vnQNboK4MwpMhMOLgePyCYPr1trrlg/8HXz5vL6ah8baxdsurtr6/8gDsXgxn3GerXw6ntQtpRQ4MO+3Qx4UnQeZK2+Bdltne7tBR6ly48eP25y43nP8QPDwPHjvVVkH5hcBr37H7u1Z/HYnLBWPOsyW6DOd9hsw+unN4Ub+oGlKqR2193SaBiZfb5yW2UdYYw5fZZXYdXqdaqDpwMNGUce6khINO882wrSwNuYfrh9qpHc4ab6eCuDLRKdmW7oOPO8yls/Zx2yWytXHzcFpHyXZXPdRaT5528kGvcRVsQ7JW2d4+XU34pn0MCIfY0fZ3EVsqyN9qf7pWC3U040ZAbKlg7AVwqjOyPtWZbmXdE/DajRCaYMcKHEloArid6rCO1UJdhSXaBunSfdDSZKuGPBE3GubfbZPACbfCnbttb6CRCz37N+hq7PnQXA/L/mDbLY5mJLOXaSJQ6milfwhBMXDBv233RKd3zkfb8jn/oc+4+Zl1NGWvhcBItsgoBrsrmNph1k2MgY9+SfjrV5PWtIfUHY8BMC4hnLdvm8s0nz22EXHGjbZBdfdi2L8Jctfau2pP6pWjhoFf6KETQcqczt0WwV6YTLP9GXHwmBdS50HoYEg+oXP9ePx4WzVUlN59tUur8ETbQDvqbLjw4fZzRA+zo2s/f9B2G73qJfD1YFSzy2Xr9OHwiSA80SaAzM+d9zuKBtq5P4If77BtJb6BMOMGuPIFO/bgaA2ZZT9nyR7bhuPbd9r7+kXVkFI9pqXFdkEcdoq9EEUPs/W9wAdb8/H3cbFkez6ZgZ/SHDSCbeWBTPat6FyFs3sxfPaArZ93+8L6/0FVIYTEMj4hzJYmhs63I1MzP4fnr4DBk+2I2UmXexanywWDJx2cCEr22uqi6d8++DWtd6iBkZA0vZtzuuG6d+yAp47ix9kuq62/H85Zvzt4m4htnN31AVzzGsSMOPw5OopKs/36O/YY6irMaVfb+4l9jPawRNAa27Eazety2c/5xaPtVWt9hJYIlDoa+Vts749hp2KMoTIoBUr2tC3tuGD8IB67YiwpLZksr0mmPiAa/5aazoOpNr9sq1fO+SvMutn2fNno1L1X5NnRuonT7B37dW/bu92cNTDuooMbpQ8nYfLBg8HSP7SPI7qp+glLhPAhturjUCNso4cdfGGM71AKiD/MnfnhLPgj3P7l0SUBsIknMPLwF/fWmUv3LrcN3kHRXy3GY2H8xfYx7TDdYnuBJgKljkbGEvs47FQeWrqbR7e5oDybL/fup6S6gdPGxHNq43J8aOE7l1/KzWefaI+vslNI01BjexuNPd82wMaOsj1K1j1pSxutg5VaGyODoux8NvN+AqfcfXSxJkyxddKFHZak3PWBrRrp7sIpAt/+wA6IOhpxYwCxUyW3NuAeLbfPVxtJO+8OuPnTw08N0droXV1oP3dvdtlMOQG+v6b7RNyLNBEodTR2L4H48eysDubvS9LZZ2wD79r16/BxCaf6b7fTD6fOs90EQ5wuja2JYNf7thqlteEVbL1/6T7Y8ZZNBC7fznfZ/qFw2r22h87RaK3q2fq6TUAf/dImstHnHPo14Yn2/Y6Gf4hNAHFjPJur51jyC2q/4z+UgIj2gWtHUy3kLbGj+sz4gVbaRqCUJ5qb7AU8axXNs27mjpe/JCzAl/NPPAlW/JMNG9ezMGkyIa/fbO+4L3vG1v+3LiJSZaePYPMrtsEwZU77ucecZ+u4F/3AVs8MGn9sGhIj0+zApxV/hc/+Yaugpl1ne8Ica+f81bZh9EUiNlkU7fS8x9AAo4lAqVbpi2HRrfCdxZ3vMje/Am98z1azAOt9prI5t5wHr5jCqaOCYQWkkMeZwVVQUAFXfNLel761RFBdYKdfSP/Qdo3seOfs4wfffNLOcVOw1Q6yOhZcLvtZMpbakbppJ9mBU94w7FTvnPdYCU+0iaCPTOnQ12giUKrVrvfsfDnL/gjn/9NuK9xpJ18bNB5GLYSACD4rH4tIBqePiUf83DQFxjItoISJpWvsrJEd68mDYgCxVUP7PrV35WPOPfi9o4fB+Q/Cy9dByonH7jO53HbGztZZOweqMKedINrD+YEGGE0ESrXK+cI+bnwO5txuJyN76VrbXfKyZ9t6y6Q/u57kqCAC/exdvU/scM4oWg9lRXBSl6kH3D62l0pVgZ1nx+3X/dz7YNeqHTSxvW+8Onai0kDcWjV0CJoIlALbmHpgC0y91lYFvXaT7cpZXQBXv9qpy2R6QSUj4jo0qEYNs9M2uP26v9sPibeJoLrQNuAebrH1vtCY2R/N+I5tl+lu+gvl3V5DIrJARHaKyG4Ruaub/X8TkY3Ozy4RKfNmPEod0v6NdkTtqLPt1Mt56yE8iaLL3uLdmjH8b1UmLS2GxuYW9hZVMyK+w6jc1ov38DO67+cfEutMl7yxzw0kGjACwu1kd6pbXisRiIgbeAg4A8gBvhCRRcaYba3HGGN+1OH424C+M/mG6v+aG223zZgR7dVCSdNh+Okw4kzeLU3g+09txBi7rsCw2GDiQv1pbDaM7JgIWgdBTbi4+/cJiYc9y+zvmghUH+TNEsFMYLcxZo8xpgF4ATj/MMdfATzvxXiU6mz1w/DPGZCz1iaCyDS7spTbh8aEafzx/V2Mig/lxZtm4+MSPk0vYle+nUqhU9XQyAV28ZaxF3T/Ph3nvtdEoPogb7YRJALZHZ7nAN3+FYhICpAGfNzdfqW8Ysc7gIH3fmrXtO0w7P/ltTlkldTwxHUzmDU0mqnJkaxIL8Lfx40IDOu4aIzb1y7ecijBTiKIGto+rkCpPqSvNBZfDrxijGnubqeI3ATcBJCcfJSjK5XqTm2pXSUqbmzbtA4maTp7C6uob2rhwY/TmZocwfxR9sI9b0QM9y/eRYi/D0Mi23sMeaR1LEEfmn9eqY68WTWUCwzp8DzJ2dadyzlMtZAx5hFjzHRjzPTYWL2jUsdAxsdgmmk++35ImgHA8to0Tv3rJyz8+wr2l9dxx5mj2mYNnTcyFmNg5Z7izu0DnmitGhoy81h+AqWOGW+WCL4ARohIGjYBXA5c2fUgERkNRAIrvRiLUp3t+pB6vwhmP1nGpzf+neAtz7GyJgE/dzZ/u2wykcG+nDgspu3wCYnhhAf6Ul7byPC4o5yLZ8gsmHWLnWhOqT7IayUCY0wTcCvwAbAdeMkYs1VE7hOR8zocejnwgunPK8+rvqWlGXZ/xJf+0ymta2FXcwKc9Tv2FNWRHB3EORMHd0oCAG6XMHe43XbUJQK/IFj4RzuTqFJ9kFfbCIwx7wLvdtl2b5fnv/JmDEodJHc91BTzhtgZPncXVDElOZJ9xdWkRgcf8mUnj4rlnc37GTP4K6xOpVQf1lcai5XqOTvfxYibd2vHAJBRWE1LiyGzuIaTRx66DeriqUmkRAVpIlD9jq5HoAYWY2DbG+yPmkEZoYQH+rK7oIr9FXXUN7WQGnPoEoHbJcwa2ourWynlJZoI1MCSvxVK9rDMfQKJEYGcMDSaPYVV7C20S0mmHSYRKNVfaSJQA8u2NzHi4r9F45k1NIrhcSFkltSwK78S0ESgBiZNBGpg2fYmNYNnk1FjSwPD4oJpbjEs21VIgK+L+NA+usqWUl6kiUANHAU7oGgnWyLmAzB7aDTDY+2YgFUZxaRGB+Ny9a21ZJXqCdprSA0cuxcD8KlrFiH+9SRFBhIV7AdAQ3OLVgupAUtLBGrgKM8Bv1A2VQSRGhOEiBDs70NCuK0OOlyPIaX6M00EauCo3A9hgw8aODYszo4UTjvMYDKl+jNNBGrgqNxPS8ggsktqOlUDtU4prSUCNVBpIlD917qn4B9T7dxCAJX7qfaPpcXQqUQwJTmCAF8XI+KOcg4hpfoJbSxW/VNLC3z2AJTsgYpcCB8ClQcoHmQnfut493/epATmjYgl0mk4Vmqg0RKB6j8yV8J7P4PmJtj7iU0CYNclrimB5gb2t0QAMLRDIhCRtt5DSg1EWiJQ/ceaR2Dra+AbCMUZ4PaH5noozYTASAD21tt1BfTuX6l2WiJQ/YMxkLXSXvw//Ztdj3j6t0HcbNn6Jb96dgkAO2uCtVFYqS40Eaj+oXSf7R56+i8hfjyYZph5I42hiexN30ZtSQ4Am8qDSIsO6t1YlepjNBGo/iHLrnT6l90JmKtfg2+9SXPkUHbURZLsKmBMiJ1ddEtFoJYIlOpCE4Hq84wxNLccYSXTzM+pcYXy0FYfMmqDYOh8XlmXzZaaKEb5lTAvvpEiE0YjPjqVhFJdaCJQfd7fFqdz9t9XcNhlrTM/Z5N7LAYXn6YXAbDoyzyqg5IIaCgmVQ5QJLbrqCYCpTrTRKD6vNV7itmZX0lGYVX7xrpyqC2DpgaozIeSDD6pGw7Ap7uLqahrZPWeEmKSRwLgzluHb0QCfm6XJgKlutDuo6pPM8a0LRqzfFcRw+NCYcX9sOTX9gDfYBg8CYCVTaMIC/Bh1Z5ilu4ooKnFMHLUeNgNNNaQljaC966aR2iAby99GqX6Ji0RqD6tqKqB0ppGAFakF9qNmZ9BeDLbJ93NquD5mAObafCLYItJ5YpZyVTVN/GPJelEBvkyaszEtnO5wga3zSuklGqniUD1aelOaWB4XAir9pRQ39QMBdsheTb3Fc7n8gNXsefadTw55WWaxYdvnZCKCGQUVnPKqDjcwdHg51z8Qwf14idRqu/SRKD6tJ1OIvj2nDRqG5vZmJ4FFbk0RI9ibWYJAB/truLLEh+So4JIjAhkfEI4AKeNiQcRiEy1JwtL6I2PoFSfp4lA9Wm78quICPLlvMkJ+LiE9C1fALCjOZHGZkOAr4sl2/PZmV/JyHi77OQpo2IJ9HVz0sgYe5LWRKAlAqW6pYlA9Wnp+ZWMjAslxN+HqSmRFO35EoBlpbH4+7i49oRU1mWWsreomlFOIvjeKcP58EcntTcKR6TYx1AtESjVHU0Eymse/GAT//pw81d+vTGGnfmVjIi3dfznT04grHI3Te5A3s50M2toNGdPGEyLgeYWw8hBNhEE+LoZEtVhGomx58PkqyEo+mt9HqX6K+0+qrziQHkdEz+7lTifGjh9Dbg8v+dY9GUe6zNL+e7JQ6msa2KUc4G/fEYymxfvZ0djArsKa7h0ZgoTEsOJDfWnsLK+rURwkORZ9kcp1S0tESiveGn5l8yVTYxpSadpy2vdHvPgknRufW49DU0tnbY/s2I7b36+iZ++sgmAaS1b4Yv/4nYJ43zy2NGcCMC8EbG4XMLpY+Lx99GBYkp9VR6VCETkNeC/wHvGmJYjHa8GtpqGJgrWL8IthiITRtiS38K4C8Dd/t8tr6yWf3ycTmOzIdDXzZ8vmYiIUFnXyMX5D3JuwOfckHEHU8SPsUv/AE11EBKHb20hMUMvZ2xFGCOdKqOfLRjFlTOT8fPR+xqlvgpP/3L+BVwJpIvIH0VklBdjUse5V9fnMrdpNdV+sdzd+B38yvfCxmc7HfOfTzIwBq6clczL63J4ZLldTWztvlLmuDYTRD1P+f2ZJ/3/DwkdbJeafOP7AMyfO593b5+HiAAQEeTHhKTwnv2QSvUjHiUCY8xiY8xVwFRgH7BYRD4XketFRMfr9xP/W5XJ6j3F7Ru2vwU56476PK+uSme+exPusd/go5ZpFIRNsOsHO5PGlW75iGHrfsOTg1/ld41/YXXonSQv+T7lNY1s3bGdJCmiae4duAaNIyTAD65+Fc76HdSX2zeIG30MPq1SqpXHjcUiEg1cDVwDbACeBeYC1wLzvRGc6jl1jc3c99ZW5o+KY9bQaLvu7+u3QOwouHFJt6/ZW1TN6xty2ZRTxrwRsdwwN43M4mqiClYS4FePGfcNwjY2szziPC7J+h31ez9ncUUSsxbdzOVShk9VMNIcQXhICAsbV/Lc5+uozvgcAJ8x58Apd0NjDQSEQdRQSDsJDmyBsMSe/GqU6vc8bSN4HRgF/A841xiz39n1oois9VZwqudszi2nsdmwu8CZ4TN/MzRUQu5aKMuGiCFQsR98AyAwEmMM1z6+hpzSGkIDfFmzt4RvTk/ig60HOMO1jha/UFxpJ5EWs4Z3m2ZyiV8I6978J+8WDuccvyI+nPQAZ150PQAB+dvg3yeQveo14uoyafQLwHfQBNum4A6z8YjApf+DqgL7u1LqmPG0jeAfxpixxpg/dEgCABhjpnshLtXD1u4rBSCzuJq6xmbIXNm+c/tb0FANj55iSwnA9v2VxJWu59GTG3jmhlnUNDTzytoclm7ex7m+a3CNPht8/EiLCWZnSQtNo89jUtnH3B32PiYyjTMvuLb9/HFjqA4ewsz6VUx17aImdhK4u6lxDIyA2JFe/BaUGpg8TQRjRSSi9YmIRIrI9470IhFZICI7RWS3iNx1iGMuFZFtIrJVRJ7zMB51jK3LtImgxcCewmrI+tyOyI2fANvehDWP2DWBM5ZAfSVLtuTysN/fOG3VdUzY+Q+mDwnlkeV7SMp7nxBTDdOuAyA1Jpi88lo2RJ9DsNSRVLcLmX1L53EFIgRMOI857q2MlUyCh83phW9AqYHL00RwozGmrPWJMaYUuPFwLxARN/AQsBAYC1whImO7HDMCuBuYY4wZB/zQ48jVV7fpJSjY0fbUGMP6rFImJNqeN+n5FbZEkHKiHZWbvcquARCRDM0NsHsJhZveJ1oqYcgsWPEXHnTfT2FFNVe5l1AfORKSTwDsamDGwD/SY8gycRj/MJh81UEhuUefgx9N+EozPqmze+Z7UEoBnicCt0h7xaxzkfc7wmtmAruNMXuMMQ3AC8D5XY65EXjISSwYYwo8jEd9Vc1N8MYtsOqhtk37imsoqW7gkmlJuF1CceZWqClqTwQA9RVw6dMQGEnN5reYXL6Yep9QuPYtWPAnBh9Yyv8C72eyKwP/WTe01eOnRttBXit2F/Nk/N3IN58E/27WBBgyCwLtUpIkzfDmN6CU6sLTXkPvYxuGH3aef9fZdjiJQHaH5zlA13H+IwFE5DPADfzKGHPQeUXkJuAmgOTkZA9DVt2qyIWWJtsA7GitFjphWDSp0UH45HxidySfCDHDIWkmxIykKX4SMmIB7m1vc6arkfqRF+Hv4w+zb4bK/Zz42QO0uANwTbqs7dypHUb7JkyYD8OHdh+X2wcmXQ55GyAo6ph/bKXUoXmaCH6Gvfjf4jz/CHjsGL3/CGz30yRguYhM6FgNBWCMeQR4BGD69OmHWcFcdbLpZUicCtHD2reVZTqPWW2b1mWWEhrgw/DYEEbEhTIocz0Ex1ISMISAhiaCbvgQgMv/s5Lo7EE87FeJvwAzrmg/72m/BNOCKzgWAiPbNocH+hId7EdxdQPzR8UePt6zfq89gpTqBZ4OKGsxxvzbGHOJ8/OwMab5CC/LBYZ0eJ7kbOsoB1hkjGk0xuwFdmETg/q6qovhte/As9+Euor27aX77GN5DrS0sH1/BZ/sLGBqciQulzAyPoSRjdtpSJjJgr+v4O7XNoMI+ZX1rM0sRYafSqP4UR8QBykdGnVdLjjzNzDnBweFMjQ2mMSIwCMvE6lJQKle4ek4ghHAH7CNvgGt240xhyjnA/AFMEJE0rAJ4HLsNBUdvQFcATwhIjHYqqI9ngavOsssrmZweKCdcyfL6f5ZkkHNq7diLv4vwQG+NBXvtf/ozfXc/PD7fJBlCPX34dtz0wAYEevPEAp4ryiSgsp6PtqWT11jM5/ssusF375wMr5774XgWHC5PYrrl+eOo76pBdELvVJ9kqeNxU8A/waagFOAp4FnDvcCY0wTcCvwAbAdeMkYs1VE7hOR85zDPgCKRWQbsBS40xhT3P0Z1UFMey1ZbUMzZz2wnH9+nG43ZH4Obn9qTriDoPQ3uf/+37F2XwlfbNjQ9pqQujy+e9IwVvz0VE4eaattxgaV4xbDsoJgUqODqGloZkV6EZ/sLCQu1J/Rg0LhxNtsfb6HxieGMy0l8sgHKqV6haeJINAYswQQY0ymMeZXwDlHepEx5l1jzEhjzDBjzO+cbfcaYxY5vxtjzI+dwWoTjDEvfNUPMuBsehn+lApbXwdgT1EVdY0tvPllHsYYOw4gaQZP+l1GjolhduMqLvnPSgKqsqn1swu0/OWMSO5aOJrwoPbBW0PIByCHQTx27XTCAnx4Z1MeK9ILOXlkrN7VK9UPeZoI6kXEhZ199FYRuRA4QoWv8oqWFjKfvsXW/9eVwd7lAGQUVPCi331MKF3C9n15sH8TLUNm88yqbLKDxnFqaA6XTR/C2IASAkecbM/V2nNo+9tt4wr8Kmwj8qknzGR4XCinj41n0Zd5VNQ1MX9UXE9/WqVUD/A0EdwOBAE/AKZhJ5+79rCvUF5R+MnDpOx5jvdDL8IkToPCXQCUZm1nlmsH9/g+w46Vb4NpZh1jyCuvI3LkCbgrsvnTqaH4N5TAoAkQEAHl2dBYB698Gz75o32Dkr3gE8BNZ58IwMLxdilIl8Dc4TG99KmVUt50xETgDB67zBhTZYzJMcZcb4y52BizqgfiUx2VZRP+6W/4tHkcNxdezF5JhqKdADQd2ArAICllbvqfMOLiwV2RJEYEMnzyPPv6rc5KYZGpdhK5sizIWw/N9bDfLgpP6T47tYQzBcS8ETEE+bmZkhzZqQpJKdV/HLHXkDGmWUTm9kQw6jAaamDRbbS0NPNA4G3MHhLNa9nB3CGFUFNCQMlOWnBRGDWN+JIv2OEaxvKsOu47fxw+ibEgLthi2xOITLEX++IMyPzMbivZA3XlNhFEpbW9bYCvmwcum0xsqH/Pf2alVI/wdEDZBhFZBLwMVLduNMZ0vxitOjYyP4fqIqgutHP9VOTwZ25k+KhxfG/+cO67fwn4QkvhLmJrMygNSCLgG3+Ap09nHWN59FvTOWNsvD1X3Fg7tTRAZJpd8WvPMvse4gLTAgc220SQ2jnvnzluUI9+bKVUz/I0EQQAxcCpHbYZQBOBtxTuhCcWtj8fPIldc+/n8deaeHB4DMnRQQQljIFCKM/eynCTRXXEBJKHzmD/BS9zfsokQiLj21+fOBXyt4BfqB35GzEEGqpg32cw+hw71fTuJXZbZNrB8Sil+i2PEoEx5npvB6K62PkeAM3XvMVLO+qYOnUWH20vAHZx4jDb/XPM2PHUL/OlePcahko+eYPsHD+DJ5958PkSp8H6p237gIidSRRs+8DYCyBnLWx7w26LTPXmJ1NK9TGejix+AlsC6MQY8+1jHlF/01gHy/8Mc3/c/aybh5L+IcRP4NXSNO5esYmQNauICvZj7OAwokNsff1JowaxZ+lg4jI/xCWG0OSJhz5f4jT7GJliH8M7zP6RfAIMngS7nPn+orREoNRA4mn30beBd5yfJUAYUOWtoPqVvcthxV9h36ceHV5W08BNjyyhJWsVTcPP4O+L0xkzOIwhUUFkldQwd0R7F86xg8PIdg8h2pQAEJYy6dAnjh1jp3mOc5aEaC0RRCRDeKJNBK0idIZXpQYST6uGXu34XESeBzy7sg10xbvtY2P14Y9zvPBFNr77luHya+afucPILavl9xdNYFpKJP9dsZdLZyS1HSsimJiRUPgZ9fjjH3WYqZ/cPnDL53a5R7DtBAERkOI0DA9yShOhCeAbeHSfUSl1XPO0RNDVCECHmXqiJMM+NtR0uzu3rJa7Xt3E7oIqmlsM/1uZycWhW6mQUB7YEc7M1ChOGhFDiL8Pt58+gsHhnS/S0akTACgISD3yJHBhg9sv8iJwzetwxq/t89YSgbYPKDXgeNpGUEnnNoID2DUK1JEUO4mg0SaCkuoGvv/seuYlCpfm/oEfFFzEuqpo1uwt4bbThpNXVs2c8A2YUWewsCWR780fdtj5fUaOmwpfQF3UqKOPLXFq++/hSRA6GOJGH/15lFLHNU+rhkK9HUh/ZYp3I4BpqEaAJdvzWbmnmBmZrxHju5SL3WFcctFvueeNLdzx8iamhVXgX18CI0/hoalTj3R6wpLG0hwcR9qMhUc89rBE4NvvQ0D41zuPUuq442mJ4ELgY2NMufM8AphvjHnDe6Ed/5obapHyHATYnVvACGBlRjGDgoTbAz6BGrgseD3uGUOorGvk9+/u4LJxIbABCPaw5s3HH/ed6ccmYK0WUmpA8rSN4JetSQDAWUryl16JqJ9objH88bn3cDk1alkHCjHG8HlGMbfEfYm7phDGX4y7IhvyNnDjvKG8cNNsLhrrdDFtbdRVSikv8zQRdHecp6OSB6Q1e0vI3LWp7XlxaSk7DlRyoKKWc2vegNjRcPZfwOUD295ARJg9NBp3vZNvtYpGKdVDPE0Ea0XkfhEZ5vzcD6zzZmDHu71F1aTKAQAa/SPxbanjz+/vYLjkElWxA2Z8B4KiIO1k2PZm+2pjda2JIKJ3AldKDTieJoLbgAbgReAFoA74vreC6g8yS6oZ7s7HBMXgDh9MmLuBpTsLGRlSbw+IGWkfx11gJ3o74JQe6rREoJTqWZ72GqoG7vJyLP1KdkkNC30KkOjhiGkmKdhAHUwb5APZtE830TrT54HNti9/XRm4fHVQl1Kqx3hUIhCRj5yeQq3PI0XkA69F1Q9kFteQIvshehj4BhEX0AzAhBjnK/cPs4/BdtF4auw0EdSV24ZiXRtYKdVDPK0ainF6CgFgjClFRxYfkjGGwuISIpuLIWoo+AUT4dPIg1dMYdpgpxDmF9L+6PaDmmL7vLZMq4WUUj3K00TQIiJtM5GJSCrdzEaqrLLqes5p+sg+iR4OvkFIYw3nTkrA3TrnkL8zRk8EgqLbE0FduTYUK6V6lKddQP8f8KmIfAIIMA+4yWtRHc9qS/F/8lx+6buZsuipRAw7FTKWtM81VF8FCPgFt7+mUyIo00SglOpRHpUIjDHvA9OBncDzwE+AWi/Gdfza+T5BRZu5q/E75F/yJgSEgW9w21xD1Ffa0kDHNoCgqC4lAq0aUkr1HE+nmPgOcDuQBGwEZgMr6bx0pQLIXUeDO4iX6ubzy2jnrt8vCBqq7ViBhsr29oFWQTHt3Udry3RUsVKqR3naRnA7MAPINMacAkwByrwV1HEtdx3ZAaOIDg0k0M+ZFto3CEwzNDc4JYKuicCpGjJGSwRKqR7naSKoM8bUAYiIvzFmB/AV5j3u55rqIX8LWxhOSlRQ+/bW9oCGattG4N9lMtegaFsSqK+ElkZtI1BK9ShPG4tznHEEbwAfiUgpkOmtoI5b+VuguYE19Skkp3RIBL7O74019mJ/UNVQNGDsCGPQEoFSqkd5OrL4QufXX4nIUiAceN9rUR2H6hqb2bjiQ2YDy6qT+Wa3JYIaaKiCkC5DMIKi7GPJHvuoiUAp1YOOegZRY8wn3gjkePfmxlx8tn5GoSucXBNNSnR3JYLq9l5DHQVF28fWZS21sVgp1YO+6prFqovF2wuY5rOHgtBxBPv5MDEpon2nn5MIGmqOkAi0RKCU6nm6psAxUNfYzMb0LFLduTDjeraevKDzAb5O1dBh2wiA4tZEEOHVeJVSqiMtERwDKzOKGdu8wz5JnHLwAa0lgpoS2430oBJB1zaCCK/EqZRS3dFEcAws3p7P2b7rML7BkDLn4ANa2wiq7EI1ByUC30BbamjdHxDmvWCVUqoLryYCEVkgIjtFZLeIHLSegYhcJyKFIrLR+fmON+PxBmMMy7bvZ6F7LTLyrO7XEWjtNVRVYB+7JgJorx7yCwG3r3eCVUqpbnitjUBE3MBDwBlADvCFiCwyxmzrcuiLxphbvRWHt23bX8GQqi8J8yuDsed3f1BriaDSuePv2kYAEBwN5VnaUKyU6nHeLBHMBHYbY/YYYxqwS1we4kp5/NqYXcbZrtW0+ATAiDO6P6itaijfPh6uRKDtA0qpHubNRJCIXZSxVY6zrauLRWSTiLwiIkO6O5GI3CQia0VkbWFhoTdi/cp25JWy0OcLZMSZnaeW7sjlAp/A9hJB17mGoEMi0BKBUqpn9XZj8VtAqjFmIvAR8FR3BxljHjHGTDfGTI+Nje3RAI+kKWsdsZQhh6oWauUX1N5G4He4EoEmAqVUz/JmIsgFOt7hJznb2hhjio0x9c7Tx4BpXoznmGtpMUjJbvskoZtuox35BkN9uf2926ohpwupjipWSvUwbyaCL4ARIpImIn7A5cCijgeIyOAOT88DtnsxnmMup7SWiKYi+yR08OEP9usw5YRWDSml+hCv9RoyxjSJyK3AB4AbeNwYs1VE7gPWGmMWAT8QkfOAJqAEuM5b8XjDtv0VxEspTX5h+HS80HentcEYaR9p3JE2FiuleolXp5gwxrwLvNtl270dfr8buNubMXjT9v0VjJVSXGEJRz64tSHZL8Q2HnelJQKlVC/p7cbi49qOAxWk+JbjCvcgEbSWCLprHwAIdqambm0rUEqpHqKJ4CgZY9iVX4kxhu37KxkkpRDqSYmgNRF00z4AEDMCLnwYxpx77IJVSikP6OyjR+njHQXc8NRazhgbT25JJWEBJRB2hIZiaG8XOFSJQAQmXX7sAlVKKQ9pieAobcopRwSW7igghnJctBy5xxC0lwi6m15CKaV6kSYCT5Vlw8vXk3WggJSoIF787gl8a7yf3edJY/GR2giUUqqXaNWQp/atgK2vERA0geHxJzEtJZJpNUGwGw9LBEeoGlJKqV6iJQJP1ZYCEFWxk5HxTvVOxX77qCUCpdRxTEsEnnISwWjZR3O8czGvzAOXLwTFHPn1HccRKKVUH6KJwFNOIhgrmdTGORfzygMQOqj7AWJdtVUNaSJQSvUtmgg85SSCNDlAQ4TYbRV5nrUPQIeqIV2GUinVt2gbgaecROASQ0DJTrutcr9nYwhAu48qpfosTQSeqi1ln8uZVfvAJvtYsd+zUcXQngC0sVgp1cdoIvCQqSnly8Zk6tyhcGAz1FdCQ6VtI/BEwhSY/3MYdop3A1VKqaOkicBDLTWllJgQKiNH20RwNF1HAdy+MP9nh17OUimleokmAk+0NONuKKecYGTQRMjfCqv/bfd52lislFJ9lCYCT9TZJSbLTAh+SVOgqRbWPQkjF0DC5F4NTSmlvi7tPuoJp8dQmQkhcMolEOgLaSd5Xi2klFJ9mCYCTziJoMEvDF//QJ0uWinVr2jVkCdqy+xjoK4eppTqfzQReKJ1MFlQZC8HopRSx54mAk84icA3JLqXA1FKqWNPE4EnnEQQGKolAqVU/6ONxR4wtSVUmiAiQoJ6OxSllDrmtETggcaqEspNMFHBfr0dilJKHXOaCDzQWFVMGcFEh2giUEr1P5oIPGBqSikzIUQF+/d2KEopdcxpIvBEXSnlhBAVpCUCpVT/o4nAAz715ZSZYKK0akgp1Q9pIjgSY/BrKKeMEKK1sVgp1Q9pIjiS+kpcNFPjCiXA193b0Sil1DGnieBInMFkTf4RvRuHUkp5iSaCI3ESgQmI6N04lFLKSzQRHImTCCRIZx5VSvVPmgiOpHXCuWBNBEqp/smriUBEFojIThHZLSJ3Hea4i0XEiMh0b8bzVZiaEgD8wmJ6ORKllPIOryUCEXEDDwELgbHAFSIytpvjQoHbgdXeiuXraKwqAiAwPLaXI1FKKe/wZolgJrDbGLPHGNMAvACc381xvwH+BNR5MZavrL6iiCoTQERocG+HopRSXuHNRJAIZHd4nuNsayMiU4Ehxph3vBjH12InnNPBZEqp/qvXGotFxAXcD/zEg2NvEpG1IrK2sLDQ+8F10FJdTKkJ0SmolVL9ljcTQS4wpMPzJGdbq1BgPLBMRPYBs4FF3TUYG2MeMcZMN8ZMj43t2br65upiSk0oCRGBPfq+SinVU7yZCL4ARohImoj4AZcDi1p3GmPKjTExxphUY0wqsAo4zxiz1osxHbWW6hJaAiKJDwvo7VCUUsorvJYIjDFNwK3AB8B24CVjzFYRuU9EzvPW+x5LZTUNBDaVEx4V39uhKKWU13h1zWJjzLvAu1223XuIY+d7M5auNmSV8tine/nbpZPx8+k+Hy7bcYDzqGHQ4ME9GZpSSvWoATuy+P6PdvHOpv2syyw95DErt2bgEkN8fEIPRqaUUj1rQCaC3QVVrEi3A8VWpHffC6mxuYVtGfsAcAVH91RoSinV4wZkInhmVSZ+bhcj40PaEkJXa/aW4FtfZp8E6jxDSqn+a8Algqr6Jl5Zl8M5Ewdz7sQEtuSVU1xVf9Bx//kkg+RAZ7BzUGQPR6mUUj1nwCWCt7/Mo6q+iWtOSGHeyFiMgc8yivlsdxHffvILsktqWLWnmBXpRVwwyhk7oCUCpVQ/5tVeQ33Rqj3FxIb6M2VIBC0GwgN9eXZVJtvyKqisb2LH/goig/2IC/VnToLYjq+BWiJQSvVfA65EsC6rlOkpkYgIbpcwd3gMq/eWEOjn5r/XTqeuqYWteRXcdupw20YgbggI7+2wlVLKawZUIiioqCO7pJZpKe13+GdPGEyovw+Pfms6p42J56XvzuZHp4/kshnJUFtiSwMivRi1Ukp514CqGlqfZccMTO2QCM6ZOJgF4wfhdtmL/fC4UG4/PdTurCkBXaJSKdXPDagSwbrMUvx8XIxLCOu0vTUJHKS2VBuKlVL93oBKBGszS5mYGI6/j9uzF9SWaolAKdXvDZhEUNfYzJbc8k7tA0dUU6IlAqVUvzdgEsGW3HIam83RJYLaEh1MppTq9wZMImidXG6qp4mgoQaa6rREoJTq9wZMr6EF4wcRE+JPTIi/Zy+oLbGP2kaglOrnBkwiSIkOJiU62DYA7/8S0k4+/PiAGicRaIlAKdXPDZiqIQBy1sF/5sHT58OrN0B95aGP1RKBUmqAGDAlAjY8C2/dDmGD4cTbYOVDsOcTCI7p/vjWJKElAqVUPzdwEkH0MBh5Fpz/TzttxMiFsPa/0NJ06NcELYCYkT0Xo1JK9YKBkwiSZ9ufVqlz7I9SSg1wA6uNQCml1EE0ESil1ACniUAppQY4TQRKKTXAaSJQSqkBThOBUkoNcJoIlFJqgNNEoJRSA5wYY3o7hqMiIoVA5ld8eQxQdAzD8Ya+HqPG9/X19Rg1vq+nr8aXYoyJ7W7HcZcIvg4RWWuMmd7bcRxOX49R4/v6+nqMGt/X09fj645WDSml1ACniUAppQa4gZYIHuntADzQ12PU+L6+vh6jxvf19PX4DjKg2giUUkodbKCVCJRSSnWhiUAppQa4AZMIRGSBiOwUkd0iclcfiGeIiCwVkW0islVEbne2R4nIRyKS7jxG9nKcbhHZICJvO8/TRGS18z2+KCJ+vRxfhIi8IiI7RGS7iJzQl75DEfmR8++7RUSeF5GA3v4OReRxESkQkS0dtnX7nYn1DyfWTSIytZfi+z/n33iTiLwuIhEd9t3txLdTRM7qjfg67PuJiBgRiXGe9/j391UMiEQgIm7gIWAhMBa4QkTG9m5UNAE/McaMBWYD33diugtYYowZASxxnvem24HtHZ7/CfibMWY4UArc0CtRtfs78L4xZjQwCRtrn/gORSQR+AEw3RgzHnADl9P73+GTwIIu2w71nS0ERjg/NwH/7qX4PgLGG2MmAruAuwGcv5nLgXHOa/7l/L33dHyIyBDgTCCrw+be+P6O2oBIBMBMYLcxZo8xpgF4ATi/NwMyxuw3xqx3fq/EXsASnbiecg57CrigVwIERCQJOAd4zHkuwKnAK84hvR1fOHAS8F8AY0yDMaaMPvQdYpeDDRQRHyAI2E8vf4fGmOVASZfNh/rOzgeeNtYqIEJEBvd0fMaYD40xrQuMrwKSOsT3gjGm3hizF9iN/Xvv0fgcfwN+CnTsgdPj399XMVASQSKQ3eF5jrOtTxCRVGAKsBqIN8bsd3YdAOJ7Ky7gAex/7BbneTRQ1uEPsre/xzSgEHjCqb56TESC6SPfoTEmF/gL9g5xP1AOrKNvfYetDvWd9cW/nW8D7zm/94n4ROR8INcY82WXXX0iviMZKImgzxKREOBV4IfGmIqO+4zt29sr/XtF5BtAgTFmXW+8v4d8gKnAv40xU4BqulQD9fJ3GIm9I0wDEoBguqlS6Gt68zs7EhH5f9hq1Wd7O5ZWIhIE/By4t7dj+aoGSiLIBYZ0eJ7kbOtVIuKLTQLPGmNeczbntxYdnceCXgpvDnCeiOzDVqWdiq2Pj3CqOaD3v8ccIMcYs9p5/go2MfSV7/B0YK8xptAY0wi8hv1e+9J32OpQ31mf+dsRkeuAbwBXmfYBUH0hvmHYZP+l8/eSBKwXkUF9JL4jGiiJ4AtghNNbww/buLSoNwNy6tv/C2w3xtzfYdci4Frn92uBN3s6NgBjzN3GmCRjTCr2+/rYGHMVsBS4pLfjAzDGHACyRWSUs+k0YBt95DvEVgnNFpEg59+7Nb4+8x12cKjvbBHwLaf3y2ygvEMVUo8RkQXYasrzjDE1HXYtAi4XEX8RScM2yq7pydiMMZuNMXHGmFTn7yUHmOr8/+wT398RGWMGxA9wNra3QQbw//pAPHOxxe9NwEbn52xsPfwSIB1YDET1gVjnA287vw/F/qHtBl4G/Hs5tsnAWud7fAOI7EvfIfBrYAewBfgf4N/b3yHwPLbNohF70brhUN8ZINgedxnAZmwPqN6Ibze2rr31b+U/HY7/f058O4GFvRFfl/37gJje+v6+yo9OMaGUUgPcQKkaUkopdQiaCJRSaoDTRKCUUgOcJgKllBrgNBEopdQAp4lAqR4kIvPFmclVqb5CE4FSSg1wmgiU6oaIXC0ia0Rko4g8LHZdhioR+ZuzvsASEYl1jp0sIqs6zJXfOpf/cBFZLCJfish6ERnmnD5E2tdQeNYZdaxUr9FEoFQXIjIGuAyYY4yZDDQDV2EnjVtrjBkHfAL80nnJ08DPjJ0rf3OH7c8CDxljJgEnYkejgp1p9ofYtTGGYucfUqrX+Bz5EKUGnNOAacAXzs16IHYSthbgReeYZ4DXnDURIowxnzjbnwJeFpFQINEY8zqAMaYOwDnfGmNMjvN8I5AKfOr1T6XUIWgiUOpgAjxljLm700aRX3Q57qvOz1Lf4fdm9O9Q9TKtGlLqYEuAS0QkDtrW803B/r20zhp6JfCpMaYcKBWRec72a4BPjF11LkdELnDO4e/MW69Un6N3Ikp1YYzZJiL3AB+KiAs7y+T3sQvfzHT2FWDbEcBO2/wf50K/B7je2X4N8LCI3Oec45s9+DGU8pjOPqqUh0SkyhgT0ttxKHWsadWQUkoNcFoiUEqpAU5LBEopNcBpIlBKqQFOE4FSSg1wmgiUUmqA00SglFID3P8HkziUWt6YEPMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# model.load_weights('py/CNN/cnn')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "plot_acc(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 596us/step\n",
      "Loss: 0.5523621773719788\n",
      "Accuracy: 0.7839999794960022\n",
      "predict accurscy: 0.784, precision: 0.7870021030273812, recall: 0.794345238095238, f1: 0.7884469497880094\n"
     ]
    }
   ],
   "source": [
    "#測試集\n",
    "model.load_weights('py/CNN/cnn')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6130/6130 [==============================] - 4s 635us/step\n",
      "Loss: 0.4609488668293976\n",
      "Accuracy: 0.8052202463150024\n",
      "predict accurscy: 0.8052202283849919, precision: 0.8096705860537732, recall: 0.8080133449418098, f1: 0.8087433682122821\n"
     ]
    }
   ],
   "source": [
    "#訓練集\n",
    "model.load_weights('py/CNN/cnn')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(train_x,train_y)\n",
    "pred_cy = model.predict_classes(train_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_x, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 3, 3, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 15,895,363\n",
      "Trainable params: 15,895,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5000 samples, validate on 1130 samples\n",
      "Epoch 1/500\n",
      "5000/5000 [==============================] - 10s 2ms/step - loss: 1.3945 - accuracy: 0.3614 - val_loss: 1.0994 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.34602, saving model to py/VGG16/vgg16_n\n",
      "Epoch 2/500\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 1.0957 - accuracy: 0.3730 - val_loss: 1.1008 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.34602\n",
      "Epoch 3/500\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 1.0956 - accuracy: 0.3730 - val_loss: 1.1001 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.34602\n",
      "Epoch 4/500\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 1.0954 - accuracy: 0.3730 - val_loss: 1.0995 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.34602\n",
      "Epoch 5/500\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 1.0955 - accuracy: 0.3730 - val_loss: 1.1000 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.34602\n",
      "Epoch 6/500\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 1.0955 - accuracy: 0.3730 - val_loss: 1.0997 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.34602\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/500\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 1.0953 - accuracy: 0.3730 - val_loss: 1.0999 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.34602\n",
      "Epoch 8/500\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 1.0953 - accuracy: 0.3730 - val_loss: 1.0998 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.34602\n",
      "Epoch 9/500\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 1.0953 - accuracy: 0.3730 - val_loss: 1.0998 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.34602\n",
      "Epoch 10/500\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 1.0953 - accuracy: 0.3730 - val_loss: 1.0997 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.34602\n",
      "Epoch 11/500\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 1.0952 - accuracy: 0.3730 - val_loss: 1.0996 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.34602\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n"
     ]
    }
   ],
   "source": [
    "conv_base = VGG16(weights = 'imagenet', include_top = False, input_shape = (112 ,112,3))\n",
    "\n",
    "# conv_base.trainable = False\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(64, activation = 'relu'))\n",
    "# # model.add(Dropout(0.1))\n",
    "# model.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "\n",
    "# model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Flatten()) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(256, activation='relu')) \n",
    "# model.add(Dropout(0.5)) \n",
    "model.add(Dense(3, activation='softmax')) \n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10)\n",
    "modelcheckpoint = keras.callbacks.ModelCheckpoint(filepath='py/VGG16/vgg16_n', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "# reduceLronplateau = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.001, cooldown=0, min_lr=0)\n",
    "reduceLronplateau=ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                             patience=5,\n",
    "                             # 3 epochs 內acc沒下降就要調整LR\n",
    "                             verbose=1,\n",
    "                             factor=0.5,\n",
    "                             # LR降為0.5\n",
    "                             min_lr=0.00001\n",
    "                             # 最小 LR 到0.00001就不再下降\n",
    "                             )\n",
    "\n",
    "\n",
    "# model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr=1e-4), metrics = ['accuracy'])\n",
    "\n",
    "# history = model.fit(train_x, train_y, epochs=500, batch_size=32, verbose=1, callbacks=[modelcheckpoint, earlystopping, reduceLronplateau])\n",
    "\n",
    "history = model.fit(train_x[:5000],train_y[:5000], epochs=500, batch_size=32, verbose=1,validation_data=(train_x[5000:],train_y[5000:]), callbacks=[modelcheckpoint, earlystopping, reduceLronplateau])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 588us/step\n",
      "Loss: 1.0931486530303955\n",
      "Accuracy: 0.3840000033378601\n",
      "predict accurscy: 0.384, precision: 0.128, recall: 0.3333333333333333, f1: 0.18497109826589597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# model.load_weights('py/vgg16/vgg16_n')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "plot_acc(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 587us/step\n",
      "Loss: 1.093849515914917\n",
      "Accuracy: 0.3840000033378601\n",
      "predict accurscy: 0.384, precision: 0.128, recall: 0.3333333333333333, f1: 0.18497109826589597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#測試集\n",
    "model.load_weights('py/VGG16/vgg16_n')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6130/6130 [==============================] - 4s 607us/step\n",
      "Loss: 1.0959790220851804\n",
      "Accuracy: 0.36802610754966736\n",
      "predict accurscy: 0.36802610114192497, precision: 0.12267536704730832, recall: 0.3333333333333333, f1: 0.1793465299308371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#訓練集\n",
    "model.load_weights('py/VGG16/vgg16_n')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(train_x,train_y)\n",
    "pred_cy = model.predict_classes(train_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_x, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料增強"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 21,138,243\n",
      "Trainable params: 21,138,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "100/100 [==============================] - 24s 245ms/step - loss: 1.2636 - accuracy: 0.3604 - val_loss: 1.0985 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.34602, saving model to py/VGG16/vgg16\n",
      "Epoch 2/500\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 1.0961 - accuracy: 0.3725 - val_loss: 1.0992 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.34602\n",
      "Epoch 3/500\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 1.0954 - accuracy: 0.3732 - val_loss: 1.0993 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.34602\n",
      "Epoch 4/500\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 1.0958 - accuracy: 0.3701 - val_loss: 1.0995 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.34602\n",
      "Epoch 5/500\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 1.0944 - accuracy: 0.3776 - val_loss: 1.1004 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.34602\n",
      "Epoch 6/500\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 1.0958 - accuracy: 0.3703 - val_loss: 1.0995 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.34602\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/500\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 1.0954 - accuracy: 0.3719 - val_loss: 1.0997 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.34602\n",
      "Epoch 8/500\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 1.0952 - accuracy: 0.3733 - val_loss: 1.0999 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.34602\n",
      "Epoch 9/500\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 1.0962 - accuracy: 0.3675 - val_loss: 1.0992 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.34602\n",
      "Epoch 10/500\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 1.0936 - accuracy: 0.3831 - val_loss: 1.1003 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.34602\n",
      "Epoch 11/500\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 1.0956 - accuracy: 0.3711 - val_loss: 1.0997 - val_accuracy: 0.3460\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.34602\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n"
     ]
    }
   ],
   "source": [
    "conv_base = VGG16(weights = 'imagenet', include_top = False, input_shape = (224 ,224,3))\n",
    "\n",
    "# conv_base.trainable = False\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(64, activation = 'relu'))\n",
    "# # model.add(Dropout(0.1))\n",
    "# model.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "\n",
    "# model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Flatten()) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(256, activation='relu')) \n",
    "# model.add(Dropout(0.5)) \n",
    "model.add(Dense(3, activation='softmax')) \n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10)\n",
    "modelcheckpoint = keras.callbacks.ModelCheckpoint(filepath='py/VGG16/vgg16', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "# reduceLronplateau = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.001, cooldown=0, min_lr=0)\n",
    "reduceLronplateau=ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                             patience=5,\n",
    "                             # 3 epochs 內acc沒下降就要調整LR\n",
    "                             verbose=1,\n",
    "                             factor=0.5,\n",
    "                             # LR降為0.5\n",
    "                             min_lr=0.00001\n",
    "                             # 最小 LR 到0.00001就不再下降\n",
    "                             )\n",
    "\n",
    "\n",
    "# model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr=1e-4), metrics = ['accuracy'])\n",
    "# train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "# test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "# train_datagen = ImageDataGenerator(rotation_range=0.2, zoom_range=0.05,\n",
    "#                                    featurewise_center = True, featurewise_std_normalization = True,\n",
    "#                                     width_shift_range=0.05, height_shift_range=0.05, shear_range=0.05,\n",
    "#                                     horizontal_flip=True, fill_mode=\"nearest\")\n",
    "train_datagen=ImageDataGenerator(rotation_range=45 , \n",
    "                             width_shift_range=0.15 , \n",
    "                             height_shift_range=0.15 ,\n",
    "                             shear_range=0.15 ,\n",
    "                             zoom_range=0.15 , \n",
    "                             data_format='channels_last')\n",
    "\n",
    "train_datagen.fit(train_x)\n",
    "history = model.fit_generator(train_datagen.flow(train_x[:5000],train_y[:5000],batch_size=36), \n",
    "                              steps_per_epoch=100 , epochs=500,\n",
    "                              validation_data=(train_x[5000:],train_y[5000:]),validation_steps=50,\n",
    "                              callbacks=[modelcheckpoint, earlystopping, reduceLronplateau])\n",
    "\n",
    "# model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step\n",
      "Loss: 1.0928948860168457\n",
      "Accuracy: 0.3840000033378601\n",
      "predict accurscy: 0.384, precision: 0.128, recall: 0.3333333333333333, f1: 0.18497109826589597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model.load_weights('py/CNN/cnn')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step\n",
      "Loss: 1.097076919555664\n",
      "Accuracy: 0.3840000033378601\n",
      "predict accurscy: 0.384, precision: 0.128, recall: 0.3333333333333333, f1: 0.18497109826589597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#測試集\n",
    "model.load_weights('py/VGG16/vgg16')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(test_x,test_y)\n",
    "pred_cy = model.predict_classes(test_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_y, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_y, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6130/6130 [==============================] - 13s 2ms/step\n",
      "Loss: 1.0971271055168663\n",
      "Accuracy: 0.36802610754966736\n",
      "predict accurscy: 0.36802610114192497, precision: 0.12267536704730832, recall: 0.3333333333333333, f1: 0.1793465299308371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#訓練集\n",
    "model.load_weights('py/VGG16/vgg16')\n",
    "# loss, accuracy = model.evaluate(test_datagen.flow(test_x, test_y))\n",
    "loss,accuracy=model.evaluate(train_x,train_y)\n",
    "pred_cy = model.predict_classes(train_x)\n",
    "\n",
    "precision = precision_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "recall = recall_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "acc = accuracy_score(label_labelencoder_x, pred_cy)\n",
    "\n",
    "f1 = f1_score(label_labelencoder_x, pred_cy, average='macro')\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n",
    "print(f'predict accurscy: {acc}, precision: {precision}, recall: {recall}, f1: {f1}')\n",
    "# plot_acc(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
